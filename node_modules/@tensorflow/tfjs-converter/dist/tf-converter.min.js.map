{"version":3,"file":"tf-converter.min.js","sources":["../src/operations/custom_op/register.ts","../src/data/compiled_api.ts","../src/operations/executors/utils.ts","../src/operations/op_list/arithmetic.ts","../src/operations/op_list/basic_math.ts","../src/operations/op_list/control.ts","../src/operations/op_list/convolution.ts","../src/operations/op_list/creation.ts","../src/operations/op_list/dynamic.ts","../src/operations/op_list/evaluation.ts","../src/operations/op_list/graph.ts","../src/operations/op_list/image.ts","../src/operations/op_list/logical.ts","../src/operations/op_list/matrices.ts","../src/operations/op_list/normalization.ts","../src/operations/op_list/reduction.ts","../src/operations/op_list/slice_join.ts","../src/operations/op_list/spectral.ts","../src/operations/op_list/transformation.ts","../src/operations/operation_mapper.ts","../src/operations/custom_op/node_value_impl.ts","../src/operations/executors/arithmetic_executor.ts","../src/operations/executors/basic_math_executor.ts","../src/executor/tensor_array.ts","../src/operations/executors/convolution_executor.ts","../src/operations/executors/creation_executor.ts","../src/operations/executors/evaluation_executor.ts","../src/operations/executors/graph_executor.ts","../src/operations/executors/image_executor.ts","../src/operations/executors/logical_executor.ts","../src/operations/executors/matrices_executor.ts","../src/operations/executors/normalization_executor.ts","../src/operations/executors/reduction_executor.ts","../src/operations/executors/slice_join_executor.ts","../src/operations/executors/spectral_executor.ts","../src/operations/executors/transformation_executor.ts","../src/operations/operation_executor.ts","../src/operations/executors/control_executor.ts","../src/operations/executors/dynamic_executor.ts","../src/executor/execution_context.ts","../src/executor/model_analysis.ts","../src/executor/graph_executor.ts","../src/executor/model_rewrite.ts","../src/executor/graph_model.ts","../src/version.ts"],"sourcesContent":["\n/**\n * @license\n * Copyright 2019 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {OpExecutor, OpMapper} from '../types';\n\nconst CUSTOM_OPS: {[key: string]: OpMapper} = {};\n\n/**\n * Register an Op for graph model executor. This allow you to register\n * TensorFlow custom op or override existing op.\n *\n * Here is an example of registering a new MatMul Op.\n * ```js\n * const customMatmul = (node) =>\n *    tf.matMul(\n *        node.inputs[0], node.inputs[1],\n *        node.attrs['transpose_a'], node.attrs['transpose_b']);\n *\n * tf.registerOp('MatMul', customMatmul);\n * ```\n * The inputs and attrs of the node object is based on the TensorFlow op\n * registry.\n *\n * @param name The Tensorflow Op name.\n * @param opFunc An op function which is called with the current graph node\n * during execution and needs to return a tensor or a list of tensors. The node\n * has the following attributes:\n *    - attr: A map from attribute name to its value\n *    - inputs: A list of input tensors\n */\n/** @doc {heading: 'Models', subheading: 'Op Registry'} */\nexport function registerOp(name: string, opFunc: OpExecutor) {\n  const opMapper: OpMapper = {\n    tfOpName: name,\n    category: 'custom',\n    inputs: [],\n    attrs: [],\n    customExecutor: opFunc\n  };\n\n  CUSTOM_OPS[name] = opMapper;\n}\n\n/**\n * Retrieve the OpMapper object for the registered op.\n *\n * @param name The Tensorflow Op name.\n */\n/** @doc {heading: 'Models', subheading: 'Op Registry'} */\n\nexport function getRegisteredOp(name: string): OpMapper {\n  return CUSTOM_OPS[name];\n}\n\n/**\n * Deregister the Op for graph model executor.\n *\n * @param name The Tensorflow Op name.\n */\n/** @doc {heading: 'Models', subheading: 'Op Registry'} */\nexport function deregisterOp(name: string) {\n  delete CUSTOM_OPS[name];\n}\n","/**\n * @license\n * Copyright 2019 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n *\n * =============================================================================\n */\n\n/** Properties of an Any. */\nexport declare interface IAny {\n  /** Any typeUrl */\n  typeUrl?: (string|null);\n\n  /** Any value */\n  value?: (Uint8Array|null);\n}\n\n/** DataType enum. */\nexport enum DataType {\n  DT_INVALID = 0,\n  DT_FLOAT = 1,\n  DT_DOUBLE = 2,\n  DT_INT32 = 3,\n  DT_UINT8 = 4,\n  DT_INT16 = 5,\n  DT_INT8 = 6,\n  DT_STRING = 7,\n  DT_COMPLEX64 = 8,\n  DT_INT64 = 9,\n  DT_BOOL = 10,\n  DT_QINT8 = 11,\n  DT_QUINT8 = 12,\n  DT_QINT32 = 13,\n  DT_BFLOAT16 = 14,\n  DT_FLOAT_REF = 101,\n  DT_DOUBLE_REF = 102,\n  DT_INT32_REF = 103,\n  DT_UINT8_REF = 104,\n  DT_INT16_REF = 105,\n  DT_INT8_REF = 106,\n  DT_STRING_REF = 107,\n  DT_COMPLEX64_REF = 108,\n  DT_INT64_REF = 109,\n  DT_BOOL_REF = 110,\n  DT_QINT8_REF = 111,\n  DT_QUINT8_REF = 112,\n  DT_QINT32_REF = 113,\n  DT_BFLOAT16_REF = 114\n}\n\n/** Properties of a TensorShape. */\nexport declare interface ITensorShape {\n  /** TensorShape dim */\n  dim?: (TensorShape.IDim[]|null);\n\n  /** TensorShape unknownRank */\n  unknownRank?: (boolean|null);\n}\n\nexport namespace TensorShape {\n  /** Properties of a Dim. */\n  export declare interface IDim {\n    /** Dim size */\n    size?: (number|string|null);\n\n    /** Dim name */\n    name?: (string|null);\n  }\n}\n\n/** Properties of a Tensor. */\nexport declare interface ITensor {\n  /** Tensor dtype */\n  dtype?: (DataType|null);\n\n  /** Tensor tensorShape */\n  tensorShape?: (ITensorShape|null);\n\n  /** Tensor versionNumber */\n  versionNumber?: (number|null);\n\n  /** Tensor tensorContent */\n  tensorContent?: (Uint8Array|null);\n\n  /** Tensor floatVal */\n  floatVal?: (number[]|null);\n\n  /** Tensor doubleVal */\n  doubleVal?: (number[]|null);\n\n  /** Tensor intVal */\n  intVal?: (number[]|null);\n\n  /** Tensor stringVal */\n  stringVal?: (Uint8Array[]|null);\n\n  /** Tensor scomplexVal */\n  scomplexVal?: (number[]|null);\n\n  /** Tensor int64Val */\n  int64Val?: ((number | string)[]|null);\n\n  /** Tensor boolVal */\n  boolVal?: (boolean[]|null);\n\n  /** Tensor uint32Val */\n  uint32Val?: (number[]|null);\n\n  /** Tensor uint64Val */\n  uint64Val?: ((number | string)[]|null);\n}\n\n/** Properties of an AttrValue. */\nexport declare interface IAttrValue {\n  /** AttrValue list */\n  list?: (AttrValue.IListValue|null);\n\n  /** AttrValue s */\n  s?: (string|null);\n\n  /** AttrValue i */\n  i?: (number|string|null);\n\n  /** AttrValue f */\n  f?: (number|null);\n\n  /** AttrValue b */\n  b?: (boolean|null);\n\n  /** AttrValue type */\n  type?: (DataType|null);\n\n  /** AttrValue shape */\n  shape?: (ITensorShape|null);\n\n  /** AttrValue tensor */\n  tensor?: (ITensor|null);\n\n  /** AttrValue placeholder */\n  placeholder?: (string|null);\n\n  /** AttrValue func */\n  func?: (INameAttrList|null);\n}\n\nexport namespace AttrValue {\n  /** Properties of a ListValue. */\n  export declare interface IListValue {\n    /** ListValue s */\n    s?: (string[]|null);\n\n    /** ListValue i */\n    i?: ((number | string)[]|null);\n\n    /** ListValue f */\n    f?: (number[]|null);\n\n    /** ListValue b */\n    b?: (boolean[]|null);\n\n    /** ListValue type */\n    type?: (DataType[]|null);\n\n    /** ListValue shape */\n    shape?: (ITensorShape[]|null);\n\n    /** ListValue tensor */\n    tensor?: (ITensor[]|null);\n\n    /** ListValue func */\n    func?: (INameAttrList[]|null);\n  }\n}\n\n/** Properties of a NameAttrList. */\nexport declare interface INameAttrList {\n  /** NameAttrList name */\n  name?: (string|null);\n\n  /** NameAttrList attr */\n  attr?: ({[k: string]: IAttrValue}|null);\n}\n\n/** Properties of a NodeDef. */\nexport declare interface INodeDef {\n  /** NodeDef name */\n  name?: (string|null);\n\n  /** NodeDef op */\n  op?: (string|null);\n\n  /** NodeDef input */\n  input?: (string[]|null);\n\n  /** NodeDef device */\n  device?: (string|null);\n\n  /** NodeDef attr */\n  attr?: ({[k: string]: IAttrValue}|null);\n}\n\n/** Properties of a VersionDef. */\nexport declare interface IVersionDef {\n  /** VersionDef producer */\n  producer?: (number|null);\n\n  /** VersionDef minConsumer */\n  minConsumer?: (number|null);\n\n  /** VersionDef badConsumers */\n  badConsumers?: (number[]|null);\n}\n\n/** Properties of a GraphDef. */\nexport declare interface IGraphDef {\n  /** GraphDef node */\n  node?: (INodeDef[]|null);\n\n  /** GraphDef versions */\n  versions?: (IVersionDef|null);\n\n  /** GraphDef library */\n  library?: (IFunctionDefLibrary|null);\n}\n\n/** Properties of a CollectionDef. */\nexport declare interface ICollectionDef {\n  /** CollectionDef nodeList */\n  nodeList?: (CollectionDef.INodeList|null);\n\n  /** CollectionDef bytesList */\n  bytesList?: (CollectionDef.IBytesList|null);\n\n  /** CollectionDef int64List */\n  int64List?: (CollectionDef.IInt64List|null);\n\n  /** CollectionDef floatList */\n  floatList?: (CollectionDef.IFloatList|null);\n\n  /** CollectionDef anyList */\n  anyList?: (CollectionDef.IAnyList|null);\n}\n\nexport namespace CollectionDef {\n  /** Properties of a NodeList. */\n  export declare interface INodeList {\n    /** NodeList value */\n    value?: (string[]|null);\n  }\n\n  /** Properties of a BytesList. */\n  export declare interface IBytesList {\n    /** BytesList value */\n    value?: (Uint8Array[]|null);\n  }\n\n  /** Properties of an Int64List. */\n  export declare interface IInt64List {\n    /** Int64List value */\n    value?: ((number | string)[]|null);\n  }\n\n  /** Properties of a FloatList. */\n  export declare interface IFloatList {\n    /** FloatList value */\n    value?: (number[]|null);\n  }\n\n  /** Properties of an AnyList. */\n  export declare interface IAnyList {\n    /** AnyList value */\n    value?: (IAny[]|null);\n  }\n}\n\n/** Properties of a SaverDef. */\nexport declare interface ISaverDef {\n  /** SaverDef filenameTensorName */\n  filenameTensorName?: (string|null);\n\n  /** SaverDef saveTensorName */\n  saveTensorName?: (string|null);\n\n  /** SaverDef restoreOpName */\n  restoreOpName?: (string|null);\n\n  /** SaverDef maxToKeep */\n  maxToKeep?: (number|null);\n\n  /** SaverDef sharded */\n  sharded?: (boolean|null);\n\n  /** SaverDef keepCheckpointEveryNHours */\n  keepCheckpointEveryNHours?: (number|null);\n\n  /** SaverDef version */\n  version?: (SaverDef.CheckpointFormatVersion|null);\n}\n\nexport namespace SaverDef {\n  /** CheckpointFormatVersion enum. */\n  export enum CheckpointFormatVersion {LEGACY = 0, V1 = 1, V2 = 2}\n}\n\n/** Properties of a TensorInfo. */\nexport declare interface ITensorInfo {\n  /** TensorInfo name */\n  name?: (string|null);\n\n  /** TensorInfo cooSparse */\n  cooSparse?: (TensorInfo.ICooSparse|null);\n\n  /** TensorInfo dtype */\n  dtype?: (DataType|null);\n\n  /** TensorInfo tensorShape */\n  tensorShape?: (ITensorShape|null);\n}\n\nexport namespace TensorInfo {\n  /** Properties of a CooSparse. */\n  export declare interface ICooSparse {\n    /** CooSparse valuesTensorName */\n    valuesTensorName?: (string|null);\n\n    /** CooSparse indicesTensorName */\n    indicesTensorName?: (string|null);\n\n    /** CooSparse denseShapeTensorName */\n    denseShapeTensorName?: (string|null);\n  }\n}\n\n/** Properties of a SignatureDef. */\nexport declare interface ISignatureDef {\n  /** SignatureDef inputs */\n  inputs?: ({[k: string]: ITensorInfo}|null);\n\n  /** SignatureDef outputs */\n  outputs?: ({[k: string]: ITensorInfo}|null);\n\n  /** SignatureDef methodName */\n  methodName?: (string|null);\n}\n\n/** Properties of an AssetFileDef. */\nexport declare interface IAssetFileDef {\n  /** AssetFileDef tensorInfo */\n  tensorInfo?: (ITensorInfo|null);\n\n  /** AssetFileDef filename */\n  filename?: (string|null);\n}\n\n/** Properties of an OpDef. */\nexport declare interface IOpDef {\n  /** OpDef name */\n  name?: (string|null);\n\n  /** OpDef inputArg */\n  inputArg?: (OpDef.IArgDef[]|null);\n\n  /** OpDef outputArg */\n  outputArg?: (OpDef.IArgDef[]|null);\n\n  /** OpDef attr */\n  attr?: (OpDef.IAttrDef[]|null);\n\n  /** OpDef deprecation */\n  deprecation?: (OpDef.IOpDeprecation|null);\n\n  /** OpDef summary */\n  summary?: (string|null);\n\n  /** OpDef description */\n  description?: (string|null);\n\n  /** OpDef isCommutative */\n  isCommutative?: (boolean|null);\n\n  /** OpDef isAggregate */\n  isAggregate?: (boolean|null);\n\n  /** OpDef isStateful */\n  isStateful?: (boolean|null);\n\n  /** OpDef allowsUninitializedInput */\n  allowsUninitializedInput?: (boolean|null);\n}\n\nexport namespace OpDef {\n  /** Properties of an ArgDef. */\n  export declare interface IArgDef {\n    /** ArgDef name */\n    name?: (string|null);\n\n    /** ArgDef description */\n    description?: (string|null);\n\n    /** ArgDef type */\n    type?: (DataType|null);\n\n    /** ArgDef typeAttr */\n    typeAttr?: (string|null);\n\n    /** ArgDef numberAttr */\n    numberAttr?: (string|null);\n\n    /** ArgDef typeListAttr */\n    typeListAttr?: (string|null);\n\n    /** ArgDef isRef */\n    isRef?: (boolean|null);\n  }\n\n  /** Properties of an AttrDef. */\n  export declare interface IAttrDef {\n    /** AttrDef name */\n    name?: (string|null);\n\n    /** AttrDef type */\n    type?: (string|null);\n\n    /** AttrDef defaultValue */\n    defaultValue?: (IAttrValue|null);\n\n    /** AttrDef description */\n    description?: (string|null);\n\n    /** AttrDef hasMinimum */\n    hasMinimum?: (boolean|null);\n\n    /** AttrDef minimum */\n    minimum?: (number|string|null);\n\n    /** AttrDef allowedValues */\n    allowedValues?: (IAttrValue|null);\n  }\n\n  /** Properties of an OpDeprecation. */\n  export declare interface IOpDeprecation {\n    /** OpDeprecation version */\n    version?: (number|null);\n\n    /** OpDeprecation explanation */\n    explanation?: (string|null);\n  }\n}\n\n/** Properties of an OpList. */\nexport declare interface IOpList {\n  /** OpList op */\n  op?: (IOpDef[]|null);\n}\n\n/** Properties of a MetaGraphDef. */\nexport declare interface IMetaGraphDef {\n  /** MetaGraphDef metaInfoDef */\n  metaInfoDef?: (MetaGraphDef.IMetaInfoDef|null);\n\n  /** MetaGraphDef graphDef */\n  graphDef?: (IGraphDef|null);\n\n  /** MetaGraphDef saverDef */\n  saverDef?: (ISaverDef|null);\n\n  /** MetaGraphDef collectionDef */\n  collectionDef?: ({[k: string]: ICollectionDef}|null);\n\n  /** MetaGraphDef signatureDef */\n  signatureDef?: ({[k: string]: ISignatureDef}|null);\n\n  /** MetaGraphDef assetFileDef */\n  assetFileDef?: (IAssetFileDef[]|null);\n}\n\nexport namespace MetaGraphDef {\n  /** Properties of a MetaInfoDef. */\n  export declare interface IMetaInfoDef {\n    /** MetaInfoDef metaGraphVersion */\n    metaGraphVersion?: (string|null);\n\n    /** MetaInfoDef strippedOpList */\n    strippedOpList?: (IOpList|null);\n\n    /** MetaInfoDef anyInfo */\n    anyInfo?: (IAny|null);\n\n    /** MetaInfoDef tags */\n    tags?: (string[]|null);\n\n    /** MetaInfoDef tensorflowVersion */\n    tensorflowVersion?: (string|null);\n\n    /** MetaInfoDef tensorflowGitVersion */\n    tensorflowGitVersion?: (string|null);\n  }\n}\n\n/** Properties of a SavedModel. */\nexport declare interface ISavedModel {\n  /** SavedModel savedModelSchemaVersion */\n  savedModelSchemaVersion?: (number|string|null);\n\n  /** SavedModel metaGraphs */\n  metaGraphs?: (IMetaGraphDef[]|null);\n}\n\n/** Properties of a FunctionDefLibrary. */\nexport declare interface IFunctionDefLibrary {\n  /** FunctionDefLibrary function */\n  'function'?: (IFunctionDef[]|null);\n\n  /** FunctionDefLibrary gradient */\n  gradient?: (IGradientDef[]|null);\n}\n\n/** Properties of a FunctionDef. */\nexport declare interface IFunctionDef {\n  /** FunctionDef signature */\n  signature?: (IOpDef|null);\n\n  /** FunctionDef attr */\n  attr?: ({[k: string]: IAttrValue}|null);\n\n  /** FunctionDef nodeDef */\n  nodeDef?: (INodeDef[]|null);\n\n  /** FunctionDef ret */\n  ret?: ({[k: string]: string}|null);\n}\n\n/** Properties of a GradientDef. */\nexport declare interface IGradientDef {\n  /** GradientDef functionName */\n  functionName?: (string|null);\n\n  /** GradientDef gradientFunc */\n  gradientFunc?: (string|null);\n}\n","/**\n * @license\n * Copyright 2018 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport * as tfc from '@tensorflow/tfjs-core';\n\nimport {NamedTensorsMap} from '../../data/types';\nimport {ExecutionContext} from '../../executor/execution_context';\nimport {Node, ValueType} from '../types';\n\nexport function getParamValue(\n    paramName: string, node: Node, tensorMap: NamedTensorsMap,\n    context: ExecutionContext): ValueType {\n  const inputParam = node.inputParams[paramName];\n  if (inputParam && inputParam.inputIndexStart !== undefined) {\n    const start = inputParam.inputIndexStart;\n    const end = inputParam.inputIndexEnd === 0 ?\n        undefined :\n        (inputParam.inputIndexEnd === undefined ? start + 1 :\n                                                  inputParam.inputIndexEnd);\n    if (inputParam.type === 'tensor') {\n      return getTensor(\n          node.inputNames[inputParam.inputIndexStart], tensorMap, context);\n    }\n    if (inputParam.type === 'tensors') {\n      const inputs = node.inputNames.slice(start, end);\n\n      return inputs.map(name => getTensor(name, tensorMap, context));\n    }\n    const data = Array.prototype.slice.call(\n        getTensor(node.inputNames.slice(start)[0], tensorMap, context)\n            .dataSync());\n    return inputParam.type === 'number' ? data[0] : data;\n  }\n  const attrParam = node.attrParams[paramName];\n  return attrParam && attrParam.value;\n}\n\n/**\n * Retrieve the tensor based on input name by extracting the node name and\n * output index information.\n * @param name Node input name\n * @param tensorsMap Tensors map keyed by the node\n */\nexport function getTensor(\n    name: string, tensorsMap: NamedTensorsMap,\n    context: ExecutionContext): tfc.Tensor {\n  const [nodeName, index] = parseNodeName(name);\n  const contextId = context.currentContextIds.find(contextId => {\n    return !!tensorsMap[getNodeNameWithContextId(nodeName, contextId)];\n  });\n\n  return contextId !== undefined ?\n      tensorsMap[getNodeNameWithContextId(nodeName, contextId)][index] :\n      undefined;\n}\n\n/**\n * Retrieve the tensors based on input name for current context.\n * @param name Node input name\n * @param tensorsMap Tensors map keyed by the node\n */\nexport function getTensorsForCurrentContenxt(\n    name: string, tensorsMap: NamedTensorsMap,\n    context: ExecutionContext): tfc.Tensor[] {\n  return tensorsMap[getNodeNameWithContextId(name, context.currentContextId)];\n}\n\n/**\n * Returns the node name and index from the Node input name.\n * @param inputName The input name of the node, in format of\n * node_name:output_index, i.e. MatMul:0, if the output_index is not set, it is\n * default to 0.\n */\nexport function getNodeNameAndIndex(\n    inputName: string, context?: ExecutionContext): [string, number] {\n  const [nodeName, index] = parseNodeName(inputName);\n\n  return [\n    getNodeNameWithContextId(nodeName, context && context.currentContextId),\n    index\n  ];\n}\n\nfunction getNodeNameWithContextId(name: string, contextId?: string): string {\n  return !!contextId ? `${name}-${contextId}` : name;\n}\n\nexport function parseNodeName(name: string): [string, number] {\n  const index = name.lastIndexOf(':');\n  if (index === -1) return [name, 0];\n\n  const nodeName = name.substring(0, index);\n  return [nodeName, Number(name.substring(index + 1))];\n}\n\nexport function split(arr: number[], size: number) {\n  const res = [];\n  for (let i = 0; i < arr.length; i += size) {\n    res.push(arr.slice(i, i + size));\n  }\n  return res;\n}\n","/**\n * @license\n * Copyright 2018 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {OpMapper} from '../types';\n\nexport const json: OpMapper[] = [\n  {\n    'tfOpName': 'Add',\n    'category': 'arithmetic',\n    'inputs': [\n      {'start': 0, 'name': 'a', 'type': 'tensor'},\n      {'start': 1, 'name': 'b', 'type': 'tensor'},\n    ],\n    'attrs': [\n      {'tfName': 'T', 'name': 'dtype', 'type': 'dtype', 'notSupported': true}\n    ]\n  },\n  {\n    'tfOpName': 'AddV2',\n    'category': 'arithmetic',\n    'inputs': [\n      {'start': 0, 'name': 'a', 'type': 'tensor'},\n      {'start': 1, 'name': 'b', 'type': 'tensor'},\n    ],\n    'attrs': [\n      {'tfName': 'T', 'name': 'dtype', 'type': 'dtype', 'notSupported': true}\n    ]\n  },\n  {\n    'tfOpName': 'AddN',\n    'category': 'arithmetic',\n    'inputs': [{'start': 0, 'end': 0, 'name': 'tensors', 'type': 'tensors'}]\n  },\n  {\n    'tfOpName': 'BiasAdd',\n    'category': 'arithmetic',\n    'inputs': [\n      {'start': 0, 'name': 'a', 'type': 'tensor'},\n      {'start': 1, 'name': 'b', 'type': 'tensor'},\n    ],\n    'attrs': [\n      {'tfName': 'T', 'name': 'dtype', 'type': 'dtype', 'notSupported': true}\n    ]\n  },\n  {\n    'tfOpName': 'Sub',\n    'category': 'arithmetic',\n    'inputs': [\n      {'start': 0, 'name': 'a', 'type': 'tensor'},\n      {'start': 1, 'name': 'b', 'type': 'tensor'},\n    ],\n    'attrs': [\n      {'tfName': 'T', 'name': 'dtype', 'type': 'dtype', 'notSupported': true}\n    ]\n  },\n  {\n    'tfOpName': 'RealDiv',\n    'category': 'arithmetic',\n    'inputs': [\n      {'start': 0, 'name': 'a', 'type': 'tensor'},\n      {'start': 1, 'name': 'b', 'type': 'tensor'},\n    ],\n    'attrs': [\n      {'tfName': 'T', 'name': 'dtype', 'type': 'dtype', 'notSupported': true}\n    ]\n  },\n  {\n    'tfOpName': 'Div',\n    'category': 'arithmetic',\n    'inputs': [\n      {'start': 0, 'name': 'a', 'type': 'tensor'},\n      {'start': 1, 'name': 'b', 'type': 'tensor'},\n    ],\n    'attrs': [\n      {'tfName': 'T', 'name': 'dtype', 'type': 'dtype', 'notSupported': true}\n    ]\n  },\n  {\n    'tfOpName': 'FloorDiv',\n    'category': 'arithmetic',\n    'inputs': [\n      {'start': 0, 'name': 'a', 'type': 'tensor'},\n      {'start': 1, 'name': 'b', 'type': 'tensor'},\n    ],\n    'attrs': [\n      {'tfName': 'T', 'name': 'dtype', 'type': 'dtype', 'notSupported': true}\n    ]\n  },\n  {\n    'tfOpName': 'Mul',\n    'category': 'arithmetic',\n    'inputs': [\n      {'start': 0, 'name': 'a', 'type': 'tensor'},\n      {'start': 1, 'name': 'b', 'type': 'tensor'},\n    ],\n    'attrs': [\n      {'tfName': 'T', 'name': 'dtype', 'type': 'dtype', 'notSupported': true}\n    ]\n  },\n  {\n    'tfOpName': 'Maximum',\n    'category': 'arithmetic',\n    'inputs': [\n      {'start': 0, 'name': 'a', 'type': 'tensor'},\n      {'start': 1, 'name': 'b', 'type': 'tensor'}\n    ]\n  },\n  {\n    'tfOpName': 'Minimum',\n    'category': 'arithmetic',\n    'inputs': [\n      {'start': 0, 'name': 'a', 'type': 'tensor'},\n      {'start': 1, 'name': 'b', 'type': 'tensor'}\n    ]\n  },\n  {\n    'tfOpName': 'Pow',\n    'category': 'arithmetic',\n    'inputs': [\n      {'start': 0, 'name': 'a', 'type': 'tensor'},\n      {'start': 1, 'name': 'b', 'type': 'tensor'},\n    ],\n    'attrs': [\n      {'tfName': 'T', 'name': 'dtype', 'type': 'dtype', 'notSupported': true}\n    ]\n  },\n  {\n    'tfOpName': 'SquaredDifference',\n    'category': 'arithmetic',\n    'inputs': [\n      {'start': 0, 'name': 'a', 'type': 'tensor'},\n      {'start': 1, 'name': 'b', 'type': 'tensor'},\n    ],\n    'attrs': [\n      {'tfName': 'T', 'name': 'dtype', 'type': 'dtype', 'notSupported': true}\n    ]\n  },\n  {\n    'tfOpName': 'Mod',\n    'category': 'arithmetic',\n    'inputs': [\n      {'start': 0, 'name': 'a', 'type': 'tensor'},\n      {'start': 1, 'name': 'b', 'type': 'tensor'},\n    ],\n    'attrs': [\n      {'tfName': 'T', 'name': 'dtype', 'type': 'dtype', 'notSupported': true}\n    ]\n  },\n  {\n    'tfOpName': 'FloorMod',\n    'category': 'arithmetic',\n    'inputs': [\n      {'start': 0, 'name': 'a', 'type': 'tensor'},\n      {'start': 1, 'name': 'b', 'type': 'tensor'},\n    ],\n    'attrs': [{\n      'tfName': 'T',\n      'name': 'dtype',\n      'type': 'dtype',\n      'notSupported': true\n    }]\n  }\n];\n","import {OpMapper} from '../types';\n\n/**\n * @license\n * Copyright 2018 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nexport const json: OpMapper[] = [\n  {\n    'tfOpName': 'Abs',\n    'category': 'basic_math',\n    'inputs': [\n      {'start': 0, 'name': 'x', 'type': 'tensor'},\n    ],\n    'attrs': [\n      {'tfName': 'T', 'name': 'dtype', 'type': 'dtype', 'notSupported': true}\n    ]\n  },\n  {\n    'tfOpName': 'Acos',\n    'category': 'basic_math',\n    'inputs': [\n      {'start': 0, 'name': 'x', 'type': 'tensor'},\n    ],\n    'attrs': [\n      {'tfName': 'T', 'name': 'dtype', 'type': 'dtype', 'notSupported': true}\n    ]\n  },\n  {\n    'tfOpName': 'Asin',\n    'category': 'basic_math',\n    'inputs': [\n      {'start': 0, 'name': 'x', 'type': 'tensor'},\n    ],\n    'attrs': [\n      {'tfName': 'T', 'name': 'dtype', 'type': 'dtype', 'notSupported': true}\n    ]\n  },\n  {\n    'tfOpName': 'Atan',\n    'category': 'basic_math',\n    'inputs': [\n      {'start': 0, 'name': 'x', 'type': 'tensor'},\n    ],\n    'attrs': [\n      {'tfName': 'T', 'name': 'dtype', 'type': 'dtype', 'notSupported': true}\n    ]\n  },\n  {\n    'tfOpName': 'Atan2',\n    'category': 'basic_math',\n    'inputs': [\n      {'start': 0, 'name': 'x', 'type': 'tensor'},\n      {'start': 1, 'name': 'y', 'type': 'tensor'},\n    ],\n    'attrs': [\n      {'tfName': 'T', 'name': 'dtype', 'type': 'dtype', 'notSupported': true}\n    ]\n  },\n  {\n    'tfOpName': 'Ceil',\n    'category': 'basic_math',\n    'inputs': [\n      {'start': 0, 'name': 'x', 'type': 'tensor'},\n    ],\n    'attrs': [\n      {'tfName': 'T', 'name': 'dtype', 'type': 'dtype', 'notSupported': true}\n    ]\n  },\n  {\n    'tfOpName': 'ClipByValue',\n    'category': 'basic_math',\n    'inputs': [\n      {'start': 0, 'name': 'x', 'type': 'tensor'},\n    ],\n    'attrs': [\n      {'tfName': 'clip_value_min', 'name': 'clipValueMin', 'type': 'number'},\n      {'tfName': 'clip_value_max', 'name': 'clipValueMax', 'type': 'number'}\n    ]\n  },\n  {\n    'tfOpName': 'Complex',\n    'category': 'basic_math',\n    'inputs': [\n      {'start': 0, 'name': 'real', 'type': 'tensor'},\n      {'start': 1, 'name': 'imag', 'type': 'tensor'},\n    ],\n    'attrs': [\n      {'tfName': 'T', 'name': 'dtype', 'type': 'dtype', 'notSupported': true}\n    ]\n  },\n  {\n    'tfOpName': 'ComplexAbs',\n    'category': 'basic_math',\n    'inputs': [\n      {'start': 0, 'name': 'x', 'type': 'tensor'},\n    ],\n    'attrs': [\n      {'tfName': 'T', 'name': 'dtype', 'type': 'dtype', 'notSupported': true}\n    ]\n  },\n  {\n    'tfOpName': 'Cos',\n    'category': 'basic_math',\n    'inputs': [\n      {'start': 0, 'name': 'x', 'type': 'tensor'},\n    ],\n    'attrs': [\n      {'tfName': 'T', 'name': 'dtype', 'type': 'dtype', 'notSupported': true}\n    ]\n  },\n  {\n    'tfOpName': 'Cosh',\n    'category': 'basic_math',\n    'inputs': [\n      {'start': 0, 'name': 'x', 'type': 'tensor'},\n    ],\n    'attrs': [\n      {'tfName': 'T', 'name': 'dtype', 'type': 'dtype', 'notSupported': true}\n    ]\n  },\n  {\n    'tfOpName': 'Elu',\n    'category': 'basic_math',\n    'inputs': [\n      {'start': 0, 'name': 'x', 'type': 'tensor'},\n    ],\n    'attrs': [\n      {'tfName': 'T', 'name': 'dtype', 'type': 'dtype', 'notSupported': true}\n    ]\n  },\n  {\n    'tfOpName': 'Exp',\n    'category': 'basic_math',\n    'inputs': [\n      {'start': 0, 'name': 'x', 'type': 'tensor'},\n    ],\n    'attrs': [\n      {'tfName': 'T', 'name': 'dtype', 'type': 'dtype', 'notSupported': true}\n    ]\n  },\n  {\n    'tfOpName': 'Floor',\n    'category': 'basic_math',\n    'inputs': [\n      {'start': 0, 'name': 'x', 'type': 'tensor'},\n    ],\n    'attrs': [\n      {'tfName': 'T', 'name': 'dtype', 'type': 'dtype', 'notSupported': true}\n    ]\n  },\n  {\n    'tfOpName': 'Log',\n    'category': 'basic_math',\n    'inputs': [\n      {'start': 0, 'name': 'x', 'type': 'tensor'},\n    ],\n    'attrs': [\n      {'tfName': 'T', 'name': 'dtype', 'type': 'dtype', 'notSupported': true}\n    ]\n  },\n  {\n    'tfOpName': 'Imag',\n    'category': 'basic_math',\n    'inputs': [\n      {'start': 0, 'name': 'x', 'type': 'tensor'},\n    ],\n    'attrs': [\n      {'tfName': 'T', 'name': 'dtype', 'type': 'dtype', 'notSupported': true}, {\n        'tfName': 'Tout',\n        'name': 'outputType',\n        'type': 'dtype',\n        'notSupported': true\n      }\n    ]\n  },\n  {\n    'tfOpName': 'Neg',\n    'category': 'basic_math',\n    'inputs': [\n      {'start': 0, 'name': 'x', 'type': 'tensor'},\n    ],\n    'attrs': [\n      {'tfName': 'T', 'name': 'dtype', 'type': 'dtype', 'notSupported': true}\n    ]\n  },\n  {\n    'tfOpName': 'Real',\n    'category': 'basic_math',\n    'inputs': [\n      {'start': 0, 'name': 'x', 'type': 'tensor'},\n    ],\n    'attrs': [\n      {'tfName': 'T', 'name': 'dtype', 'type': 'dtype', 'notSupported': true}, {\n        'tfName': 'Tout',\n        'name': 'outputType',\n        'type': 'dtype',\n        'notSupported': true\n      }\n    ]\n  },\n  {\n    'tfOpName': 'Relu',\n    'category': 'basic_math',\n    'inputs': [\n      {'start': 0, 'name': 'x', 'type': 'tensor'},\n    ],\n    'attrs': [\n      {'tfName': 'T', 'name': 'dtype', 'type': 'dtype', 'notSupported': true}\n    ]\n  },\n  {\n    'tfOpName': 'Relu6',\n    'category': 'basic_math',\n    'inputs': [\n      {'start': 0, 'name': 'x', 'type': 'tensor'},\n    ],\n    'attrs': [\n      {'tfName': 'T', 'name': 'dtype', 'type': 'dtype', 'notSupported': true}, {\n        'tfName': 'clipValueMin',\n        'name': 'clipValueMin',\n        'type': 'number',\n        'defaultValue': 0\n      },\n      {\n        'tfName': 'clipValueMax',\n        'name': 'clipValueMax',\n        'type': 'number',\n        'defaultValue': 6\n      }\n    ]\n  },\n  {\n    'tfOpName': 'Selu',\n    'category': 'basic_math',\n    'inputs': [\n      {'start': 0, 'name': 'x', 'type': 'tensor'},\n    ],\n    'attrs': [\n      {'tfName': 'T', 'name': 'dtype', 'type': 'dtype', 'notSupported': true}\n    ]\n  },\n  {\n    'tfOpName': 'Sigmoid',\n    'category': 'basic_math',\n    'inputs': [\n      {'start': 0, 'name': 'x', 'type': 'tensor'},\n    ],\n    'attrs': [\n      {'tfName': 'T', 'name': 'dtype', 'type': 'dtype', 'notSupported': true}\n    ]\n  },\n  {\n    'tfOpName': 'Sin',\n    'category': 'basic_math',\n    'inputs': [\n      {'start': 0, 'name': 'x', 'type': 'tensor'},\n    ],\n    'attrs': [\n      {'tfName': 'T', 'name': 'dtype', 'type': 'dtype', 'notSupported': true}\n    ]\n  },\n  {\n    'tfOpName': 'Sinh',\n    'category': 'basic_math',\n    'inputs': [\n      {'start': 0, 'name': 'x', 'type': 'tensor'},\n    ],\n    'attrs': [\n      {'tfName': 'T', 'name': 'dtype', 'type': 'dtype', 'notSupported': true}\n    ]\n  },\n  {\n    'tfOpName': 'Sqrt',\n    'category': 'basic_math',\n    'inputs': [\n      {'start': 0, 'name': 'x', 'type': 'tensor'},\n    ],\n    'attrs': [\n      {'tfName': 'T', 'name': 'dtype', 'type': 'dtype', 'notSupported': true}\n    ]\n  },\n  {\n    'tfOpName': 'Rsqrt',\n    'category': 'basic_math',\n    'inputs': [\n      {'start': 0, 'name': 'x', 'type': 'tensor'},\n    ],\n    'attrs': [\n      {'tfName': 'T', 'name': 'dtype', 'type': 'dtype', 'notSupported': true}\n    ]\n  },\n  {\n    'tfOpName': 'Square',\n    'category': 'basic_math',\n    'inputs': [\n      {'start': 0, 'name': 'x', 'type': 'tensor'},\n    ],\n    'attrs': [\n      {'tfName': 'T', 'name': 'dtype', 'type': 'dtype', 'notSupported': true}\n    ]\n  },\n  {\n    'tfOpName': 'Tan',\n    'category': 'basic_math',\n    'inputs': [\n      {'start': 0, 'name': 'x', 'type': 'tensor'},\n    ],\n    'attrs': [\n      {'tfName': 'T', 'name': 'dtype', 'type': 'dtype', 'notSupported': true}\n    ]\n  },\n  {\n    'tfOpName': 'Tanh',\n    'category': 'basic_math',\n    'inputs': [\n      {'start': 0, 'name': 'x', 'type': 'tensor'},\n    ],\n    'attrs': [\n      {'tfName': 'T', 'name': 'dtype', 'type': 'dtype', 'notSupported': true}\n    ]\n  },\n  {\n    'tfOpName': 'Sign',\n    'category': 'basic_math',\n    'inputs': [\n      {'start': 0, 'name': 'x', 'type': 'tensor'},\n    ],\n    'attrs': [\n      {'tfName': 'T', 'name': 'dtype', 'type': 'dtype', 'notSupported': true}\n    ]\n  },\n  {\n    'tfOpName': 'Round',\n    'category': 'basic_math',\n    'inputs': [\n      {'start': 0, 'name': 'x', 'type': 'tensor'},\n    ],\n    'attrs': [\n      {'tfName': 'T', 'name': 'dtype', 'type': 'dtype', 'notSupported': true}\n    ]\n  },\n  {\n    'tfOpName': 'Expm1',\n    'category': 'basic_math',\n    'inputs': [\n      {'start': 0, 'name': 'x', 'type': 'tensor'},\n    ],\n    'attrs': [\n      {'tfName': 'T', 'name': 'dtype', 'type': 'dtype', 'notSupported': true}\n    ]\n  },\n  {\n    'tfOpName': 'Log1p',\n    'category': 'basic_math',\n    'inputs': [\n      {'start': 0, 'name': 'x', 'type': 'tensor'},\n    ],\n    'attrs': [\n      {'tfName': 'T', 'name': 'dtype', 'type': 'dtype', 'notSupported': true}\n    ]\n  },\n  {\n    'tfOpName': 'Reciprocal',\n    'category': 'basic_math',\n    'inputs': [\n      {'start': 0, 'name': 'x', 'type': 'tensor'},\n    ],\n    'attrs': [\n      {'tfName': 'T', 'name': 'dtype', 'type': 'dtype', 'notSupported': true}\n    ]\n  },\n  {\n    'tfOpName': 'Softplus',\n    'category': 'basic_math',\n    'inputs': [\n      {'start': 0, 'name': 'x', 'type': 'tensor'},\n    ],\n    'attrs': [\n      {'tfName': 'T', 'name': 'dtype', 'type': 'dtype', 'notSupported': true}\n    ]\n  },\n  {\n    'tfOpName': 'Asinh',\n    'category': 'basic_math',\n    'inputs': [\n      {'start': 0, 'name': 'x', 'type': 'tensor'},\n    ],\n    'attrs': [\n      {'tfName': 'T', 'name': 'dtype', 'type': 'dtype', 'notSupported': true}\n    ]\n  },\n  {\n    'tfOpName': 'Acosh',\n    'category': 'basic_math',\n    'inputs': [\n      {'start': 0, 'name': 'x', 'type': 'tensor'},\n    ],\n    'attrs': [\n      {'tfName': 'T', 'name': 'dtype', 'type': 'dtype', 'notSupported': true}\n    ]\n  },\n  {\n    'tfOpName': 'Atanh',\n    'category': 'basic_math',\n    'inputs': [\n      {'start': 0, 'name': 'x', 'type': 'tensor'},\n    ],\n    'attrs': [\n      {'tfName': 'T', 'name': 'dtype', 'type': 'dtype', 'notSupported': true}\n    ]\n  },\n  {\n    'tfOpName': 'Erf',\n    'category': 'basic_math',\n    'inputs': [\n      {'start': 0, 'name': 'x', 'type': 'tensor'},\n    ],\n    'attrs': [\n      {'tfName': 'T', 'name': 'dtype', 'type': 'dtype', 'notSupported': true}\n    ]\n  },\n  {\n    'tfOpName': 'Prod',\n    'category': 'basic_math',\n    'inputs': [\n      {'start': 0, 'name': 'x', 'type': 'tensor'},\n      {'start': 1, 'name': 'axes', 'type': 'number[]'},\n    ],\n    'attrs': [\n      {\n        'tfName': 'keep_dims',\n        'name': 'keepDims',\n        'type': 'bool',\n        'notSupported': true\n      },\n      {'tfName': 'T', 'name': 'dtype', 'type': 'dtype', 'notSupported': true}\n    ]\n  },\n  {\n    'tfOpName': 'LeakyRelu',\n    'category': 'basic_math',\n    'inputs': [\n      {'start': 0, 'name': 'x', 'type': 'tensor'},\n    ],\n    'attrs': [\n      {\n        'tfName': 'alpha',\n        'name': 'alpha',\n        'type': 'number',\n        'defaultValue': 0.2\n      },\n      {\n        'tfName': 'T',\n        'name': 'dtype',\n        'type': 'dtype',\n        'notSupported': true\n      }\n    ]\n  }\n];\n","import {OpMapper} from '../types';\n\n/**\n * @license\n * Copyright 2018 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nexport const json: OpMapper[] = [\n  {\n    'tfOpName': 'LoopCond',\n    'category': 'control',\n    'inputs': [{'start': 0, 'name': 'pred', 'type': 'tensor'}]\n  },\n  {\n    'tfOpName': 'Switch',\n    'category': 'control',\n    'inputs': [\n      {'start': 0, 'name': 'data', 'type': 'tensor'},\n      {'start': 1, 'name': 'pred', 'type': 'tensor'}\n    ]\n  },\n  {\n    'tfOpName': 'Merge',\n    'category': 'control',\n    'inputs':\n        [{'start': 0, 'end': 0, 'name': 'tensors', 'type': 'tensors'}]\n  },\n  {\n    'tfOpName': 'Enter',\n    'category': 'control',\n    'inputs': [\n      {'start': 0, 'name': 'tensor', 'type': 'tensor'},\n    ],\n    'attrs': [\n      {'tfName': 'T', 'name': 'dtype', 'type': 'dtype', 'notSupported': true},\n      {'tfName': 'frame_name', 'name': 'frameName', 'type': 'string'},\n      {'tfName': 'is_constant', 'name': 'isConstant', 'type': 'bool'}\n    ]\n  },\n  {\n    'tfOpName': 'Exit',\n    'category': 'control',\n    'inputs': [\n      {'start': 0, 'name': 'tensor', 'type': 'tensor'},\n    ],\n    'attrs': [\n      {'tfName': 'T', 'name': 'dtype', 'type': 'dtype', 'notSupported': true}\n    ]\n  },\n  {\n    'tfOpName': 'NextIteration',\n    'category': 'control',\n    'inputs': [\n      {'start': 0, 'name': 'tensor', 'type': 'tensor'},\n    ],\n    'attrs': [\n      {'tfName': 'T', 'name': 'dtype', 'type': 'dtype', 'notSupported': true}\n    ]\n  },\n  {\n    'tfOpName': 'TensorArrayV3',\n    'category': 'control',\n    'inputs': [\n      {'start': 0, 'name': 'size', 'type': 'number'},\n    ],\n    'attrs': [\n      {'tfName': 'dtype', 'name': 'dtype', 'type': 'dtype'},\n      {'tfName': 'element_shape', 'name': 'elementShape', 'type': 'shape'},\n      {'tfName': 'dynamic_size', 'name': 'dynamicSize', 'type': 'bool'},\n      {'tfName': 'clear_after_read', 'name': 'clearAfterRead', 'type': 'bool'},\n      {\n        'tfName': 'identical_element_shapes',\n        'name': 'identicalElementShapes',\n        'type': 'bool'\n      },\n      {'tfName': 'tensor_array_name', 'name': 'name', 'type': 'string'}\n    ]\n  },\n  {\n    'tfOpName': 'TensorArrayWriteV3',\n    'category': 'control',\n    'inputs': [\n      {'start': 0, 'name': 'tensorArrayId', 'type': 'number'},\n      {'start': 1, 'name': 'index', 'type': 'number'},\n      {'start': 2, 'name': 'tensor', 'type': 'tensor'},\n      {'start': 3, 'name': 'flowIn', 'type': 'number'},\n    ],\n    'attrs': [\n      {'tfName': 'T', 'name': 'dtype', 'type': 'dtype', 'notSupported': true}\n    ]\n  },\n  {\n    'tfOpName': 'TensorArrayReadV3',\n    'category': 'control',\n    'inputs': [\n      {'start': 0, 'name': 'tensorArrayId', 'type': 'number'},\n      {'start': 1, 'name': 'index', 'type': 'number'},\n      {'start': 2, 'name': 'flowIn', 'type': 'number'},\n    ],\n    'attrs': [{\n      'tfName': 'dtype',\n      'name': 'dtype',\n      'type': 'dtype',\n      'notSupported': true\n    }]\n  },\n  {\n    'tfOpName': 'TensorArrayGatherV3',\n    'category': 'control',\n    'inputs': [\n      {'start': 0, 'name': 'tensorArrayId', 'type': 'number'},\n      {'start': 1, 'name': 'indices', 'type': 'number[]'},\n      {'start': 2, 'name': 'flowIn', 'type': 'number'},\n    ],\n    'attrs': [\n      {'tfName': 'dtype', 'name': 'dtype', 'type': 'dtype'},\n      {'tfName': 'element_shape', 'name': 'elementShape', 'type': 'shape'}\n    ]\n  },\n  {\n    'tfOpName': 'TensorArrayScatterV3',\n    'category': 'control',\n    'inputs': [\n      {'start': 0, 'name': 'tensorArrayId', 'type': 'number'},\n      {'start': 1, 'name': 'indices', 'type': 'number[]'},\n      {'start': 2, 'name': 'tensor', 'type': 'tensor'},\n      {'start': 3, 'name': 'flowIn', 'type': 'number'},\n    ],\n    'attrs': [{'tfName': 'T', 'name': 'dtype', 'type': 'dtype'}]\n  },\n  {\n    'tfOpName': 'TensorArrayConcatV3',\n    'category': 'control',\n    'inputs': [\n      {'start': 0, 'name': 'tensorArrayId', 'type': 'number'},\n      {'start': 1, 'name': 'flowIn', 'type': 'number'},\n    ],\n    'attrs': [\n      {'tfName': 'dtype', 'name': 'dtype', 'type': 'dtype'}, {\n        'tfName': 'element_shape_except0',\n        'name': 'elementShapeExcept0',\n        'type': 'shape',\n        'notSupported': true\n      }\n    ]\n  },\n  {\n    'tfOpName': 'TensorArraySplitV3',\n    'category': 'control',\n    'inputs': [\n      {'start': 0, 'name': 'tensorArrayId', 'type': 'number'},\n      {'start': 1, 'name': 'tensor', 'type': 'tensor'},\n      {'start': 2, 'name': 'lengths', 'type': 'number[]'},\n      {'start': 3, 'name': 'flowIn', 'type': 'number'},\n    ],\n    'attrs': [{'tfName': 'T', 'name': 'dtype', 'type': 'dtype'}]\n  },\n  {\n    'tfOpName': 'TensorArraySizeV3',\n    'category': 'control',\n    'inputs': [\n      {'start': 0, 'name': 'tensorArrayId', 'type': 'number'},\n      {'start': 1, 'name': 'flowIn', 'type': 'number'}\n    ]\n  },\n  {\n    'tfOpName': 'TensorArrayCloseV3',\n    'category': 'control',\n    'inputs': [{'start': 0, 'name': 'tensorArrayId', 'type': 'number'}]\n  }\n];\n","import {OpMapper} from '../types';\n\n/**\n * @license\n * Copyright 2018 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nexport const json: OpMapper[] = [\n  {\n    'tfOpName': 'AvgPool',\n    'category': 'convolution',\n    'inputs': [\n      {'start': 0, 'name': 'x', 'type': 'tensor'},\n    ],\n    'attrs': [\n      {'tfName': 'strides', 'name': 'strides', 'type': 'number[]'},\n      {'tfName': 'padding', 'name': 'pad', 'type': 'string'}, {\n        'tfName': 'data_format',\n        'name': 'dataFormat',\n        'type': 'string',\n        'notSupported': true\n      },\n      {'tfName': 'ksize', 'name': 'kernelSize', 'type': 'number[]'},\n      {'tfName': 'T', 'name': 'dtype', 'type': 'dtype', 'notSupported': true}\n    ]\n  },\n  {\n    'tfOpName': 'MaxPool',\n    'category': 'convolution',\n    'inputs': [\n      {'start': 0, 'name': 'x', 'type': 'tensor'},\n    ],\n    'attrs': [\n      {'tfName': 'strides', 'name': 'strides', 'type': 'number[]'},\n      {'tfName': 'padding', 'name': 'pad', 'type': 'string'}, {\n        'tfName': 'data_format',\n        'name': 'dataFormat',\n        'type': 'string',\n        'notSupported': true\n      },\n      {'tfName': 'ksize', 'name': 'kernelSize', 'type': 'number[]'},\n      {'tfName': 'T', 'name': 'dtype', 'type': 'dtype', 'notSupported': true}\n    ]\n  },\n  {\n    'tfOpName': 'AvgPool3D',\n    'category': 'convolution',\n    'inputs': [\n      {'start': 0, 'name': 'x', 'type': 'tensor'},\n    ],\n    'attrs': [\n      {'tfName': 'strides', 'name': 'strides', 'type': 'number[]'},\n      {'tfName': 'padding', 'name': 'pad', 'type': 'string'}, {\n        'tfName': 'data_format',\n        'name': 'dataFormat',\n        'type': 'string',\n        'notSupported': true\n      },\n      {'tfName': 'ksize', 'name': 'kernelSize', 'type': 'number[]'},\n      {'tfName': 'T', 'name': 'dtype', 'type': 'dtype', 'notSupported': true}\n    ]\n  },\n  {\n    'tfOpName': 'MaxPool3D',\n    'category': 'convolution',\n    'inputs': [\n      {'start': 0, 'name': 'x', 'type': 'tensor'},\n    ],\n    'attrs': [\n      {'tfName': 'strides', 'name': 'strides', 'type': 'number[]'},\n      {'tfName': 'padding', 'name': 'pad', 'type': 'string'}, {\n        'tfName': 'data_format',\n        'name': 'dataFormat',\n        'type': 'string',\n        'notSupported': true\n      },\n      {'tfName': 'ksize', 'name': 'kernelSize', 'type': 'number[]'},\n      {'tfName': 'T', 'name': 'dtype', 'type': 'dtype', 'notSupported': true}\n    ]\n  },\n  {\n    'tfOpName': 'Conv1D',\n    'category': 'convolution',\n    'inputs': [\n      {'start': 0, 'name': 'x', 'type': 'tensor'},\n      {'start': 1, 'name': 'filter', 'type': 'tensor'},\n    ],\n    'attrs': [\n      {'tfName': 'stride', 'name': 'stride', 'type': 'number'},\n      {'tfName': 'padding', 'name': 'pad', 'type': 'string'}, {\n        'tfName': 'data_format',\n        'name': 'dataFormat',\n        'type': 'string',\n        'defaultValue': 'NWC'\n      },\n      {'tfName': 'T', 'name': 'dtype', 'type': 'dtype', 'notSupported': true}, {\n        'tfName': 'dilation',\n        'name': 'dilation',\n        'type': 'number',\n        'defaultValue': 1\n      }\n    ]\n  },\n  {\n    'tfOpName': 'Conv2D',\n    'category': 'convolution',\n    'inputs': [\n      {'start': 0, 'name': 'x', 'type': 'tensor'},\n      {'start': 1, 'name': 'filter', 'type': 'tensor'},\n    ],\n    'attrs': [\n      {'tfName': 'T', 'name': 'dtype', 'type': 'dtype', 'notSupported': true},\n      {'tfName': 'strides', 'name': 'strides', 'type': 'number[]'},\n      {'tfName': 'padding', 'name': 'pad', 'type': 'string'},\n      {'tfName': 'useCudnnOnGpu', 'name': 'useCudnnOnGpu', 'type': 'bool'}, {\n        'tfName': 'data_format',\n        'name': 'dataFormat',\n        'type': 'string',\n        'defaultValue': 'NHWC'\n      },\n      {'tfName': 'dilations', 'name': 'dilations', 'type': 'number[]'}\n    ]\n  },\n  {\n    'tfOpName': 'Conv2DBackpropInput',\n    'category': 'convolution',\n    'inputs': [\n      {'start': 2, 'name': 'x', 'type': 'tensor'},\n      {'start': 1, 'name': 'filter', 'type': 'tensor'},\n      {'start': 0, 'name': 'outputShape', 'type': 'number[]'},\n    ],\n    'attrs': [\n      {'tfName': 'strides', 'name': 'strides', 'type': 'number[]'},\n      {'tfName': 'padding', 'name': 'pad', 'type': 'string'}, {\n        'tfName': 'data_format',\n        'name': 'dataFormat',\n        'type': 'string',\n        'notSupported': true\n      }\n    ]\n  },\n  {\n    'tfOpName': 'DepthwiseConv2d',\n    'category': 'convolution',\n    'inputs': [\n      {'start': 0, 'name': 'input', 'type': 'tensor'},\n      {'start': 1, 'name': 'filter', 'type': 'tensor'},\n    ],\n    'attrs': [\n      {'tfName': 'strides', 'name': 'strides', 'type': 'number[]'},\n      {'tfName': 'padding', 'name': 'pad', 'type': 'string'}, {\n        'tfName': 'data_format',\n        'name': 'dataFormat',\n        'type': 'string',\n        'defaultValue': 'NHWC'\n      },\n      {'tfName': 'dilations', 'name': 'dilations', 'type': 'number[]'}\n    ]\n  },\n  {\n    'tfOpName': 'DepthwiseConv2dNative',\n    'category': 'convolution',\n    'inputs': [\n      {'start': 0, 'name': 'input', 'type': 'tensor'},\n      {'start': 1, 'name': 'filter', 'type': 'tensor'},\n    ],\n    'attrs': [\n      {'tfName': 'strides', 'name': 'strides', 'type': 'number[]'},\n      {'tfName': 'padding', 'name': 'pad', 'type': 'string'}, {\n        'tfName': 'data_format',\n        'name': 'dataFormat',\n        'type': 'string',\n        'defaultValue': 'NHWC'\n      },\n      {'tfName': 'dilations', 'name': 'dilations', 'type': 'number[]'}\n    ]\n  },\n  {\n    'tfOpName': 'Conv3D',\n    'category': 'convolution',\n    'inputs': [\n      {'start': 0, 'name': 'x', 'type': 'tensor'},\n      {'start': 1, 'name': 'filter', 'type': 'tensor'},\n    ],\n    'attrs': [\n      {'tfName': 'strides', 'name': 'strides', 'type': 'number[]'},\n      {'tfName': 'padding', 'name': 'pad', 'type': 'string'}, {\n        'tfName': 'data_format',\n        'name': 'dataFormat',\n        'type': 'string',\n        'defaultValue': 'NHWC'\n      },\n      {'tfName': 'dilations', 'name': 'dilations', 'type': 'number[]'}\n    ],\n  }\n];\n","import {OpMapper} from '../types';\n\n/**\n * @license\n * Copyright 2018 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nexport const json: OpMapper[] = [\n  {\n    'tfOpName': 'Fill',\n    'category': 'creation',\n    'inputs': [\n      {'start': 0, 'name': 'shape', 'type': 'number[]'},\n      {'start': 1, 'name': 'value', 'type': 'number'},\n    ],\n    'attrs': [{'tfName': 'T', 'name': 'dtype', 'type': 'dtype'}]\n  },\n  {\n    'tfOpName': 'LinSpace',\n    'category': 'creation',\n    'inputs': [\n      {'start': 0, 'name': 'start', 'type': 'number'},\n      {'start': 1, 'name': 'stop', 'type': 'number'},\n      {'start': 2, 'name': 'num', 'type': 'number'},\n    ],\n    'attrs': [\n      {'tfName': 'T', 'name': 'dtype', 'type': 'dtype', 'notSupported': true}\n    ]\n  },\n  {\n    'tfOpName': 'OneHot',\n    'category': 'creation',\n    'inputs': [\n      {'start': 0, 'name': 'indices', 'type': 'tensor'},\n      {'start': 1, 'name': 'depth', 'type': 'number'},\n      {'start': 2, 'name': 'onValue', 'type': 'number', 'defaultValue': 1},\n      {'start': 3, 'name': 'offValue', 'type': 'number', 'defaultValue': 0},\n    ],\n    'attrs': [\n      {\n        'tfName': 'axis',\n        'name': 'axis',\n        'type': 'number',\n        'notSupported': true\n      },\n      {'tfName': 'T', 'name': 'dtype', 'type': 'dtype', 'notSupported': true}\n    ]\n  },\n  {\n    'tfOpName': 'Ones',\n    'category': 'creation',\n    'inputs': [\n      {'start': 0, 'name': 'shape', 'type': 'number[]'},\n    ],\n    'attrs': [{'tfName': 'T', 'name': 'dtype', 'type': 'dtype'}]\n  },\n  {\n    'tfOpName': 'OnesLike',\n    'category': 'creation',\n    'inputs': [\n      {'start': 0, 'name': 'x', 'type': 'tensor'},\n    ],\n    'attrs': [{'tfName': 'dtype', 'name': 'dtype', 'type': 'dtype'}]\n  },\n  {\n    'tfOpName': 'RandomUniform',\n    'category': 'creation',\n    'inputs': [\n      {'start': 0, 'name': 'shape', 'type': 'number[]'},\n    ],\n    'attrs': [\n      {\n        'tfName': 'minval',\n        'name': 'minval',\n        'type': 'number',\n        'defaultValue': 0\n      },\n      {\n        'tfName': 'maxval',\n        'name': 'maxval',\n        'type': 'number',\n        'defaultValue': 1\n      },\n      {'tfName': 'dtype', 'name': 'dtype', 'type': 'dtype'},\n      {'tfName': 'seed', 'name': 'seed', 'type': 'number', 'defaultValue': 0}, {\n        'tfName': 'seed2',\n        'name': 'seed2',\n        'type': 'number',\n        'defaultValue': 0,\n        'notSupported': true\n      },\n      {'tfName': 'T', 'name': 'T', 'type': 'number', 'notSupported': true}\n    ]\n  },\n  {\n    'tfOpName': 'Range',\n    'category': 'creation',\n    'inputs': [\n      {'start': 0, 'name': 'start', 'type': 'number'},\n      {'start': 1, 'name': 'stop', 'type': 'number'},\n      {'start': 2, 'name': 'step', 'type': 'number', 'defaultValue': 0},\n    ],\n    'attrs': [{'tfName': 'Tidx', 'name': 'dtype', 'type': 'dtype'}]\n  },\n  {\n    'tfOpName': 'TruncatedNormal',\n    'category': 'creation',\n    'inputs': [\n      {'start': 0, 'name': 'shape', 'type': 'number[]'},\n    ],\n    'attrs': [\n      {\n        'tfName': 'means',\n        'name': 'mean',\n        'type': 'number',\n        'defaultValue': 0.0\n      },\n      {\n        'tfName': 'stddev',\n        'name': 'stdDev',\n        'type': 'number',\n        'defaultValue': 1.0\n      },\n      {'tfName': 'seed', 'name': 'seed', 'type': 'number'}, {\n        'tfName': 'seed2',\n        'name': 'seed2',\n        'type': 'number',\n        'defaultValue': 0,\n        'notSupported': true\n      },\n      {'tfName': 'dtype', 'name': 'dtype', 'type': 'dtype'},\n      {'tfName': 'T', 'name': 'T', 'type': 'number', 'notSupported': true}\n    ]\n  },\n  {\n    'tfOpName': 'Zeros',\n    'category': 'creation',\n    'inputs': [\n      {'start': 0, 'name': 'shape', 'type': 'number[]'},\n    ],\n    'attrs': [{'tfName': 'T', 'name': 'dtype', 'type': 'dtype'}]\n  },\n  {\n    'tfOpName': 'ZerosLike',\n    'category': 'creation',\n    'inputs': [\n      {'start': 0, 'name': 'x', 'type': 'tensor'},\n    ],\n    'attrs': [{'tfName': 'T', 'name': 'dtype', 'type': 'dtype'}]\n  }\n];\n","import {OpMapper} from '../types';\n\n/**\n * @license\n * Copyright 2018 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nexport const json: OpMapper[] = [\n  {\n    'tfOpName': 'NonMaxSuppressionV2',\n    'category': 'dynamic',\n    'inputs': [\n      {'start': 0, 'name': 'boxes', 'type': 'tensor'},\n      {'start': 1, 'name': 'scores', 'type': 'tensor'},\n      {'start': 2, 'name': 'maxOutputSize', 'type': 'number'},\n      {'start': 3, 'name': 'iouThreshold', 'type': 'number'}\n    ]\n  },\n  {\n    'tfOpName': 'NonMaxSuppressionV3',\n    'category': 'dynamic',\n    'inputs': [\n      {'start': 0, 'name': 'boxes', 'type': 'tensor'},\n      {'start': 1, 'name': 'scores', 'type': 'tensor'},\n      {'start': 2, 'name': 'maxOutputSize', 'type': 'number'},\n      {'start': 3, 'name': 'iouThreshold', 'type': 'number'},\n      {'start': 4, 'name': 'scoreThreshold', 'type': 'number'}\n    ]\n  },\n  {\n    'tfOpName': 'Where',\n    'category': 'dynamic',\n    'inputs': [\n      {'start': 0, 'name': 'condition', 'type': 'tensor'},\n    ],\n    'attrs': [\n      {'tfName': 'T', 'name': 'dtype', 'type': 'dtype', 'notSupported': true}\n    ]\n  },\n  {\n    'tfOpName': 'ListDiff',\n    'category': 'dynamic',\n    'inputs': [\n      {'start': 0, 'name': 'x', 'type': 'tensor'},\n      {'start': 1, 'name': 'y', 'type': 'tensor'},\n    ],\n    'attrs': [{\n      'tfName': 'T',\n      'name': 'dtype',\n      'type': 'dtype',\n      'notSupported': true\n    }]\n  }\n];\n","import {OpMapper} from '../types';\n\n/**\n * @license\n * Copyright 2018 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nexport const json: OpMapper[] = [{\n  'tfOpName': 'TopKV2',\n  'category': 'evaluation',\n  'inputs': [\n    {'start': 0, 'name': 'x', 'type': 'tensor'},\n    {'start': 1, 'name': 'k', 'type': 'number'},\n  ],\n  'attrs': [{'tfName': 'sorted', 'name': 'sorted', 'type': 'bool'}]\n}];\n","import {OpMapper} from '../types';\n\n/**\n * @license\n * Copyright 2018 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nexport const json: OpMapper[] = [\n  {\n    'tfOpName': 'PlaceholderWithDefault',\n    'category': 'graph',\n    'inputs': [\n      {'start': 0, 'name': 'default', 'type': 'tensor'},\n    ],\n    'attrs': [\n      {'tfName': 'shape', 'name': 'shape', 'type': 'shape'},\n      {'tfName': 'dtype', 'name': 'dtype', 'type': 'dtype'}\n    ]\n  },\n  {\n    'tfOpName': 'Placeholder',\n    'category': 'graph',\n    'attrs': [\n      {'tfName': 'shape', 'name': 'shape', 'type': 'shape'},\n      {'tfName': 'dtype', 'name': 'dtype', 'type': 'dtype'}\n    ]\n  },\n  {'tfOpName': 'Const', 'category': 'graph'}, {\n    'tfOpName': 'Identity',\n    'category': 'graph',\n    'inputs': [{'start': 0, 'name': 'x', 'type': 'tensor'}]\n  },\n  {\n    'tfOpName': 'IdentityN',\n    'category': 'graph',\n    'inputs': [{'start': 0, 'end': 0, 'name': 'x', 'type': 'tensors'}]\n  },\n  {\n    'tfOpName': 'Snapshot',\n    'category': 'graph',\n    'inputs': [{'start': 0, 'name': 'x', 'type': 'tensor'}]\n  },\n  {\n    'tfOpName': 'Rank',\n    'category': 'graph',\n    'inputs': [{'start': 0, 'name': 'x', 'type': 'tensor'}]\n  },\n  {\n    'tfOpName': 'Size',\n    'category': 'graph',\n    'inputs': [{'start': 0, 'name': 'x', 'type': 'tensor'}]\n  },\n  {\n    'tfOpName': 'Shape',\n    'category': 'graph',\n    'inputs': [{'start': 0, 'name': 'x', 'type': 'tensor'}]\n  },\n  {\n    'tfOpName': 'ShapeN',\n    'category': 'graph',\n    'inputs': [{'start': 0, 'end': 0, 'name': 'x', 'type': 'tensors'}]\n  },\n  {\n    'tfOpName': 'Print',\n    'category': 'graph',\n    'inputs': [\n      {'start': 0, 'name': 'x', 'type': 'tensor'},\n      {'start': 1, 'name': 'data', 'type': 'tensors'},\n    ],\n    'attrs': [\n      {'tfName': 'message', 'name': 'message', 'type': 'string'}, {\n        'tfName': 'first_n',\n        'name': 'firstN',\n        'type': 'number',\n        'notSupported': true\n      },\n      {\n        'tfName': 'summarize',\n        'name': 'summarize',\n        'type': 'number',\n        'defaultValue': 3\n      }\n    ]\n  },\n  {'tfOpName': 'NoOp', 'category': 'graph', 'inputs': []}, {\n    'tfOpName': 'StopGradient',\n    'category': 'graph',\n    'inputs': [{'start': 0, 'name': 'x', 'type': 'tensor'}]\n  },\n  {\n    'tfOpName': 'FakeQuantWithMinMaxVars',\n    'category': 'graph',\n    'inputs': [\n      {'start': 0, 'name': 'x', 'type': 'tensor'},\n    ],\n    'attrs': [\n      {'tfName': 'min', 'name': 'min', 'type': 'number'},\n      {'tfName': 'max', 'name': 'max', 'type': 'number'}\n    ]\n  }\n];\n","import {OpMapper} from '../types';\n\n/**\n * @license\n * Copyright 2018 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nexport const json: OpMapper[] = [\n  {\n    'tfOpName': 'ResizeBilinear',\n    'category': 'image',\n    'inputs': [\n      {'start': 0, 'name': 'images', 'type': 'tensor'},\n      {'start': 1, 'name': 'size', 'type': 'number[]'},\n    ],\n    'attrs': [\n      {'tfName': 'align_corners', 'name': 'alignCorners', 'type': 'bool'},\n      {'tfName': 'T', 'name': 'dtype', 'type': 'dtype', 'notSupported': true}\n    ]\n  },\n  {\n    'tfOpName': 'ResizeNearestNeighbor',\n    'category': 'image',\n    'inputs': [\n      {'start': 0, 'name': 'images', 'type': 'tensor'},\n      {'start': 1, 'name': 'size', 'type': 'number[]'},\n    ],\n    'attrs': [\n      {'tfName': 'align_corners', 'name': 'alignCorners', 'type': 'bool'},\n      {'tfName': 'T', 'name': 'dtype', 'type': 'dtype', 'notSupported': true}\n    ]\n  },\n  {\n    'tfOpName': 'CropAndResize',\n    'category': 'image',\n    'inputs': [\n      {'start': 0, 'name': 'image', 'type': 'tensor'},\n      {'start': 1, 'name': 'boxes', 'type': 'tensor'},\n      {'start': 2, 'name': 'boxInd', 'type': 'tensor'},\n      {'start': 3, 'name': 'cropSize', 'type': 'number[]'},\n    ],\n    'attrs': [\n      {'tfName': 'method', 'name': 'method', 'type': 'string'}, {\n        'tfName': 'extrapolation_value',\n        'name': 'extrapolationValue',\n        'type': 'number'\n      }\n    ]\n  }\n];\n","import {OpMapper} from '../types';\n\n/**\n * @license\n * Copyright 2018 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nexport const json: OpMapper[] = [\n  {\n    'tfOpName': 'Equal',\n    'category': 'logical',\n    'inputs': [\n      {'start': 0, 'name': 'a', 'type': 'tensor'},\n      {'start': 1, 'name': 'b', 'type': 'tensor'},\n    ],\n    'attrs': [\n      {'tfName': 'T', 'name': 'dtype', 'type': 'dtype', 'notSupported': true}\n    ]\n  },\n  {\n    'tfOpName': 'NotEqual',\n    'category': 'logical',\n    'inputs': [\n      {'start': 0, 'name': 'a', 'type': 'tensor'},\n      {'start': 1, 'name': 'b', 'type': 'tensor'},\n    ],\n    'attrs': [\n      {'tfName': 'T', 'name': 'dtype', 'type': 'dtype', 'notSupported': true}\n    ]\n  },\n  {\n    'tfOpName': 'Greater',\n    'category': 'logical',\n    'inputs': [\n      {'start': 0, 'name': 'a', 'type': 'tensor'},\n      {'start': 1, 'name': 'b', 'type': 'tensor'},\n    ],\n    'attrs': [\n      {'tfName': 'T', 'name': 'dtype', 'type': 'dtype', 'notSupported': true}\n    ]\n  },\n  {\n    'tfOpName': 'GreaterEqual',\n    'category': 'logical',\n    'inputs': [\n      {'start': 0, 'name': 'a', 'type': 'tensor'},\n      {'start': 1, 'name': 'b', 'type': 'tensor'},\n    ],\n    'attrs': [\n      {'tfName': 'T', 'name': 'dtype', 'type': 'dtype', 'notSupported': true}\n    ]\n  },\n  {\n    'tfOpName': 'Less',\n    'category': 'logical',\n    'inputs': [\n      {'start': 0, 'name': 'a', 'type': 'tensor'},\n      {'start': 1, 'name': 'b', 'type': 'tensor'},\n    ],\n    'attrs': [\n      {'tfName': 'T', 'name': 'dtype', 'type': 'dtype', 'notSupported': true}\n    ]\n  },\n  {\n    'tfOpName': 'LessEqual',\n    'category': 'logical',\n    'inputs': [\n      {'start': 0, 'name': 'a', 'type': 'tensor'},\n      {'start': 1, 'name': 'b', 'type': 'tensor'},\n    ],\n    'attrs': [\n      {'tfName': 'T', 'name': 'dtype', 'type': 'dtype', 'notSupported': true}\n    ]\n  },\n  {\n    'tfOpName': 'LogicalAnd',\n    'category': 'logical',\n    'inputs': [\n      {'start': 0, 'name': 'a', 'type': 'tensor'},\n      {'start': 1, 'name': 'b', 'type': 'tensor'},\n    ],\n    'attrs': [\n      {'tfName': 'T', 'name': 'dtype', 'type': 'dtype', 'notSupported': true}\n    ]\n  },\n  {\n    'tfOpName': 'LogicalNot',\n    'category': 'logical',\n    'inputs': [\n      {'start': 0, 'name': 'a', 'type': 'tensor'},\n    ],\n    'attrs': [\n      {'tfName': 'T', 'name': 'dtype', 'type': 'dtype', 'notSupported': true}\n    ]\n  },\n  {\n    'tfOpName': 'LogicalOr',\n    'category': 'logical',\n    'inputs': [\n      {'start': 0, 'name': 'a', 'type': 'tensor'},\n      {'start': 1, 'name': 'b', 'type': 'tensor'},\n    ],\n    'attrs': [\n      {'tfName': 'T', 'name': 'dtype', 'type': 'dtype', 'notSupported': true}\n    ]\n  },\n  {\n    'tfOpName': 'Select',\n    'category': 'logical',\n    'inputs': [\n      {'start': 0, 'name': 'condition', 'type': 'tensor'},\n      {'start': 1, 'name': 'a', 'type': 'tensor'},\n      {'start': 2, 'name': 'b', 'type': 'tensor'},\n    ],\n    'attrs': [{\n      'tfName': 'T',\n      'name': 'dtype',\n      'type': 'dtype',\n      'notSupported': true\n    }]\n  }\n];\n","/**\n * @license\n * Copyright 2018 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {OpMapper} from '../types';\n\nexport const json: OpMapper[] = [\n  {\n    'tfOpName': 'MatMul',\n    'category': 'matrices',\n    'inputs': [\n      {'start': 0, 'name': 'a', 'type': 'tensor'},\n      {'start': 1, 'name': 'b', 'type': 'tensor'},\n    ],\n    'attrs': [\n      {\n        'tfName': 'transpose_a',\n        'name': 'transposeA',\n        'type': 'bool',\n        'defaultValue': false\n      },\n      {\n        'tfName': 'transpose_b',\n        'name': 'transposeB',\n        'type': 'bool',\n        'defaultValue': false\n      },\n      {'tfName': 'T', 'name': 'dtype', 'type': 'dtype', 'notSupported': true}\n    ]\n  },\n  {\n    'tfOpName': 'BatchMatMul',\n    'category': 'matrices',\n    'inputs': [\n      {'start': 0, 'name': 'a', 'type': 'tensor'},\n      {'start': 1, 'name': 'b', 'type': 'tensor'},\n    ],\n    'attrs': [\n      {\n        'tfName': 'adj_x',\n        'name': 'transposeA',\n        'type': 'bool',\n        'defaultValue': false\n      },\n      {\n        'tfName': 'adj_y',\n        'name': 'transposeB',\n        'type': 'bool',\n        'defaultValue': false\n      },\n      {'tfName': 'T', 'name': 'dtype', 'type': 'dtype', 'notSupported': true}\n    ]\n  },\n  {\n    'tfOpName': 'BatchMatMulV2',\n    'category': 'matrices',\n    'inputs': [\n      {'start': 0, 'name': 'a', 'type': 'tensor'},\n      {'start': 1, 'name': 'b', 'type': 'tensor'},\n    ],\n    'attrs': [\n      {\n        'tfName': 'adj_x',\n        'name': 'transposeA',\n        'type': 'bool',\n        'defaultValue': false\n      },\n      {\n        'tfName': 'adj_y',\n        'name': 'transposeB',\n        'type': 'bool',\n        'defaultValue': false\n      },\n      {'tfName': 'T', 'name': 'dtype', 'type': 'dtype', 'notSupported': true}\n    ]\n  },\n  {\n    'tfOpName': 'Transpose',\n    'category': 'matrices',\n    'inputs': [\n      {'start': 0, 'name': 'x', 'type': 'tensor'},\n      {'start': 1, 'name': 'perm', 'type': 'number[]'},\n    ],\n    'attrs': [{\n      'tfName': 'T',\n      'name': 'dtype',\n      'type': 'dtype',\n      'notSupported': true\n    }]\n  }\n];\n","import {OpMapper} from '../types';\n\n/**\n * @license\n * Copyright 2018 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nexport const json: OpMapper[] = [\n  {\n    'tfOpName': 'FusedBatchNorm',\n    'category': 'normalization',\n    'inputs': [\n      {'start': 0, 'name': 'x', 'type': 'tensor'},\n      {'start': 1, 'name': 'scale', 'type': 'tensor'},\n      {'start': 2, 'name': 'offset', 'type': 'tensor'},\n      {'start': 3, 'name': 'mean', 'type': 'tensor'},\n      {'start': 4, 'name': 'variance', 'type': 'tensor'},\n    ],\n    'attrs': [\n      {\n        'tfName': 'epsilon',\n        'name': 'epsilon',\n        'type': 'number',\n        'defaultValue': 0.001\n      },\n      {\n        'tfName': 'data_format',\n        'name': 'dataFormat',\n        'type': 'string',\n        'notSupported': true\n      }\n    ]\n  },\n  {\n    'tfOpName': 'FusedBatchNormV2',\n    'category': 'normalization',\n    'inputs': [\n      {'start': 0, 'name': 'x', 'type': 'tensor'},\n      {'start': 1, 'name': 'scale', 'type': 'tensor'},\n      {'start': 2, 'name': 'offset', 'type': 'tensor'},\n      {'start': 3, 'name': 'mean', 'type': 'tensor'},\n      {'start': 4, 'name': 'variance', 'type': 'tensor'},\n    ],\n    'attrs': [\n      {\n        'tfName': 'epsilon',\n        'name': 'epsilon',\n        'type': 'number',\n        'defaultValue': 0.001\n      },\n      {\n        'tfName': 'data_format',\n        'name': 'dataFormat',\n        'type': 'string',\n        'notSupported': true\n      }\n    ]\n  },\n  {\n    'tfOpName': 'FusedBatchNormV3',\n    'category': 'normalization',\n    'inputs': [\n      {'start': 0, 'name': 'x', 'type': 'tensor'},\n      {'start': 1, 'name': 'scale', 'type': 'tensor'},\n      {'start': 2, 'name': 'offset', 'type': 'tensor'},\n      {'start': 3, 'name': 'mean', 'type': 'tensor'},\n      {'start': 4, 'name': 'variance', 'type': 'tensor'},\n    ],\n    'attrs': [\n      {\n        'tfName': 'epsilon',\n        'name': 'epsilon',\n        'type': 'number',\n        'defaultValue': 0.001\n      },\n      {\n        'tfName': 'data_format',\n        'name': 'dataFormat',\n        'type': 'string',\n        'notSupported': true\n      }\n    ]\n  },\n  {\n    'tfOpName': 'LRN',\n    'category': 'normalization',\n    'inputs': [\n      {'start': 0, 'name': 'x', 'type': 'tensor'},\n    ],\n    'attrs': [\n      {\n        'tfName': 'depth_radius',\n        'name': 'radius',\n        'type': 'number',\n        'defaultValue': 5\n      },\n      {'tfName': 'bias', 'name': 'bias', 'type': 'number', 'defaultValue': 1.0},\n      {\n        'tfName': 'alpha',\n        'name': 'alpha',\n        'type': 'number',\n        'defaultValue': 1.0\n      },\n      {\n        'tfName': 'beta',\n        'name': 'beta',\n        'type': 'number',\n        'defaultValue': 0.5\n      }\n    ]\n  },\n  {\n    'tfOpName': 'Softmax',\n    'category': 'normalization',\n    'inputs': [{'start': 0, 'name': 'x', 'type': 'tensor'}]\n  },\n  {\n    'tfOpName': 'LogSoftmax',\n    'category': 'normalization',\n    'inputs': [{'start': 0, 'name': 'x', 'type': 'tensor'}]\n  },\n  {\n    'tfOpName': 'SparseToDense',\n    'category': 'normalization',\n    'inputs': [\n      {'start': 0, 'name': 'sparseIndices', 'type': 'tensor'},\n      {'start': 1, 'name': 'outputShape', 'type': 'number[]'},\n      {'start': 2, 'name': 'sparseValues', 'type': 'tensor'},\n      {'start': 3, 'name': 'defaultValue', 'type': 'tensor'},\n    ],\n    'attrs': [{\n      'tfName': 'validate_indices',\n      'name': 'validateIndices',\n      'type': 'bool',\n      'defaultValue': true,\n      'notSupported': true\n    }]\n  }\n];\n","import {OpMapper} from '../types';\n\n/**\n * @license\n * Copyright 2018 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nexport const json: OpMapper[] = [\n  {\n    'tfOpName': 'Max',\n    'category': 'reduction',\n    'inputs': [\n      {'start': 0, 'name': 'x', 'type': 'tensor'},\n      {'start': 1, 'name': 'axis', 'type': 'number[]'},\n    ],\n    'attrs': [{'tfName': 'keep_dims', 'name': 'keepDims', 'type': 'bool'}]\n  },\n  {\n    'tfOpName': 'Mean',\n    'category': 'reduction',\n    'inputs': [\n      {'start': 0, 'name': 'x', 'type': 'tensor'},\n      {'start': 1, 'name': 'axis', 'type': 'number[]'},\n    ],\n    'attrs': [{'tfName': 'keep_dims', 'name': 'keepDims', 'type': 'bool'}]\n  },\n  {\n    'tfOpName': 'Min',\n    'category': 'reduction',\n    'inputs': [\n      {'start': 0, 'name': 'x', 'type': 'tensor'},\n      {'start': 1, 'name': 'axis', 'type': 'number[]'},\n    ],\n    'attrs': [{'tfName': 'keep_dims', 'name': 'keepDims', 'type': 'bool'}]\n  },\n  {\n    'tfOpName': 'Sum',\n    'category': 'reduction',\n    'inputs': [\n      {'start': 0, 'name': 'x', 'type': 'tensor'},\n      {'start': 1, 'name': 'axis', 'type': 'number[]'},\n    ],\n    'attrs': [{'tfName': 'keep_dims', 'name': 'keepDims', 'type': 'bool'}]\n  },\n  {\n    'tfOpName': 'All',\n    'category': 'reduction',\n    'inputs': [\n      {'start': 0, 'name': 'x', 'type': 'tensor'},\n      {'start': 1, 'name': 'axis', 'type': 'number[]'},\n    ],\n    'attrs': [{'tfName': 'keep_dims', 'name': 'keepDims', 'type': 'bool'}]\n  },\n  {\n    'tfOpName': 'Any',\n    'category': 'reduction',\n    'inputs': [\n      {'start': 0, 'name': 'x', 'type': 'tensor'},\n      {'start': 1, 'name': 'axis', 'type': 'number[]'},\n    ],\n    'attrs': [{'tfName': 'keep_dims', 'name': 'keepDims', 'type': 'bool'}]\n  },\n  {\n    'tfOpName': 'ArgMax',\n    'category': 'reduction',\n    'inputs': [\n      {'start': 0, 'name': 'x', 'type': 'tensor'},\n      {'start': 1, 'name': 'axis', 'type': 'number'}\n    ]\n  },\n  {\n    'tfOpName': 'ArgMin',\n    'category': 'reduction',\n    'inputs': [\n      {'start': 0, 'name': 'x', 'type': 'tensor'},\n      {'start': 1, 'name': 'axis', 'type': 'number'}\n    ]\n  },\n  {\n    'tfOpName': 'Prod',\n    'category': 'reduction',\n    'inputs': [\n      {'start': 0, 'name': 'x', 'type': 'tensor'},\n      {'start': 1, 'name': 'axis', 'type': 'number[]'},\n    ],\n    'attrs': [{'tfName': 'keep_dims', 'name': 'keepDims', 'type': 'bool'}]\n  }\n];\n","import {OpMapper} from '../types';\n\n/**\n * @license\n * Copyright 2018 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nexport const json: OpMapper[] = [\n  {\n    'tfOpName': 'ConcatV2',\n    'category': 'slice_join',\n    'inputs': [\n      {'start': 0, 'end': -1, 'name': 'tensors', 'type': 'tensors'},\n      {'start': -1, 'name': 'axis', 'type': 'number'}\n    ]\n  },\n  {\n    'tfOpName': 'Concat',\n    'category': 'slice_join',\n    'inputs': [\n      {'start': 1, 'end': 0, 'name': 'tensors', 'type': 'tensors'},\n      {'start': 0, 'name': 'axis', 'type': 'number'}\n    ]\n  },\n  {\n    'tfOpName': 'GatherV2',\n    'category': 'slice_join',\n    'inputs': [\n      {'start': 0, 'name': 'x', 'type': 'tensor'},\n      {'start': 1, 'name': 'indices', 'type': 'tensor'},\n      {'start': 2, 'name': 'axis', 'type': 'number', 'defaultValue': 0}\n    ]\n  },\n  {\n    'tfOpName': 'Gather',\n    'category': 'slice_join',\n    'inputs': [\n      {'start': 0, 'name': 'x', 'type': 'tensor'},\n      {'start': 1, 'name': 'indices', 'type': 'tensor'},\n    ],\n    'attrs': [\n      {'tfName': 'axis', 'name': 'axis', 'type': 'number', 'defaultValue': 0}, {\n        'tfName': 'validate_indices',\n        'name': 'validateIndices',\n        'type': 'bool',\n        'notSupported': true\n      }\n    ]\n  },\n  {\n    'tfOpName': 'Reverse',\n    'category': 'slice_join',\n    'inputs': [\n      {'start': 0, 'name': 'x', 'type': 'tensor'},\n      {'start': 1, 'name': 'dims', 'type': 'bool', 'notSupported': true}\n    ]\n  },\n  {\n    'tfOpName': 'ReverseV2',\n    'category': 'slice_join',\n    'inputs': [\n      {'start': 0, 'name': 'x', 'type': 'tensor'},\n      {'start': 1, 'name': 'axis', 'type': 'number[]'}\n    ]\n  },\n  {\n    'tfOpName': 'Slice',\n    'category': 'slice_join',\n    'inputs': [\n      {'start': 0, 'name': 'x', 'type': 'tensor'},\n      {'start': 1, 'name': 'begin', 'type': 'number[]'},\n      {'start': 2, 'name': 'size', 'type': 'number[]'}\n    ]\n  },\n  {\n    'tfOpName': 'StridedSlice',\n    'category': 'slice_join',\n    'inputs': [\n      {'start': 0, 'name': 'x', 'type': 'tensor'},\n      {'start': 1, 'name': 'begin', 'type': 'number[]'},\n      {'start': 2, 'name': 'end', 'type': 'number[]'},\n      {'start': 3, 'name': 'strides', 'type': 'number[]'},\n    ],\n    'attrs': [\n      {\n        'tfName': 'begin_mask',\n        'name': 'beginMask',\n        'type': 'number',\n        'defaultValue': 0\n      },\n      {\n        'tfName': 'end_mask',\n        'name': 'endMask',\n        'type': 'number',\n        'defaultValue': 0\n      },\n      {\n        'tfName': 'new_axis_mask',\n        'name': 'newAxisMask',\n        'type': 'number',\n        'defaultValue': 0\n      },\n      {\n        'tfName': 'ellipsis_mask',\n        'name': 'ellipsisMask',\n        'type': 'number',\n        'defaultValue': 0\n      },\n      {\n        'tfName': 'shrink_axis_mask',\n        'name': 'shrinkAxisMask',\n        'type': 'number',\n        'defaultValue': 0\n      }\n    ]\n  },\n  {\n    'tfOpName': 'Pack',\n    'category': 'slice_join',\n    'inputs': [\n      {'start': 0, 'end': 0, 'name': 'tensors', 'type': 'tensors'},\n    ],\n    'attrs': [\n      {'tfName': 'axis', 'name': 'axis', 'type': 'number', 'defaultValue': 0}\n    ]\n  },\n  {\n    'tfOpName': 'Unpack',\n    'category': 'slice_join',\n    'inputs': [\n      {'start': 0, 'name': 'tensor', 'type': 'tensor'},\n    ],\n    'attrs': [\n      {'tfName': 'axis', 'name': 'axis', 'type': 'number', 'defaultValue': 0}, {\n        'tfName': 'num',\n        'name': 'num',\n        'type': 'number',\n        'defaultValue': 0,\n        'notSupported': true\n      }\n    ]\n  },\n  {\n    'tfOpName': 'Tile',\n    'category': 'slice_join',\n    'inputs': [\n      {'start': 0, 'name': 'x', 'type': 'tensor'},\n      {'start': 1, 'name': 'reps', 'type': 'number[]'}\n    ]\n  },\n  {\n    'tfOpName': 'Split',\n    'category': 'slice_join',\n    'inputs': [\n      {'start': 0, 'name': 'axis', 'type': 'number', 'defaultValue': 0},\n      {'start': 1, 'name': 'x', 'type': 'tensor'},\n    ],\n    'attrs': [{\n      'tfName': 'num_split',\n      'name': 'numOrSizeSplits',\n      'type': 'number',\n      'defaultValue': 1\n    }]\n  },\n  {\n    'tfOpName': 'SplitV',\n    'category': 'slice_join',\n    'inputs': [\n      {'start': 0, 'name': 'x', 'type': 'tensor'},\n      {'start': 1, 'name': 'numOrSizeSplits', 'type': 'number[]'},\n      {'start': 2, 'name': 'axis', 'type': 'number', 'defaultValue': 0}\n    ]\n  },\n  {\n    'tfOpName': 'ScatterNd',\n    'category': 'slice_join',\n    'inputs': [\n      {'start': 0, 'name': 'indices', 'type': 'tensor'},\n      {'start': 1, 'name': 'values', 'type': 'tensor'},\n      {'start': 2, 'name': 'shape', 'type': 'number[]'}\n    ]\n  },\n  {\n    'tfOpName': 'GatherNd',\n    'category': 'slice_join',\n    'inputs': [\n      {'start': 0, 'name': 'x', 'type': 'tensor'},\n      {'start': 1, 'name': 'indices', 'type': 'tensor'}\n    ]\n  },\n  {\n    'tfOpName': 'SparseToDense',\n    'category': 'slice_join',\n    'inputs': [\n      {'start': 0, 'name': 'sparseIndices', 'type': 'tensor'},\n      {'start': 1, 'name': 'outputShape', 'type': 'number[]'},\n      {'start': 2, 'name': 'sparseValues', 'type': 'tensor'},\n      {'start': 3, 'name': 'defaultValue', 'type': 'tensor'},\n    ],\n    'attrs': [{\n      'tfName': 'validate_indices',\n      'name': 'validateIndices',\n      'type': 'bool',\n      'defaultValue': false,\n      'notSupported': true\n    }]\n  }\n];\n","import {OpMapper} from '../types';\n\n/**\n * @license\n * Copyright 2018 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nexport const json: OpMapper[] = [\n  {\n    'tfOpName': 'FFT',\n    'category': 'spectral',\n    'inputs': [{'start': 0, 'name': 'x', 'type': 'tensor'}]\n  },\n  {\n    'tfOpName': 'IFFT',\n    'category': 'spectral',\n    'inputs': [{'start': 0, 'name': 'x', 'type': 'tensor'}]\n  },\n  {\n    'tfOpName': 'RFFT',\n    'category': 'spectral',\n    'inputs': [\n      {'start': 0, 'name': 'x', 'type': 'tensor'}, {\n        'start': 1,\n        'name': 'fft_length',\n        'type': 'number',\n        'notSupported': true\n      }\n    ]\n  },\n  {\n    'tfOpName': 'IRFFT',\n    'category': 'spectral',\n    'inputs': [\n      {'start': 0, 'name': 'x', 'type': 'tensor'}, {\n        'start': 1,\n        'name': 'fft_length',\n        'type': 'number',\n        'notSupported': true\n      }\n    ]\n  }\n];\n","import {OpMapper} from '../types';\n\n/**\n * @license\n * Copyright 2018 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nexport const json: OpMapper[] = [\n  {\n    'tfOpName': 'Cast',\n    'category': 'transformation',\n    'inputs': [\n      {'start': 0, 'name': 'x', 'type': 'tensor'},\n    ],\n    'attrs': [\n      {\n        'tfName': 'SrcT',\n        'name': 'sdtype',\n        'type': 'dtype',\n        'notSupported': true\n      },\n      {'tfName': 'DstT', 'name': 'dtype', 'type': 'dtype'}\n    ]\n  },\n  {\n    'tfOpName': 'ExpandDims',\n    'category': 'transformation',\n    'inputs': [\n      {'start': 0, 'name': 'x', 'type': 'tensor'},\n      {'start': 1, 'name': 'axis', 'type': 'number'}\n    ]\n  },\n  {\n    'tfOpName': 'Pad',\n    'category': 'transformation',\n    'inputs': [\n      {'start': 0, 'name': 'x', 'type': 'tensor'},\n      {'start': 1, 'name': 'padding', 'type': 'number[]'},\n    ],\n    'attrs': [{\n      'tfName': 'constant_value',\n      'name': 'constantValue',\n      'type': 'number',\n      'defaultValue': 0\n    }]\n  },\n  {\n    'tfOpName': 'PadV2',\n    'category': 'transformation',\n    'inputs': [\n      {'start': 0, 'name': 'x', 'type': 'tensor'},\n      {'start': 1, 'name': 'padding', 'type': 'number[]'}, {\n        'start': 2,\n        'name': 'constantValue',\n        'type': 'number',\n        'defaultValue': 0\n      }\n    ]\n  },\n  {\n    'tfOpName': 'Reshape',\n    'category': 'transformation',\n    'inputs': [\n      {'start': 0, 'name': 'x', 'type': 'tensor'},\n      {'start': 1, 'name': 'shape', 'type': 'number[]'}\n    ]\n  },\n  {\n    'tfOpName': 'Squeeze',\n    'category': 'transformation',\n    'inputs': [\n      {'start': 0, 'name': 'x', 'type': 'tensor'},\n    ],\n    'attrs': [{\n      'tfName': 'axis',\n      'tfDeprecatedName': 'squeeze_dims',\n      'name': 'axis',\n      'type': 'number[]'\n    }]\n  },\n  {\n    'tfOpName': 'SpaceToBatchND',\n    'category': 'transformation',\n    'inputs': [\n      {'start': 0, 'name': 'x', 'type': 'tensor'},\n      {'start': 1, 'name': 'blockShape', 'type': 'number[]'},\n      {'start': 2, 'name': 'paddings', 'type': 'number[]'}\n    ]\n  },\n  {\n    'tfOpName': 'BatchToSpaceND',\n    'category': 'transformation',\n    'inputs': [\n      {'start': 0, 'name': 'x', 'type': 'tensor'},\n      {'start': 1, 'name': 'blockShape', 'type': 'number[]'},\n      {'start': 2, 'name': 'crops', 'type': 'number[]'}\n    ]\n  },\n  {\n    'tfOpName': 'DepthToSpace',\n    'category': 'transformation',\n    'inputs': [\n      {'start': 0, 'name': 'x', 'type': 'tensor'},\n    ],\n    'attrs': [\n      {'tfName': 'block_size', 'name': 'blockSize', 'type': 'number'},\n      {'tfName': 'data_format', 'name': 'dataFormat', 'type': 'string'}\n    ]\n  }\n];\n","/**\n * @license\n * Copyright 2018 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {DataType, ENV} from '@tensorflow/tfjs-core';\n\nimport * as tensorflow from '../data/compiled_api';\nimport {getRegisteredOp} from './custom_op/register';\n\nimport {getNodeNameAndIndex} from './executors/utils';\nimport * as arithmetic from './op_list/arithmetic';\nimport * as basicMath from './op_list/basic_math';\nimport * as control from './op_list/control';\nimport * as convolution from './op_list/convolution';\nimport * as creation from './op_list/creation';\nimport * as dynamic from './op_list/dynamic';\nimport * as evaluation from './op_list/evaluation';\nimport * as graph from './op_list/graph';\nimport * as image from './op_list/image';\nimport * as logical from './op_list/logical';\nimport * as matrices from './op_list/matrices';\nimport * as normalization from './op_list/normalization';\nimport * as reduction from './op_list/reduction';\nimport * as sliceJoin from './op_list/slice_join';\nimport * as spectral from './op_list/spectral';\nimport * as transformation from './op_list/transformation';\nimport {Graph, InputParamValue, Node, OpMapper, ParamValue} from './types';\n\nexport class OperationMapper {\n  private static _instance: OperationMapper;\n\n  private opMappers: {[key: string]: OpMapper};\n\n  // Singleton instance for the mapper\n  public static get Instance() {\n    return this._instance || (this._instance = new this());\n  }\n\n  // Loads the op mapping from the JSON file.\n  private constructor() {\n    const ops = [\n      arithmetic, basicMath, control, convolution, creation, dynamic,\n      evaluation, logical, image, graph, matrices, normalization, reduction,\n      sliceJoin, spectral, transformation\n    ];\n    const mappersJson: OpMapper[] = [].concat.apply([], ops.map(op => op.json));\n\n    this.opMappers = mappersJson.reduce<{[key: string]: OpMapper}>(\n        (map, mapper: OpMapper) => {\n          map[mapper.tfOpName] = mapper;\n          return map;\n        },\n        {});\n  }\n\n  // Converts the model from Tensorflow GraphDef to local representation for\n  // TensorFlow.js API\n  transformGraph(graph: tensorflow.IGraphDef): Graph {\n    const tfNodes = graph.node;\n    const placeholders: Node[] = [];\n    const weights: Node[] = [];\n    const nodes = tfNodes.reduce<{[key: string]: Node}>((map, node) => {\n      map[node.name] = this.mapNode(node);\n      if (node.op === 'Placeholder') {\n        placeholders.push(map[node.name]);\n      }\n      if (node.op === 'Const') {\n        weights.push(map[node.name]);\n      }\n      return map;\n    }, {});\n\n    const inputs: Node[] = [];\n    const outputs: Node[] = [];\n    const allNodes = Object.keys(nodes);\n    allNodes.forEach(key => {\n      const node = nodes[key];\n      node.inputNames.forEach(name => {\n        const [nodeName, ] = getNodeNameAndIndex(name);\n        node.inputs.push(nodes[nodeName]);\n        nodes[nodeName].children.push(node);\n      });\n      if (node.inputs.length === 0) inputs.push(node);\n    });\n\n    allNodes.forEach(key => {\n      const node = nodes[key];\n      if (node.children.length === 0) outputs.push(node);\n    });\n\n    return {nodes, inputs, outputs, weights, placeholders};\n  }\n\n  private mapNode(node: tensorflow.INodeDef): Node {\n    // Unsupported ops will cause an error at run-time (not parse time), since\n    // they may not be used by the actual execution subgraph.\n    const mapper =\n        getRegisteredOp(node.op) || this.opMappers[node.op] || {} as OpMapper;\n    if (node.attr == null) {\n      node.attr = {};\n    }\n\n    const newNode: Node = {\n      name: node.name,\n      op: node.op,\n      category: mapper.category,\n      inputNames:\n          (node.input ||\n           []).map(input => input.startsWith('^') ? input.substr(1) : input),\n      inputs: [],\n      children: [],\n      inputParams: {},\n      attrParams: {},\n      rawAttrs: node.attr\n    };\n\n    if (mapper.inputs != null) {\n      newNode.inputParams =\n          mapper.inputs.reduce<{[key: string]: InputParamValue}>(\n              (map, param) => {\n                map[param.name] = {\n                  type: param.type,\n                  inputIndexStart: param.start,\n                  inputIndexEnd: param.end\n                };\n                return map;\n              },\n              {});\n    }\n    if (mapper.attrs != null) {\n      newNode.attrParams =\n          mapper.attrs.reduce<{[key: string]: ParamValue}>((map, param) => {\n            const type = param.type;\n            let value = undefined;\n            switch (param.type) {\n              case 'string':\n                value = getStringParam(\n                    node.attr, param.tfName, param.defaultValue as string);\n\n                if (value === undefined && !!param.tfDeprecatedName) {\n                  value = getStringParam(\n                      node.attr, param.tfDeprecatedName,\n                      param.defaultValue as string);\n                }\n                break;\n              case 'string[]':\n                value = getStringArrayParam(\n                    node.attr, param.tfName, param.defaultValue as string[]);\n\n                if (value === undefined && !!param.tfDeprecatedName) {\n                  value = getStringArrayParam(\n                      node.attr, param.tfDeprecatedName,\n                      param.defaultValue as string[]);\n                }\n                break;\n              case 'number':\n                value = getNumberParam(\n                    node.attr, param.tfName,\n                    (param.defaultValue || 0) as number);\n                if (value === undefined && !!param.tfDeprecatedName) {\n                  value = getNumberParam(\n                      node.attr, param.tfDeprecatedName,\n                      param.defaultValue as number);\n                }\n                break;\n              case 'number[]':\n                value = getNumericArrayParam(\n                    node.attr, param.tfName, param.defaultValue as number[]);\n                if (value === undefined && !!param.tfDeprecatedName) {\n                  value = getNumericArrayParam(\n                      node.attr, param.tfDeprecatedName,\n                      param.defaultValue as number[]);\n                }\n                break;\n              case 'bool':\n                value = getBoolParam(\n                    node.attr, param.tfName, param.defaultValue as boolean);\n                if (value === undefined && !!param.tfDeprecatedName) {\n                  value = getBoolParam(\n                      node.attr, param.tfDeprecatedName,\n                      param.defaultValue as boolean);\n                }\n                break;\n              case 'bool[]':\n                value = getBoolArrayParam(\n                    node.attr, param.tfName, param.defaultValue as boolean[]);\n                if (value === undefined && !!param.tfDeprecatedName) {\n                  value = getBoolArrayParam(\n                      node.attr, param.tfDeprecatedName,\n                      param.defaultValue as boolean[]);\n                }\n                break;\n              case 'shape':\n                value = getTensorShapeParam(\n                    node.attr, param.tfName, param.defaultValue as number[]);\n                if (value === undefined && !!param.tfDeprecatedName) {\n                  value = getTensorShapeParam(\n                      node.attr, param.tfDeprecatedName,\n                      param.defaultValue as number[]);\n                }\n                break;\n              case 'shape[]':\n                value = getTensorShapeArrayParam(\n                    node.attr, param.tfName, param.defaultValue as number[][]);\n                if (value === undefined && !!param.tfDeprecatedName) {\n                  value = getTensorShapeArrayParam(\n                      node.attr, param.tfDeprecatedName,\n                      param.defaultValue as number[][]);\n                }\n                break;\n              case 'dtype':\n                value = getDtypeParam(\n                    node.attr, param.tfName, param.defaultValue as DataType);\n                if (value === undefined && !!param.tfDeprecatedName) {\n                  value = getDtypeParam(\n                      node.attr, param.tfDeprecatedName,\n                      param.defaultValue as DataType);\n                }\n                break;\n              case 'dtype[]':\n                value = getDtypeArrayParam(\n                    node.attr, param.tfName, param.defaultValue as DataType[]);\n                if (value === undefined && !!param.tfDeprecatedName) {\n                  value = getDtypeArrayParam(\n                      node.attr, param.tfDeprecatedName,\n                      param.defaultValue as DataType[]);\n                }\n                break;\n              case 'tensor':\n              case 'tensors':\n                break;\n              default:\n                throw new Error(\n                    `Unsupported param type: ${param.type} for op: ${node.op}`);\n            }\n            map[param.name] = {value, type};\n            return map;\n          }, {});\n    }\n    return newNode;\n  }\n}\n\nexport function decodeBase64(text: string): string {\n  // tslint:disable-next-line:no-any\n  const global = ENV.global as any;\n  if (typeof global.atob !== 'undefined') {\n    return global.atob(text);\n  } else if (typeof Buffer !== 'undefined') {\n    return new Buffer(text, 'base64').toString();\n  } else {\n    throw new Error(\n        'Unable to decode base64 in this environment. ' +\n        'Missing built-in atob() or Buffer()');\n  }\n}\n\nexport function parseStringParam(s: []|string, keepCase: boolean): string {\n  const value =\n      Array.isArray(s) ? String.fromCharCode.apply(null, s) : decodeBase64(s);\n  return keepCase ? value : value.toLowerCase();\n}\n\nexport function getStringParam(\n    attrs: {[key: string]: tensorflow.IAttrValue}, name: string, def: string,\n    keepCase = false): string {\n  const param = attrs[name];\n  if (param != null) {\n    return parseStringParam(param.s, keepCase);\n  }\n  return def;\n}\n\nexport function getBoolParam(\n    attrs: {[key: string]: tensorflow.IAttrValue}, name: string,\n    def: boolean): boolean {\n  const param = attrs[name];\n  return param ? param.b : def;\n}\n\nexport function getNumberParam(\n    attrs: {[key: string]: tensorflow.IAttrValue}, name: string,\n    def: number): number {\n  const param = attrs[name] || {};\n  const value =\n      param['i'] != null ? param['i'] : (param['f'] != null ? param['f'] : def);\n  return (typeof value === 'number') ? value :\n                                       parseInt(value as string, 10) as number;\n}\n\nexport function parseDtypeParam(value: string|tensorflow.DataType): DataType {\n  if (typeof (value) === 'string') {\n    // tslint:disable-next-line:no-any\n    value = tensorflow.DataType[value as any];\n  }\n  switch (value) {\n    case tensorflow.DataType.DT_FLOAT:\n      return 'float32';\n    case tensorflow.DataType.DT_INT32:\n      return 'int32';\n    case tensorflow.DataType.DT_BOOL:\n      return 'bool';\n    case tensorflow.DataType.DT_DOUBLE:\n      return 'float32';\n    case tensorflow.DataType.DT_STRING:\n      return 'string';\n    default:\n      // Unknown dtype error will happen at runtime (instead of parse time),\n      // since these nodes might not be used by the actual subgraph execution.\n      return null;\n  }\n}\n\nexport function getDtypeParam(\n    attrs: {[key: string]: tensorflow.IAttrValue}, name: string,\n    def: DataType): DataType {\n  const param = attrs[name];\n  if (param && param.type) {\n    return parseDtypeParam(param.type);\n  }\n  return def;\n}\n\nexport function getDtypeArrayParam(\n    attrs: {[key: string]: tensorflow.IAttrValue}, name: string,\n    def: DataType[]): DataType[] {\n  const param = attrs[name];\n  if (param && param.list && param.list.type) {\n    return param.list.type.map(v => parseDtypeParam(v));\n  }\n  return def;\n}\n\nexport function parseTensorShapeParam(shape: tensorflow.ITensorShape): number[]|\n    undefined {\n  if (shape.unknownRank) {\n    return undefined;\n  }\n  if (shape.dim != null) {\n    return shape.dim.map(\n        dim => (typeof dim.size === 'number') ?\n            dim.size :\n            parseInt(dim.size as string, 10));\n  }\n  return [];\n}\n\nexport function getTensorShapeParam(\n    attrs: {[key: string]: tensorflow.IAttrValue}, name: string,\n    def?: number[]): number[]|undefined {\n  const param = attrs[name];\n  if (param && param.shape) {\n    return parseTensorShapeParam(param.shape);\n  }\n  return def;\n}\n\nexport function getNumericArrayParam(\n    attrs: {[key: string]: tensorflow.IAttrValue}, name: string,\n    def: number[]): number[] {\n  const param = attrs[name];\n  if (param) {\n    return ((param.list.f && param.list.f.length ? param.list.f : param.list.i) || [])\n               .map(\n                   v => (typeof v === 'number') ? v :\n                                                  parseInt(v as string, 10)) as\n        number[];\n  }\n  return def;\n}\n\nexport function getStringArrayParam(\n    attrs: {[key: string]: tensorflow.IAttrValue}, name: string, def: string[],\n    keepCase = false): string[] {\n  const param = attrs[name];\n  if (param && param.list && param.list.s) {\n    return param.list.s.map((v) => {\n      return parseStringParam(v, keepCase);\n    }) as string[];\n  }\n  return def;\n}\n\nexport function getTensorShapeArrayParam(\n    attrs: {[key: string]: tensorflow.IAttrValue}, name: string,\n    def: number[][]): number[][] {\n  const param = attrs[name];\n  if (param && param.list && param.list.shape) {\n    return param.list.shape.map((v) => {\n      return parseTensorShapeParam(v);\n    }) as number[][];\n  }\n  return def;\n}\n\nexport function getBoolArrayParam(\n    attrs: {[key: string]: tensorflow.IAttrValue}, name: string,\n    def: boolean[]): boolean[] {\n  const param = attrs[name];\n  if (param && param.list && param.list.b) {\n    return param.list.b;\n  }\n  return def;\n}\n","/**\n * @license\n * Copyright 2019 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {DataType, Tensor} from '@tensorflow/tfjs-core';\n\nimport {NamedTensorsMap} from '../../data/types';\nimport {ExecutionContext} from '../../executor/execution_context';\nimport {getTensor} from '../executors/utils';\nimport {getBoolArrayParam, getBoolParam, getDtypeArrayParam, getDtypeParam, getNumberParam, getNumericArrayParam, getStringArrayParam, getStringParam, getTensorShapeArrayParam, getTensorShapeParam} from '../operation_mapper';\nimport {GraphNode, Node, ValueType} from '../types';\n\n/**\n * Helper class for lookup inputs and params for nodes in the model graph.\n */\nexport class NodeValueImpl implements GraphNode {\n  public readonly inputs: Tensor[] = [];\n  public readonly attrs: {[key: string]: ValueType} = {};\n  constructor(\n      private node: Node, private tensorMap: NamedTensorsMap,\n      private context: ExecutionContext) {\n    this.inputs = node.inputNames.map(name => this.getInput(name));\n    if (node.rawAttrs != null) {\n      this.attrs = Object.keys(node.rawAttrs)\n                       .reduce((attrs: {[key: string]: ValueType}, key) => {\n                         attrs[key] = this.getAttr(key);\n                         return attrs;\n                       }, {});\n    }\n  }\n\n  /**\n   * Return the value of the attribute or input param.\n   * @param name String: name of attribute or input param.\n   */\n  private getInput(name: string): Tensor {\n    return getTensor(name, this.tensorMap, this.context);\n  }\n\n  /**\n   * Return the value of the attribute or input param.\n   * @param name String: name of attribute or input param.\n   */\n  private getAttr(name: string, defaultValue?: ValueType): ValueType {\n    const value = this.node.rawAttrs[name];\n    if (value.tensor != null) {\n      return getTensor(name, this.tensorMap, this.context);\n    }\n    if (value.i != null || value.f != null) {\n      return getNumberParam(this.node.rawAttrs, name, defaultValue as number);\n    }\n    if (value.s != null) {\n      return getStringParam(this.node.rawAttrs, name, defaultValue as string);\n    }\n    if (value.b != null) {\n      return getBoolParam(this.node.rawAttrs, name, defaultValue as boolean);\n    }\n    if (value.shape != null) {\n      return getTensorShapeParam(\n          this.node.rawAttrs, name, defaultValue as number[]);\n    }\n    if (value.type != null) {\n      return getDtypeParam(this.node.rawAttrs, name, defaultValue as DataType);\n    }\n    if (value.list != null) {\n      if (value.list.i != null || value.list.f != null) {\n        return getNumericArrayParam(\n            this.node.rawAttrs, name, defaultValue as number[]);\n      }\n      if (value.list.s != null) {\n        return getStringArrayParam(\n            this.node.rawAttrs, name, defaultValue as string[]);\n      }\n      if (value.list.shape != null) {\n        return getTensorShapeArrayParam(\n            this.node.rawAttrs, name, defaultValue as number[][]);\n      }\n      if (value.list.b != null) {\n        return getBoolArrayParam(\n            this.node.rawAttrs, name, defaultValue as boolean[]);\n      }\n      if (value.list.type != null) {\n        return getDtypeArrayParam(\n            this.node.rawAttrs, name, defaultValue as DataType[]);\n      }\n    }\n\n    return defaultValue;\n  }\n}\n","/**\n * @license\n * Copyright 2018 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport * as tfc from '@tensorflow/tfjs-core';\n\nimport {NamedTensorsMap} from '../../data/types';\nimport {ExecutionContext} from '../../executor/execution_context';\nimport {InternalOpExecutor, Node} from '../types';\n\nimport {getParamValue} from './utils';\n\nexport let executeOp: InternalOpExecutor = (node: Node,\n                                            tensorMap: NamedTensorsMap,\n                                            context: ExecutionContext):\n                                               tfc.Tensor[] => {\n  switch (node.op) {\n    case 'BiasAdd':\n    case 'AddV2':\n    case 'Add': {\n      return [tfc.add(\n          (getParamValue('a', node, tensorMap, context) as tfc.Tensor),\n          getParamValue('b', node, tensorMap, context) as tfc.Tensor)];\n    }\n    case 'AddN': {\n      return [tfc.addN((\n          getParamValue('tensors', node, tensorMap, context) as tfc.Tensor[]))];\n    }\n    case 'FloorMod':\n    case 'Mod':\n      return [tfc.mod(\n          getParamValue('a', node, tensorMap, context) as tfc.Tensor,\n          getParamValue('b', node, tensorMap, context) as tfc.Tensor)];\n    case 'Mul':\n      return [tfc.mul(\n          getParamValue('a', node, tensorMap, context) as tfc.Tensor,\n          getParamValue('b', node, tensorMap, context) as tfc.Tensor)];\n    case 'RealDiv':\n    case 'Div': {\n      return [tfc.div(\n          getParamValue('a', node, tensorMap, context) as tfc.Tensor,\n          getParamValue('b', node, tensorMap, context) as tfc.Tensor)];\n    }\n    case 'FloorDiv': {\n      return [tfc.floorDiv(\n          getParamValue('a', node, tensorMap, context) as tfc.Tensor,\n          getParamValue('b', node, tensorMap, context) as tfc.Tensor)];\n    }\n    case 'Sub': {\n      return [tfc.sub(\n          getParamValue('a', node, tensorMap, context) as tfc.Tensor,\n          getParamValue('b', node, tensorMap, context) as tfc.Tensor)];\n    }\n    case 'Minimum': {\n      return [tfc.minimum(\n          getParamValue('a', node, tensorMap, context) as tfc.Tensor,\n          getParamValue('b', node, tensorMap, context) as tfc.Tensor)];\n    }\n    case 'Maximum': {\n      return [tfc.maximum(\n          getParamValue('a', node, tensorMap, context) as tfc.Tensor,\n          getParamValue('b', node, tensorMap, context) as tfc.Tensor)];\n    }\n    case 'Pow': {\n      return [tfc.pow(\n          getParamValue('a', node, tensorMap, context) as tfc.Tensor,\n          getParamValue('b', node, tensorMap, context) as tfc.Tensor)];\n    }\n    case 'SquaredDifference': {\n      return [tfc.squaredDifference(\n          getParamValue('a', node, tensorMap, context) as tfc.Tensor,\n          getParamValue('b', node, tensorMap, context) as tfc.Tensor)];\n    }\n    default:\n      throw TypeError(`Node type ${node.op} is not implemented`);\n  }\n};\n\nexport const CATEGORY = 'arithmetic';\n","/**\n * @license\n * Copyright 2018 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport * as tfc from '@tensorflow/tfjs-core';\n\nimport {NamedTensorsMap} from '../../data/types';\nimport {ExecutionContext} from '../../executor/execution_context';\nimport {InternalOpExecutor, Node} from '../types';\n\nimport {getParamValue, getTensor} from './utils';\n\nexport let executeOp: InternalOpExecutor = (node: Node,\n                                            tensorMap: NamedTensorsMap,\n                                            context: ExecutionContext):\n                                               tfc.Tensor[] => {\n  switch (node.op) {\n    case 'Abs':\n    case 'ComplexAbs':\n      return [tfc.abs(\n          getParamValue('x', node, tensorMap, context) as tfc.Tensor)];\n    case 'Acos':\n      return [tfc.acos(\n          getParamValue('x', node, tensorMap, context) as tfc.Tensor)];\n    case 'Acosh':\n      return [tfc.acosh(\n          getParamValue('x', node, tensorMap, context) as tfc.Tensor)];\n    case 'Asin':\n      return [tfc.asin(\n          getParamValue('x', node, tensorMap, context) as tfc.Tensor)];\n    case 'Asinh':\n      return [tfc.asinh(\n          getParamValue('x', node, tensorMap, context) as tfc.Tensor)];\n    case 'Atan':\n      return [tfc.atan(\n          getParamValue('x', node, tensorMap, context) as tfc.Tensor)];\n    case 'Atan2':\n      return [tfc.atan2(\n          getParamValue('x', node, tensorMap, context) as tfc.Tensor,\n          getParamValue('y', node, tensorMap, context) as tfc.Tensor)];\n    case 'Atanh':\n      return [tfc.atanh(\n          getParamValue('x', node, tensorMap, context) as tfc.Tensor)];\n    case 'Ceil':\n      return [tfc.ceil(\n          getParamValue('x', node, tensorMap, context) as tfc.Tensor)];\n    case 'Complex':\n      return [tfc.complex(\n          getParamValue('real', node, tensorMap, context) as tfc.Tensor,\n          getParamValue('imag', node, tensorMap, context) as tfc.Tensor)];\n    case 'Cos':\n      return [tfc.cos(\n          getParamValue('x', node, tensorMap, context) as tfc.Tensor)];\n    case 'Cosh':\n      return [tfc.cosh(\n          getParamValue('x', node, tensorMap, context) as tfc.Tensor)];\n    case 'Elu':\n      return [tfc.elu(\n          getParamValue('x', node, tensorMap, context) as tfc.Tensor)];\n    case 'Erf':\n      return [tfc.erf(\n          getParamValue('x', node, tensorMap, context) as tfc.Tensor)];\n    case 'Exp':\n      return [tfc.exp(\n          getParamValue('x', node, tensorMap, context) as tfc.Tensor)];\n    case 'Expm1': {\n      return [tfc.expm1(\n          getParamValue('x', node, tensorMap, context) as tfc.Tensor)];\n    }\n    case 'Floor':\n      return [tfc.floor(\n          getParamValue('x', node, tensorMap, context) as tfc.Tensor)];\n    case 'Log':\n      return [tfc.log(\n          getParamValue('x', node, tensorMap, context) as tfc.Tensor)];\n    case 'Log1p': {\n      return [tfc.log1p(\n          getParamValue('x', node, tensorMap, context) as tfc.Tensor)];\n    }\n    case 'Imag':\n      return [tfc.imag(\n          getParamValue('x', node, tensorMap, context) as tfc.Tensor)];\n\n    case 'Neg':\n      return [tfc.neg(\n          getParamValue('x', node, tensorMap, context) as tfc.Tensor)];\n    case 'Reciprocal': {\n      return [tfc.reciprocal(\n          getParamValue('x', node, tensorMap, context) as tfc.Tensor)];\n    }\n    case 'Real':\n      return [tfc.real(\n          getParamValue('x', node, tensorMap, context) as tfc.Tensor)];\n    case 'Relu':\n      return [tfc.relu(\n          getParamValue('x', node, tensorMap, context) as tfc.Tensor)];\n    case 'Round': {\n      return [tfc.round(\n          getParamValue('x', node, tensorMap, context) as tfc.Tensor)];\n    }\n    case 'Selu':\n      return [tfc.selu(\n          getParamValue('x', node, tensorMap, context) as tfc.Tensor)];\n    case 'Sigmoid':\n      return [tfc.sigmoid(\n          getParamValue('x', node, tensorMap, context) as tfc.Tensor)];\n    case 'Sin':\n      return [tfc.sin(\n          getParamValue('x', node, tensorMap, context) as tfc.Tensor)];\n    case 'Sign': {\n      return [tfc.sign(\n          getParamValue('x', node, tensorMap, context) as tfc.Tensor)];\n    }\n    case 'Sinh': {\n      return [tfc.sinh(\n          getParamValue('x', node, tensorMap, context) as tfc.Tensor)];\n    }\n    case 'Softplus': {\n      return [tfc.softplus(\n          getParamValue('x', node, tensorMap, context) as tfc.Tensor)];\n    }\n    case 'Sqrt': {\n      return [tfc.sqrt(\n          getParamValue('x', node, tensorMap, context) as tfc.Tensor)];\n    }\n    case 'Square': {\n      return [tfc.square(\n          getParamValue('x', node, tensorMap, context) as tfc.Tensor)];\n    }\n    case 'Tanh': {\n      return [tfc.tanh(\n          getParamValue('x', node, tensorMap, context) as tfc.Tensor)];\n    }\n    case 'Tan':\n      return [tfc.tan(\n          getParamValue('x', node, tensorMap, context) as tfc.Tensor)];\n    case 'Relu6':\n    case 'ClipByValue':\n      return [tfc.clipByValue(\n          getParamValue('x', node, tensorMap, context) as tfc.Tensor,\n          getParamValue('clipValueMin', node, tensorMap, context) as number,\n          getParamValue('clipValueMax', node, tensorMap, context) as number)];\n    case 'Rsqrt':\n      return [tfc.rsqrt(getTensor(node.inputNames[0], tensorMap, context))];\n    case 'Prod':\n      return [tfc.prod(\n          getParamValue('x', node, tensorMap, context) as tfc.Tensor,\n          getParamValue('axes', node, tensorMap, context) as number[])];\n    case 'LeakyRelu':\n      return [tfc.leakyRelu(\n          getParamValue('x', node, tensorMap, context) as tfc.Tensor,\n          getParamValue('alpha', node, tensorMap, context) as number)];\n    default:\n      throw TypeError(`Node type ${node.op} is not implemented`);\n  }\n};\n\nexport const CATEGORY = 'basic_math';\n","/**\n * @license\n * Copyright 2018 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n// tslint:disable-next-line:max-line-length\nimport {concat, DataType, slice, stack, Tensor, tensor, tidy, unstack, util} from '@tensorflow/tfjs-core';\n\nexport interface TensorWithState {\n  tensor?: Tensor;\n  written?: boolean;\n  read?: boolean;\n  cleared?: boolean;\n}\n/**\n * The TensorArray object keeps an array of Tensors.  It\n * allows reading from the array and writing to the array.\n */\nexport class TensorArray {\n  private static nextId = 0;\n  private tensors: TensorWithState[] = [];\n  private closed_ = false;\n  readonly id: number;\n  constructor(\n      public readonly name: string, public readonly dtype: DataType,\n      private maxSize: number, private elementShape: number[],\n      public readonly identicalElementShapes: boolean,\n      public readonly dynamicSize: boolean,\n      public readonly clearAfterRead: boolean) {\n    this.id = TensorArray.nextId++;\n  }\n\n  get closed() {\n    return this.closed_;\n  }\n\n  /**\n   * Close the current TensorArray.\n   */\n  clearAndClose() {\n    this.tensors.forEach(tensor => tensor.tensor.dispose());\n    this.tensors = [];\n    this.closed_ = true;\n  }\n\n  size(): number {\n    return this.tensors.length;\n  }\n\n  /**\n   * Read the value at location index in the TensorArray.\n   * @param index Number the index to read from.\n   */\n  read(index: number): Tensor {\n    if (this.closed_) {\n      throw new Error(`TensorArray ${this.name} has already been closed.`);\n    }\n\n    if (index < 0 || index >= this.tensors.length) {\n      throw new Error(`Tried to read from index ${index}, but array size is: ${\n          this.tensors.length}`);\n    }\n\n    const tensorWithState = this.tensors[index];\n    if (tensorWithState.cleared) {\n      throw new Error(\n          `TensorArray ${this.name}: Could not read index ${\n              index} twice because it was cleared after a previous read ` +\n          `(perhaps try setting clear_after_read = false?).`);\n    }\n\n    if (this.clearAfterRead) {\n      tensorWithState.cleared = true;\n    }\n\n    tensorWithState.read = true;\n    return tensorWithState.tensor;\n  }\n\n  /**\n   * Helper method to read multiple tensors from the specified indices.\n   */\n  readMany(indices: number[]): Tensor[] {\n    return indices.map(index => this.read(index));\n  }\n\n  /**\n   * Write value into the index of the TensorArray.\n   * @param index number the index to write to.\n   * @param tensor\n   */\n  write(index: number, tensor: Tensor) {\n    if (this.closed_) {\n      throw new Error(`TensorArray ${this.name} has already been closed.`);\n    }\n\n    if (index < 0 || !this.dynamicSize && index >= this.maxSize) {\n      throw new Error(`Tried to write to index ${\n          index}, but array is not resizeable and size is: ${this.maxSize}`);\n    }\n\n    const t = this.tensors[index] || {};\n\n    if (tensor.dtype !== this.dtype) {\n      throw new Error(`TensorArray ${\n          this.name}: Could not write to TensorArray index ${index},\n          because the value dtype is ${\n          tensor.dtype}, but TensorArray dtype is ${this.dtype}.`);\n    }\n\n    // Set the shape for the first time write to unknow shape tensor array\n    if (this.size() === 0 &&\n        (this.elementShape == null || this.elementShape.length === 0)) {\n      this.elementShape = tensor.shape;\n    }\n\n    this.assertShapesMatchAllowUndefinedSize(\n        this.elementShape, tensor.shape,\n        `TensorArray ${this.name}: Could not write to TensorArray index ${\n            index}.`);\n\n    if (t && t.read) {\n      throw new Error(\n          `TensorArray ${this.name}: Could not write to TensorArray index ${\n              index}, because it has already been read.`);\n    }\n\n    if (t && t.written) {\n      throw new Error(\n          `TensorArray ${this.name}: Could not write to TensorArray index ${\n              index}, because it has already been written.`);\n    }\n\n    t.tensor = tensor;\n    t.written = true;\n\n    this.tensors[index] = t;\n  }\n\n  /**\n   * Helper method to write multiple tensors to the specified indices.\n   */\n  writeMany(indices: number[], tensors: Tensor[]) {\n    if (indices.length !== tensors.length) {\n      throw new Error(\n          `TensorArray ${this.name}: could not write multiple tensors,` +\n          `because the index size: ${\n              indices.length} is not the same as tensors size: ${\n              tensors.length}.`);\n    }\n\n    indices.forEach((i, index) => this.write(i, tensors[index]));\n  }\n\n  /**\n   * Return selected values in the TensorArray as a packed Tensor. All of\n   * selected values must have been written and their shapes must all match.\n   * @param [indices] number[] Optional. Taking values in [0, max_value). If the\n   *    TensorArray is not dynamic, max_value=size(). If not specified returns\n   *    all tensors in the original order.\n   * @param [dtype]\n   */\n  gather(indices?: number[], dtype?: DataType): Tensor {\n    if (!!dtype && dtype !== this.dtype) {\n      throw new Error(`TensorArray dtype is ${\n          this.dtype} but gather requested dtype ${dtype}`);\n    }\n\n    if (!indices) {\n      indices = [];\n      for (let i = 0; i < this.size(); i++) {\n        indices.push(i);\n      }\n    }\n\n    if (indices.length === 0) {\n      return tensor([], [0].concat(this.elementShape));\n    }\n\n    // Read all the PersistentTensors into a vector to keep track of\n    // their memory.\n    const tensors = this.readMany(indices);\n\n    this.assertShapesMatchAllowUndefinedSize(\n        this.elementShape, tensors[0].shape, 'TensorArray shape mismatch: ');\n\n    return stack(tensors, 0);\n  }\n\n  /**\n   * Return the values in the TensorArray as a concatenated Tensor.\n   */\n  concat(dtype?: DataType): Tensor {\n    if (!!dtype && dtype !== this.dtype) {\n      throw new Error(`TensorArray dtype is ${\n          this.dtype} but concat requested dtype ${dtype}`);\n    }\n\n    if (this.size() === 0) {\n      return tensor([], [0].concat(this.elementShape));\n    }\n\n    const indices = [];\n    for (let i = 0; i < this.size(); i++) {\n      indices.push(i);\n    }\n    // Collect all the tensors from the tensors array.\n    const tensors = this.readMany(indices);\n\n    this.assertShapesMatchAllowUndefinedSize(\n        this.elementShape, tensors[0].shape,\n        `TensorArray shape mismatch: tensor array shape (${\n            this.elementShape}) vs first tensor shape (${tensors[0].shape})`);\n\n    return concat(tensors, 0);\n  }\n\n  /**\n   * Scatter the values of a Tensor in specific indices of a TensorArray.\n   * @param indices nummber[] values in [0, max_value). If the\n   *    TensorArray is not dynamic, max_value=size().\n   * @param tensor Tensor input tensor.\n   */\n  scatter(indices: number[], tensor: Tensor) {\n    if (tensor.dtype !== this.dtype) {\n      throw new Error(`TensorArray dtype is ${\n          this.dtype} but tensor has dtype ${tensor.dtype}`);\n    }\n\n    if (indices.length !== tensor.shape[0]) {\n      throw new Error(`Expected len(indices) == tensor.shape[0], but saw: ${\n          indices.length} vs. ${tensor.shape[0]}`);\n    }\n\n    const maxIndex = Math.max(...indices);\n\n    if (!this.dynamicSize && maxIndex >= this.maxSize) {\n      throw new Error(\n          `Max index must be < array size (${maxIndex}  vs. ${this.maxSize})`);\n    }\n\n    this.writeMany(indices, unstack(tensor, 0));\n  }\n\n  /**\n   * Split the values of a Tensor into the TensorArray.\n   * @param length number[] with the lengths to use when splitting value along\n   *    its first dimension.\n   * @param tensor Tensor, the tensor to split.\n   */\n  split(length: number[], tensor: Tensor) {\n    if (tensor.dtype !== this.dtype) {\n      throw new Error(`TensorArray dtype is ${\n          this.dtype} but tensor has dtype ${tensor.dtype}`);\n    }\n    let totalLength = 0;\n    const cumulativeLengths = length.map(len => {\n      totalLength += len;\n      return totalLength;\n    });\n\n    if (totalLength !== tensor.shape[0]) {\n      throw new Error(`Expected sum of lengths to be equal to\n          tensor.shape[0], but sum of lengths is\n        ${totalLength}, and tensor's shape is: ${tensor.shape}`);\n    }\n\n    if (!this.dynamicSize && length.length !== this.maxSize) {\n      throw new Error(\n          `TensorArray's size is not equal to the size of lengths (${\n              this.maxSize} vs. ${length.length}), ` +\n          'and the TensorArray is not marked as dynamically resizeable');\n    }\n\n    const elementPerRow = totalLength === 0 ? 0 : tensor.size / totalLength;\n    const tensors: Tensor[] = [];\n    tidy(() => {\n      tensor = tensor.reshape([1, totalLength, elementPerRow]);\n      for (let i = 0; i < length.length; ++i) {\n        const previousLength = (i === 0) ? 0 : cumulativeLengths[i - 1];\n        const indices = [0, previousLength, 0];\n        const sizes = [1, length[i], elementPerRow];\n        tensors[i] = slice(tensor, indices, sizes).reshape(this.elementShape);\n      }\n      return tensors;\n    });\n    const indices = [];\n    for (let i = 0; i < length.length; i++) {\n      indices[i] = i;\n    }\n    this.writeMany(indices, tensors);\n  }\n\n  /**\n   * This differs from util.assertShapesMatch in that it allows values of\n   * negative one, an undefined size of a dimensinon, in a shape to match\n   * anything.\n   */\n  private assertShapesMatchAllowUndefinedSize(\n      shapeA: number[], shapeB: number[], errorMessagePrefix = ''): void {\n    util.assert(\n        this.shapesEqualAllowUndefinedSize(shapeA, shapeB),\n        () =>\n            errorMessagePrefix + ` Shapes ${shapeA} and ${shapeB} must match`);\n  }\n\n  private shapesEqualAllowUndefinedSize(n1: number[], n2: number[]) {\n    if (n1.length !== n2.length) {\n      return false;\n    }\n    for (let i = 0; i < n1.length; i++) {\n      if (n1[i] !== -1 && n2[i] !== -1 && n1[i] !== n2[i]) {\n        return false;\n      }\n    }\n    return true;\n  }\n}\n","/**\n * @license\n * Copyright 2018 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport * as tfc from '@tensorflow/tfjs-core';\n\nimport {NamedTensorsMap} from '../../data/types';\nimport {ExecutionContext} from '../../executor/execution_context';\nimport {InternalOpExecutor, Node} from '../types';\n\nimport {getParamValue} from './utils';\n\nexport let executeOp: InternalOpExecutor =\n    (node: Node, tensorMap: NamedTensorsMap,\n     context: ExecutionContext): tfc.Tensor[] => {\n      switch (node.op) {\n        case 'Conv1D': {\n          const stride =\n              getParamValue('stride', node, tensorMap, context) as number;\n          const pad = getParamValue('pad', node, tensorMap, context);\n          const dataFormat =\n              (getParamValue('dataFormat', node, tensorMap, context) as string)\n                  .toUpperCase();\n          const dilation =\n              getParamValue('dilation', node, tensorMap, context) as number;\n          return [tfc.conv1d(\n              getParamValue('x', node, tensorMap, context) as tfc.Tensor3D,\n              getParamValue('filter', node, tensorMap, context) as tfc.Tensor3D,\n              stride, pad as 'valid' | 'same', dataFormat as 'NWC' | 'NCW',\n              dilation)];\n        }\n        case 'Conv2D': {\n          const stride =\n              getParamValue('strides', node, tensorMap, context) as number[];\n          const pad = getParamValue('pad', node, tensorMap, context);\n          const dataFormat =\n              (getParamValue('dataFormat', node, tensorMap, context) as string)\n                  .toUpperCase();\n          const dilations =\n              getParamValue('dilations', node, tensorMap, context) as number[];\n          return [tfc.conv2d(\n              getParamValue('x', node, tensorMap, context) as tfc.Tensor3D |\n                  tfc.Tensor4D,\n              getParamValue('filter', node, tensorMap, context) as tfc.Tensor4D,\n              [stride[1], stride[2]], pad as 'valid' | 'same',\n              dataFormat as 'NHWC' | 'NCHW', [dilations[1], dilations[2]])];\n        }\n        case 'Conv2DBackpropInput':\n        case 'Conv2dTranspose': {\n          const shape = getParamValue(\n                            'outputShape', node, tensorMap,\n                            context) as [number, number, number] |\n              [number, number, number, number];\n          const stride =\n              getParamValue('strides', node, tensorMap, context) as number[];\n          const pad = getParamValue('pad', node, tensorMap, context);\n          return [tfc.conv2dTranspose(\n              getParamValue('x', node, tensorMap, context) as tfc.Tensor3D |\n                  tfc.Tensor4D,\n              getParamValue('filter', node, tensorMap, context) as tfc.Tensor4D,\n              shape, [stride[1], stride[2]], pad as 'valid' | 'same')];\n        }\n        case 'DepthwiseConv2dNative':\n        case 'DepthwiseConv2d': {\n          const stride =\n              getParamValue('strides', node, tensorMap, context) as number[];\n          const pad = getParamValue('pad', node, tensorMap, context);\n          const dilations =\n              getParamValue('dilations', node, tensorMap, context) as number[];\n          const dataFormat =\n              (getParamValue('dataFormat', node, tensorMap, context) as string)\n                  .toUpperCase();\n\n          return [tfc.depthwiseConv2d(\n              getParamValue('input', node, tensorMap, context) as tfc.Tensor3D |\n                  tfc.Tensor4D,\n              getParamValue('filter', node, tensorMap, context) as tfc.Tensor4D,\n              [stride[1], stride[2]], pad as 'valid' | 'same',\n              dataFormat as 'NHWC' | 'NCHW', [dilations[1], dilations[2]])];\n        }\n        case 'Conv3D': {\n          const stride =\n              getParamValue('strides', node, tensorMap, context) as number[];\n          const pad = getParamValue('pad', node, tensorMap, context);\n          const dataFormat =\n              (getParamValue('dataFormat', node, tensorMap, context) as string)\n                  .toUpperCase();\n          const dilations =\n              getParamValue('dilations', node, tensorMap, context) as number[];\n          return [tfc.conv3d(\n              getParamValue('x', node, tensorMap, context) as tfc.Tensor4D |\n                  tfc.Tensor<tfc.Rank.R5>,\n              getParamValue('filter', node, tensorMap, context) as\n                  tfc.Tensor<tfc.Rank.R5>,\n              [stride[1], stride[2], stride[3]], pad as 'valid' | 'same',\n              dataFormat as 'NDHWC' | 'NCDHW',\n              [dilations[1], dilations[2], dilations[3]])];\n        }\n\n        case 'AvgPool': {\n          const stride =\n              getParamValue('strides', node, tensorMap, context) as number[];\n          const pad = getParamValue('pad', node, tensorMap, context);\n          const kernelSize =\n              getParamValue('kernelSize', node, tensorMap, context) as number[];\n\n          return [tfc.avgPool(\n              getParamValue('x', node, tensorMap, context) as tfc.Tensor3D |\n                  tfc.Tensor4D,\n              [kernelSize[1], kernelSize[2]], [stride[1], stride[2]],\n              pad as 'valid' | 'same')];\n        }\n\n        case 'MaxPool': {\n          const stride =\n              getParamValue('strides', node, tensorMap, context) as number[];\n          const pad = getParamValue('pad', node, tensorMap, context);\n          const kernelSize =\n              getParamValue('kernelSize', node, tensorMap, context) as number[];\n\n          return [tfc.maxPool(\n              getParamValue('x', node, tensorMap, context) as tfc.Tensor3D |\n                  tfc.Tensor4D,\n              [kernelSize[1], kernelSize[2]], [stride[1], stride[2]],\n              pad as 'valid' | 'same')];\n        }\n\n        case 'AvgPool3D': {\n          const stride =\n              getParamValue('strides', node, tensorMap, context) as number[];\n          const pad = getParamValue('pad', node, tensorMap, context);\n          const kernelSize =\n              getParamValue('kernelSize', node, tensorMap, context) as number[];\n\n          return [tfc.avgPool3d(\n              getParamValue('x', node, tensorMap, context) as tfc.Tensor5D,\n              [kernelSize[1], kernelSize[2], kernelSize[3]],\n              [stride[1], stride[2], stride[3]], pad as 'valid' | 'same')];\n        }\n\n        case 'MaxPool3D': {\n          const stride =\n              getParamValue('strides', node, tensorMap, context) as number[];\n          const pad = getParamValue('pad', node, tensorMap, context);\n          const kernelSize =\n              getParamValue('kernelSize', node, tensorMap, context) as number[];\n\n          return [tfc.maxPool3d(\n              getParamValue('x', node, tensorMap, context) as tfc.Tensor5D,\n              [kernelSize[1], kernelSize[2], kernelSize[3]],\n              [stride[1], stride[2], stride[3]], pad as 'valid' | 'same')];\n        }\n\n        default:\n          throw TypeError(`Node type ${node.op} is not implemented`);\n      }\n    };\n\nexport const CATEGORY = 'convolution';\n","/**\n * @license\n * Copyright 2018 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport * as tfc from '@tensorflow/tfjs-core';\n\nimport {NamedTensorsMap} from '../../data/types';\nimport {ExecutionContext} from '../../executor/execution_context';\nimport {InternalOpExecutor, Node} from '../types';\n\nimport {getParamValue} from './utils';\n\nexport let executeOp: InternalOpExecutor = (node: Node,\n                                            tensorMap: NamedTensorsMap,\n                                            context: ExecutionContext):\n                                               tfc.Tensor[] => {\n  switch (node.op) {\n    case 'Fill': {\n      const shape =\n          getParamValue('shape', node, tensorMap, context) as number[];\n      const dtype =\n          getParamValue('dtype', node, tensorMap, context) as tfc.DataType;\n      const value = getParamValue('value', node, tensorMap, context) as number;\n      return [tfc.fill(shape, value, dtype)];\n    }\n    case 'LinSpace': {\n      const start = getParamValue('start', node, tensorMap, context) as number;\n      const stop = getParamValue('stop', node, tensorMap, context) as number;\n      const num = getParamValue('num', node, tensorMap, context) as number;\n      return [tfc.linspace(start, stop, num)];\n    }\n    case 'OneHot': {\n      const indices =\n          getParamValue('indices', node, tensorMap, context) as tfc.Tensor1D;\n      const depth = getParamValue('depth', node, tensorMap, context) as number;\n      const onValue =\n          getParamValue('onValue', node, tensorMap, context) as number;\n      const offValue =\n          getParamValue('offValue', node, tensorMap, context) as number;\n      return [tfc.oneHot(indices, depth, onValue, offValue)];\n    }\n    case 'Ones': {\n      return [tfc.ones(\n          getParamValue('shape', node, tensorMap, context) as number[],\n          getParamValue('dtype', node, tensorMap, context) as tfc.DataType)];\n    }\n    case 'OnesLike': {\n      return [tfc.onesLike(\n          getParamValue('x', node, tensorMap, context) as tfc.Tensor)];\n    }\n    case 'RandomUniform': {\n      return [tfc.randomUniform(\n          // tslint:disable-next-line:no-any\n          getParamValue('shape', node, tensorMap, context) as any,\n          getParamValue('minval', node, tensorMap, context) as number,\n          getParamValue('maxval', node, tensorMap, context) as number,\n          getParamValue('dtype', node, tensorMap, context) as tfc.DataType)];\n    }\n    case 'Range': {\n      const start = getParamValue('start', node, tensorMap, context) as number;\n      const stop = getParamValue('stop', node, tensorMap, context) as number;\n      const step = getParamValue('step', node, tensorMap, context) as number;\n      return [tfc.range(\n          start, stop, step,\n          getParamValue('dtype', node, tensorMap, context) as 'float32' |\n              'int32')];\n    }\n    case 'TruncatedNormal': {\n      const shape =\n          getParamValue('shape', node, tensorMap, context) as number[];\n      const mean = getParamValue('mean', node, tensorMap, context) as number;\n      const stdDev =\n          getParamValue('stdDev', node, tensorMap, context) as number;\n      const seed = getParamValue('seed', node, tensorMap, context) as number;\n      return [tfc.truncatedNormal(\n          shape, mean, stdDev,\n          getParamValue('dtype', node, tensorMap, context) as 'float32' |\n              'int32',\n          seed)];\n    }\n    case 'Zeros': {\n      return [tfc.zeros(\n          getParamValue('shape', node, tensorMap, context) as number[],\n          getParamValue('dtype', node, tensorMap, context) as tfc.DataType)];\n    }\n    case 'ZerosLike': {\n      return [tfc.zerosLike(\n          getParamValue('x', node, tensorMap, context) as tfc.Tensor)];\n    }\n    default:\n      throw TypeError(`Node type ${node.op} is not implemented`);\n  }\n};\n\nexport const CATEGORY = 'creation';\n","/**\n * @license\n * Copyright 2018 Google Inc. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport * as tfc from '@tensorflow/tfjs-core';\n\nimport {NamedTensorsMap} from '../../data/types';\nimport {ExecutionContext} from '../../executor/execution_context';\nimport {InternalOpExecutor, Node} from '../types';\n\nimport {getParamValue} from './utils';\n\nexport let executeOp: InternalOpExecutor =\n    (node: Node, tensorMap: NamedTensorsMap,\n     context: ExecutionContext): tfc.Tensor[] => {\n      switch (node.op) {\n        case 'TopKV2': {\n          const x = getParamValue('x', node, tensorMap, context) as tfc.Tensor;\n          const k = getParamValue('k', node, tensorMap, context) as number;\n          const sorted =\n              getParamValue('sorted', node, tensorMap, context) as boolean;\n          const result = tfc.topk(x, k, sorted);\n          return [result.values, result.indices];\n        }\n        default:\n          throw TypeError(`Node type ${node.op} is not implemented`);\n      }\n    };\n\nexport const CATEGORY = 'evaluation';\n","/**\n * @license\n * Copyright 2018 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport * as tfc from '@tensorflow/tfjs-core';\n\nimport {NamedTensorsMap} from '../../data/types';\nimport {ExecutionContext} from '../../executor/execution_context';\nimport {InternalOpExecutor, Node} from '../types';\n\nimport {getParamValue, getTensor} from './utils';\n\nexport let executeOp: InternalOpExecutor = (node: Node,\n                                            tensorMap: NamedTensorsMap,\n                                            context: ExecutionContext):\n                                               tfc.Tensor[] => {\n  switch (node.op) {\n    case 'Const': {\n      return tensorMap[node.name];\n    }\n    case 'PlaceholderWithDefault':\n      const def =\n          getParamValue('default', node, tensorMap, context) as tfc.Tensor;\n      return [getTensor(node.name, tensorMap, context) || def];\n    case 'Placeholder':\n      return [getTensor(node.name, tensorMap, context)];\n    case 'Identity':\n    case 'StopGradient':\n    case 'FakeQuantWithMinMaxVars':  // This op is currently ignored.\n      return [\n        (getParamValue('x', node, tensorMap, context) as tfc.Tensor).clone()\n      ];\n    case 'IdentityN':\n      return (getParamValue('x', node, tensorMap, context) as tfc.Tensor[])\n          .map((t: tfc.Tensor) => t.clone());\n    case 'Snapshot':\n      const snapshot =\n          (getParamValue('x', node, tensorMap, context) as tfc.Tensor);\n      return [snapshot.clone()];\n    case 'Shape':\n      return [tfc.tensor1d(\n          (getParamValue('x', node, tensorMap, context) as tfc.Tensor).shape,\n          'int32')];\n    case 'ShapeN':\n      return (getParamValue('x', node, tensorMap, context) as tfc.Tensor[])\n          .map((t: tfc.Tensor) => tfc.tensor1d(t.shape));\n    case 'Size':\n      return [tfc.scalar(\n          (getParamValue('x', node, tensorMap, context) as tfc.Tensor).size,\n          'int32')];\n    case 'Rank':\n      return [tfc.scalar(\n          (getParamValue('x', node, tensorMap, context) as tfc.Tensor).rank,\n          'int32')];\n    case 'NoOp':\n      return [];\n    case 'Print':\n      const input = getParamValue('x', node, tensorMap, context) as tfc.Tensor;\n      const data =\n          getParamValue('data', node, tensorMap, context) as tfc.Tensor[];\n      const message =\n          getParamValue('message', node, tensorMap, context) as string;\n      const summarize =\n          getParamValue('summarize', node, tensorMap, context) as number;\n      console.warn(\n          'The graph has a tf.print() operation,' +\n          'usually used for debugging, which slows down performance.');\n      console.log(message);\n      for (let i = 0; i < data.length; i++) {\n        console.log(\n            Array.prototype.slice.call(data[i].dataSync()).slice(0, summarize));\n      }\n      return [input];\n\n    default:\n      throw TypeError(`Node type ${node.op} is not implemented`);\n  }\n};\n\nexport const CATEGORY = 'graph';\n","/**\n * @license\n * Copyright 2018 Google Inc. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport * as tfc from '@tensorflow/tfjs-core';\n\nimport {NamedTensorsMap} from '../../data/types';\nimport {ExecutionContext} from '../../executor/execution_context';\nimport {InternalOpExecutor, Node} from '../types';\n\nimport {getParamValue} from './utils';\n\nexport let executeOp: InternalOpExecutor = (node: Node,\n                                            tensorMap: NamedTensorsMap,\n                                            context: ExecutionContext):\n                                               tfc.Tensor[] => {\n  switch (node.op) {\n    case 'ResizeBilinear': {\n      const images =\n          getParamValue('images', node, tensorMap, context) as tfc.Tensor;\n      const size = getParamValue('size', node, tensorMap, context) as number[];\n      const alignCorners =\n          getParamValue('alignCorners', node, tensorMap, context) as boolean;\n      return [tfc.image.resizeBilinear(\n          images as tfc.Tensor3D | tfc.Tensor4D, [size[0], size[1]],\n          alignCorners)];\n    }\n    case 'ResizeNearestNeighbor': {\n      const images =\n          getParamValue('images', node, tensorMap, context) as tfc.Tensor;\n      const size = getParamValue('size', node, tensorMap, context) as number[];\n      const alignCorners =\n          getParamValue('alignCorners', node, tensorMap, context) as boolean;\n      return [tfc.image.resizeNearestNeighbor(\n          images as tfc.Tensor3D | tfc.Tensor4D, [size[0], size[1]],\n          alignCorners)];\n    }\n    case 'CropAndResize': {\n      const image =\n          getParamValue('image', node, tensorMap, context) as tfc.Tensor;\n      const boxes =\n          getParamValue('boxes', node, tensorMap, context) as tfc.Tensor;\n      const boxInd =\n          getParamValue('boxInd', node, tensorMap, context) as tfc.Tensor;\n      const cropSize =\n          getParamValue('cropSize', node, tensorMap, context) as number[];\n      const method =\n          getParamValue('method', node, tensorMap, context) as string;\n      const extrapolationValue =\n          getParamValue('extrapolationValue', node, tensorMap, context) as\n          number;\n      return [tfc.image.cropAndResize(\n          image as tfc.Tensor4D, boxes as tfc.Tensor2D, boxInd as tfc.Tensor1D,\n          cropSize as [number, number], method as 'bilinear' | 'nearest',\n          extrapolationValue)];\n    }\n    default:\n      throw TypeError(`Node type ${node.op} is not implemented`);\n  }\n};\n\nexport const CATEGORY = 'image';\n","/**\n * @license\n * Copyright 2018 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport * as tfc from '@tensorflow/tfjs-core';\n\nimport {NamedTensorsMap} from '../../data/types';\nimport {ExecutionContext} from '../../executor/execution_context';\nimport {InternalOpExecutor, Node} from '../types';\n\nimport {getParamValue} from './utils';\n\nexport let executeOp: InternalOpExecutor = (node: Node,\n                                            tensorMap: NamedTensorsMap,\n                                            context: ExecutionContext):\n                                               tfc.Tensor[] => {\n  switch (node.op) {\n    case 'Equal': {\n      return [tfc.equal(\n          getParamValue('a', node, tensorMap, context) as tfc.Tensor,\n          getParamValue('b', node, tensorMap, context) as tfc.Tensor)];\n    }\n    case 'NotEqual': {\n      return [tfc.notEqual(\n          getParamValue('a', node, tensorMap, context) as tfc.Tensor,\n          getParamValue('b', node, tensorMap, context) as tfc.Tensor)];\n    }\n    case 'Greater': {\n      return [tfc.greater(\n          getParamValue('a', node, tensorMap, context) as tfc.Tensor,\n          getParamValue('b', node, tensorMap, context) as tfc.Tensor)];\n    }\n    case 'GreaterEqual': {\n      return [tfc.greaterEqual(\n          getParamValue('a', node, tensorMap, context) as tfc.Tensor,\n          getParamValue('b', node, tensorMap, context) as tfc.Tensor)];\n    }\n    case 'Less': {\n      return [tfc.less(\n          getParamValue('a', node, tensorMap, context) as tfc.Tensor,\n          getParamValue('b', node, tensorMap, context) as tfc.Tensor)];\n    }\n    case 'LessEqual': {\n      return [tfc.lessEqual(\n          getParamValue('a', node, tensorMap, context) as tfc.Tensor,\n          getParamValue('b', node, tensorMap, context) as tfc.Tensor)];\n    }\n    case 'LogicalAnd': {\n      return [tfc.logicalAnd(\n          getParamValue('a', node, tensorMap, context) as tfc.Tensor,\n          getParamValue('b', node, tensorMap, context) as tfc.Tensor)];\n    }\n    case 'LogicalNot': {\n      return [tfc.logicalNot(\n          getParamValue('a', node, tensorMap, context) as tfc.Tensor)];\n    }\n    case 'LogicalOr': {\n      return [tfc.logicalOr(\n          getParamValue('a', node, tensorMap, context) as tfc.Tensor,\n          getParamValue('b', node, tensorMap, context) as tfc.Tensor)];\n    }\n    case 'Select': {\n      return [tfc.where(\n          getParamValue('condition', node, tensorMap, context) as tfc.Tensor,\n          getParamValue('a', node, tensorMap, context) as tfc.Tensor,\n          getParamValue('b', node, tensorMap, context) as tfc.Tensor)];\n    }\n    default:\n      throw TypeError(`Node type ${node.op} is not implemented`);\n  }\n};\n\nexport const CATEGORY = 'logical';\n","/**\n * @license\n * Copyright 2018 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport * as tfc from '@tensorflow/tfjs-core';\n\nimport {NamedTensorsMap} from '../../data/types';\nimport {ExecutionContext} from '../../executor/execution_context';\nimport {InternalOpExecutor, Node} from '../types';\n\nimport {getParamValue} from './utils';\n\nexport let executeOp: InternalOpExecutor = (node: Node,\n                                            tensorMap: NamedTensorsMap,\n                                            context: ExecutionContext):\n                                               tfc.Tensor[] => {\n  switch (node.op) {\n    case 'BatchMatMul':\n    case 'BatchMatMulV2':\n    case 'MatMul':\n      return [tfc.matMul(\n          getParamValue('a', node, tensorMap, context) as tfc.Tensor2D,\n          getParamValue('b', node, tensorMap, context) as tfc.Tensor2D,\n          getParamValue('transposeA', node, tensorMap, context) as boolean,\n          getParamValue('transposeB', node, tensorMap, context) as boolean)];\n    case 'Transpose':\n      return [tfc.transpose(\n          getParamValue('x', node, tensorMap, context) as tfc.Tensor,\n          getParamValue('perm', node, tensorMap, context) as number[])];\n\n    default:\n      throw TypeError(`Node type ${node.op} is not implemented`);\n  }\n};\n\nexport const CATEGORY = 'matrices';\n","/**\n * @license\n * Copyright 2018 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport * as tfc from '@tensorflow/tfjs-core';\n\nimport {NamedTensorsMap} from '../../data/types';\nimport {ExecutionContext} from '../../executor/execution_context';\nimport {InternalOpExecutor, Node} from '../types';\n\nimport {getParamValue} from './utils';\n\nexport let executeOp: InternalOpExecutor = (node: Node,\n                                            tensorMap: NamedTensorsMap,\n                                            context: ExecutionContext):\n                                               tfc.Tensor[] => {\n  switch (node.op) {\n    case 'FusedBatchNorm':\n    case 'FusedBatchNormV2': {\n      return [tfc.batchNorm(\n          getParamValue('x', node, tensorMap, context) as tfc.Tensor,\n          getParamValue('mean', node, tensorMap, context) as tfc.Tensor,\n          getParamValue('variance', node, tensorMap, context) as tfc.Tensor,\n          getParamValue('offset', node, tensorMap, context) as tfc.Tensor,\n          getParamValue('scale', node, tensorMap, context) as tfc.Tensor,\n          getParamValue('epsilon', node, tensorMap, context) as number)];\n    }\n    case 'FusedBatchNormV3': {\n      return [tfc.batchNorm(\n          getParamValue('x', node, tensorMap, context) as tfc.Tensor,\n          getParamValue('mean', node, tensorMap, context) as tfc.Tensor,\n          getParamValue('variance', node, tensorMap, context) as tfc.Tensor,\n          getParamValue('offset', node, tensorMap, context) as tfc.Tensor,\n          getParamValue('scale', node, tensorMap, context) as tfc.Tensor,\n          getParamValue('epsilon', node, tensorMap, context) as number)];\n    }\n    case 'LRN': {\n      return [tfc.localResponseNormalization(\n          getParamValue('x', node, tensorMap, context) as tfc.Tensor3D |\n              tfc.Tensor4D,\n          getParamValue('radius', node, tensorMap, context) as number,\n          getParamValue('bias', node, tensorMap, context) as number,\n          getParamValue('alpha', node, tensorMap, context) as number,\n          getParamValue('beta', node, tensorMap, context) as number)];\n    }\n    case 'Softmax': {\n      return [tfc.softmax(\n          getParamValue('x', node, tensorMap, context) as tfc.Tensor)];\n    }\n    case 'LogSoftmax': {\n      return [tfc.logSoftmax(\n          getParamValue('x', node, tensorMap, context) as tfc.Tensor)];\n    }\n    case 'SparseToDense': {\n      return [tfc.sparseToDense(\n          getParamValue('sparseIndices', node, tensorMap, context) as\n              tfc.Tensor,\n          getParamValue('outputShape', node, tensorMap, context) as tfc.Tensor,\n          getParamValue('sparseValues', node, tensorMap, context) as number[],\n          getParamValue('defaultValue', node, tensorMap, context) as\n              tfc.Scalar)];\n    }\n    default:\n      throw TypeError(`Node type ${node.op} is not implemented`);\n  }\n};\n\nexport const CATEGORY = 'normalization';\n","/**\n * @license\n * Copyright 2018 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport * as tfc from '@tensorflow/tfjs-core';\n\nimport {NamedTensorsMap} from '../../data/types';\nimport {ExecutionContext} from '../../executor/execution_context';\nimport {InternalOpExecutor, Node} from '../types';\n\nimport {getParamValue} from './utils';\n\nexport let executeOp: InternalOpExecutor = (node: Node,\n                                            tensorMap: NamedTensorsMap,\n                                            context: ExecutionContext):\n                                               tfc.Tensor[] => {\n  switch (node.op) {\n    case 'Max': {\n      const axis = getParamValue('axis', node, tensorMap, context) as number[];\n      const keepDims =\n          getParamValue('keepDims', node, tensorMap, context) as boolean;\n      return [tfc.max(\n          getParamValue('x', node, tensorMap, context) as tfc.Tensor, axis,\n          keepDims)];\n    }\n    case 'Mean': {\n      const axis = getParamValue('axis', node, tensorMap, context) as number[];\n      const keepDims =\n          getParamValue('keepDims', node, tensorMap, context) as boolean;\n      return [tfc.mean(\n          getParamValue('x', node, tensorMap, context) as tfc.Tensor, axis,\n          keepDims)];\n    }\n    case 'Min': {\n      const axis = getParamValue('axis', node, tensorMap, context) as number[];\n      const keepDims =\n          getParamValue('keepDims', node, tensorMap, context) as boolean;\n      return [tfc.min(\n          getParamValue('x', node, tensorMap, context) as tfc.Tensor, axis,\n          keepDims)];\n    }\n    case 'Sum': {\n      const axis = getParamValue('axis', node, tensorMap, context) as number[];\n      const keepDims =\n          getParamValue('keepDims', node, tensorMap, context) as boolean;\n      return [tfc.sum(\n          getParamValue('x', node, tensorMap, context) as tfc.Tensor, axis,\n          keepDims)];\n    }\n    case 'All': {\n      const axis = getParamValue('axis', node, tensorMap, context) as number[];\n      const keepDims =\n          getParamValue('keepDims', node, tensorMap, context) as boolean;\n      return [tfc.all(\n          getParamValue('x', node, tensorMap, context) as tfc.Tensor, axis,\n          keepDims)];\n    }\n    case 'Any': {\n      const axis = getParamValue('axis', node, tensorMap, context) as number[];\n      const keepDims =\n          getParamValue('keepDims', node, tensorMap, context) as boolean;\n      return [tfc.any(\n          getParamValue('x', node, tensorMap, context) as tfc.Tensor, axis,\n          keepDims)];\n    }\n    case 'ArgMax': {\n      const axis = getParamValue('axis', node, tensorMap, context) as number;\n      return [tfc.argMax(\n          getParamValue('x', node, tensorMap, context) as tfc.Tensor, axis)];\n    }\n    case 'ArgMin': {\n      const axis = getParamValue('axis', node, tensorMap, context) as number;\n      return [tfc.argMin(\n          getParamValue('x', node, tensorMap, context) as tfc.Tensor, axis)];\n    }\n    case 'Prod': {\n      const axis = getParamValue('axis', node, tensorMap, context) as number[];\n      const keepDims =\n          getParamValue('keepDims', node, tensorMap, context) as boolean;\n      return [tfc.prod(\n          getParamValue('x', node, tensorMap, context) as tfc.Tensor, axis,\n          keepDims)];\n    }\n    default:\n      throw TypeError(`Node type ${node.op} is not implemented`);\n  }\n};\n\nexport const CATEGORY = 'reduction';\n","/**\n * @license\n * Copyright 2018 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport * as tfc from '@tensorflow/tfjs-core';\n\nimport {NamedTensorsMap} from '../../data/types';\nimport {ExecutionContext} from '../../executor/execution_context';\nimport {InternalOpExecutor, Node} from '../types';\n\nimport {getParamValue} from './utils';\n\nexport let executeOp: InternalOpExecutor = (node: Node,\n                                            tensorMap: NamedTensorsMap,\n                                            context: ExecutionContext):\n                                               tfc.Tensor[] => {\n  switch (node.op) {\n    case 'ConcatV2':\n    case 'Concat': {\n      const axis = getParamValue('axis', node, tensorMap, context) as number;\n      const inputs =\n          getParamValue('tensors', node, tensorMap, context) as tfc.Tensor[];\n      return [tfc.concat(inputs, axis)];\n    }\n    case 'GatherV2':\n    case 'Gather': {\n      const axis = getParamValue('axis', node, tensorMap, context) as number;\n      const input = getParamValue('x', node, tensorMap, context) as tfc.Tensor;\n      const indices =\n          getParamValue('indices', node, tensorMap, context) as tfc.Tensor1D;\n      return [tfc.gather(input, indices.asType('int32'), axis)];\n    }\n    case 'ReverseV2':\n    case 'Reverse': {\n      const axis = getParamValue('axis', node, tensorMap, context) as number[];\n      const input = getParamValue('x', node, tensorMap, context) as tfc.Tensor;\n      return [tfc.reverse(input, axis)];\n    }\n    case 'Slice': {\n      // tslint:disable-next-line:no-any\n      const begin = getParamValue('begin', node, tensorMap, context) as any;\n      // tslint:disable-next-line:no-any\n      const size = getParamValue('size', node, tensorMap, context) as any;\n      return [tfc.slice(\n          getParamValue('x', node, tensorMap, context) as tfc.Tensor, begin,\n          size)];\n    }\n    case 'StridedSlice': {\n      const begin =\n          getParamValue('begin', node, tensorMap, context) as number[];\n      const end = getParamValue('end', node, tensorMap, context) as number[];\n      const strides =\n          getParamValue('strides', node, tensorMap, context) as number[];\n      const beginMask =\n          getParamValue('beginMask', node, tensorMap, context) as number;\n      const endMask =\n          getParamValue('endMask', node, tensorMap, context) as number;\n      const ellipsisMask =\n          getParamValue('ellipsisMask', node, tensorMap, context) as number;\n      const newAxisMask =\n          getParamValue('newAxisMask', node, tensorMap, context) as number;\n      const shrinkAxisMask =\n          getParamValue('shrinkAxisMask', node, tensorMap, context) as number;\n      const tensor = getParamValue('x', node, tensorMap, context) as tfc.Tensor;\n      if (begin.length === 1 && tensor.shape.length > 1) {\n        for (let i = 1; i < tensor.shape.length; i++) {\n          begin.push(0);\n          end.push(tensor.shape[i]);\n          strides.push(strides[0]);\n        }\n      }\n      return [tfc.stridedSlice(\n          tensor, begin, end, strides, beginMask, endMask, ellipsisMask,\n          newAxisMask, shrinkAxisMask)];\n    }\n    case 'Pack': {\n      return tfc.tidy(() => {\n        const axis = getParamValue('axis', node, tensorMap, context) as number;\n        const tensors =\n            getParamValue('tensors', node, tensorMap, context) as tfc.Tensor[];\n        // Reshape the tensors to the first tensor's shape if they don't match.\n        const shape = tensors[0].shape;\n        const squeezedShape = tensors[0].squeeze().shape;\n        const mapped = tensors.map(tensor => {\n          const sameShape = tfc.util.arraysEqual(tensor.shape, shape);\n          if (!sameShape &&\n              !tfc.util.arraysEqual(tensor.squeeze().shape, squeezedShape)) {\n            throw new Error('the input tensors shape does not match');\n          }\n          return sameShape ? tensor : tensor.reshape(shape);\n        });\n        return [tfc.stack(mapped, axis)];\n      });\n    }\n    case 'Unpack': {\n      return tfc.tidy(() => {\n        const axis = getParamValue('axis', node, tensorMap, context) as number;\n        const tensor =\n            getParamValue('tensor', node, tensorMap, context) as tfc.Tensor;\n        return tfc.unstack(tensor, axis);\n      });\n    }\n    case 'Tile': {\n      const reps = getParamValue('reps', node, tensorMap, context) as number[];\n      return [tfc.tile(\n          getParamValue('x', node, tensorMap, context) as tfc.Tensor, reps)];\n    }\n    case 'Split':\n    case 'SplitV': {\n      const axis = getParamValue('axis', node, tensorMap, context) as number;\n      const numOrSizeSplits =\n          getParamValue('numOrSizeSplits', node, tensorMap, context) as number |\n          number[];\n      return tfc.split(\n          getParamValue('x', node, tensorMap, context) as tfc.Tensor,\n          numOrSizeSplits, axis);\n    }\n    case 'ScatterNd': {\n      const indices =\n          getParamValue('indices', node, tensorMap, context) as tfc.Tensor;\n      const values =\n          getParamValue('values', node, tensorMap, context) as tfc.Tensor;\n      const shape =\n          getParamValue('shape', node, tensorMap, context) as number[];\n      return [tfc.scatterND(indices, values, shape)];\n    }\n    case 'GatherNd': {\n      const x = getParamValue('x', node, tensorMap, context) as tfc.Tensor;\n      const indices =\n          getParamValue('indices', node, tensorMap, context) as tfc.Tensor;\n      return [tfc.gatherND(x, indices)];\n    }\n    case 'SparseToDense': {\n      const indices =\n          getParamValue('sparseIndices', node, tensorMap, context) as\n          tfc.Tensor;\n      const shape =\n          getParamValue('outputShape', node, tensorMap, context) as number[];\n      const sparseValues =\n          getParamValue('sparseValues', node, tensorMap, context) as tfc.Tensor;\n      const defaultValue =\n          getParamValue('defaultValue', node, tensorMap, context) as tfc.Scalar;\n      return [tfc.sparseToDense(\n          indices, sparseValues, shape,\n          sparseValues.dtype === defaultValue.dtype ?\n              defaultValue :\n              defaultValue.asType(sparseValues.dtype))];\n    }\n    default:\n      throw TypeError(`Node type ${node.op} is not implemented`);\n  }\n};\n\nexport const CATEGORY = 'slice_join';\n","/**\n * @license\n * Copyright 2018 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport * as tfc from '@tensorflow/tfjs-core';\n\nimport {NamedTensorsMap} from '../../data/types';\nimport {ExecutionContext} from '../../executor/execution_context';\nimport {InternalOpExecutor, Node} from '../types';\n\nimport {getParamValue} from './utils';\n\nexport let executeOp: InternalOpExecutor =\n    (node: Node, tensorMap: NamedTensorsMap,\n     context: ExecutionContext): tfc.Tensor[] => {\n      switch (node.op) {\n        case 'FFT': {\n          return [tfc.fft(\n              getParamValue('x', node, tensorMap, context) as tfc.Tensor)];\n        }\n        case 'IFFT': {\n          return [tfc.ifft(\n              getParamValue('x', node, tensorMap, context) as tfc.Tensor)];\n        }\n        case 'RFFT': {\n          return [tfc.rfft(\n              getParamValue('x', node, tensorMap, context) as tfc.Tensor)];\n        }\n        case 'IRFFT': {\n          return [tfc.irfft(\n              getParamValue('x', node, tensorMap, context) as tfc.Tensor)];\n        }\n        default:\n          throw TypeError(`Node type ${node.op} is not implemented`);\n      }\n    };\n\nexport const CATEGORY = 'spectral';\n","/**\n * @license\n * Copyright 2018 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport * as tfc from '@tensorflow/tfjs-core';\n\nimport {NamedTensorsMap} from '../../data/types';\nimport {ExecutionContext} from '../../executor/execution_context';\nimport {InternalOpExecutor, Node} from '../types';\n\nimport {getParamValue, split} from './utils';\n\nexport let executeOp: InternalOpExecutor = (node: Node,\n                                            tensorMap: NamedTensorsMap,\n                                            context: ExecutionContext):\n                                               tfc.Tensor[] => {\n  switch (node.op) {\n    case 'Cast': {\n      return [tfc.cast(\n          getParamValue('x', node, tensorMap, context) as tfc.Tensor,\n          getParamValue('dtype', node, tensorMap, context) as 'int32' |\n              'float32' | 'bool')];\n    }\n    case 'ExpandDims': {\n      const axis = getParamValue('axis', node, tensorMap, context) as number;\n      return [tfc.expandDims(\n          getParamValue('x', node, tensorMap, context) as tfc.Tensor, axis)];\n    }\n    case 'Squeeze': {\n      const axis = getParamValue('axis', node, tensorMap, context) as number[];\n      return [tfc.squeeze(\n          getParamValue('x', node, tensorMap, context) as tfc.Tensor, axis)];\n    }\n\n    case 'Reshape': {\n      return [tfc.reshape(\n          getParamValue('x', node, tensorMap, context) as tfc.Tensor,\n          getParamValue('shape', node, tensorMap, context) as number[])];\n    }\n    case 'PadV2':\n    case 'Pad': {\n      return [tfc.pad(\n          getParamValue('x', node, tensorMap, context) as tfc.Tensor,\n          split(\n              getParamValue('padding', node, tensorMap, context) as number[],\n              2) as Array<[number, number]>,\n          getParamValue('constantValue', node, tensorMap, context) as number)];\n    }\n    case 'SpaceToBatchND': {\n      const blockShape =\n          getParamValue('blockShape', node, tensorMap, context) as number[];\n      const paddings = split(\n          getParamValue('paddings', node, tensorMap, context) as number[], 2);\n      return [tfc.spaceToBatchND(\n          getParamValue('x', node, tensorMap, context) as tfc.Tensor,\n          blockShape, paddings)];\n    }\n    case 'BatchToSpaceND': {\n      const blockShape =\n          getParamValue('blockShape', node, tensorMap, context) as number[];\n      const crops = split(\n          getParamValue('crops', node, tensorMap, context) as number[], 2);\n      return [tfc.batchToSpaceND(\n          getParamValue('x', node, tensorMap, context) as tfc.Tensor,\n          blockShape, crops)];\n    }\n    case 'DepthToSpace': {\n      const blockSize =\n          getParamValue('blockSize', node, tensorMap, context) as number;\n      const dataFormat =\n          (getParamValue('dataFormat', node, tensorMap, context) as\n           string).toUpperCase() as 'NHWC' |\n          'NCHW';\n      return [tfc.depthToSpace(\n          getParamValue('x', node, tensorMap, context) as tfc.Tensor4D,\n          blockSize, dataFormat)];\n    }\n    default:\n      throw TypeError(`Node type ${node.op} is not implemented`);\n  }\n};\n\nexport const CATEGORY = 'transformation';\n","/**\n * @license\n * Copyright 2018 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport * as tfc from '@tensorflow/tfjs-core';\n\nimport {NamedTensorsMap} from '../data/types';\nimport {ExecutionContext} from '../executor/execution_context';\n\nimport {NodeValueImpl} from './custom_op/node_value_impl';\nimport {getRegisteredOp} from './custom_op/register';\nimport * as arithmetic from './executors/arithmetic_executor';\nimport * as basicMath from './executors/basic_math_executor';\nimport * as control from './executors/control_executor';\nimport * as convolution from './executors/convolution_executor';\nimport * as creation from './executors/creation_executor';\nimport * as dynamic from './executors/dynamic_executor';\nimport * as evaluation from './executors/evaluation_executor';\nimport * as graph from './executors/graph_executor';\nimport * as image from './executors/image_executor';\nimport * as logical from './executors/logical_executor';\nimport * as matrices from './executors/matrices_executor';\nimport * as normalization from './executors/normalization_executor';\nimport * as reduction from './executors/reduction_executor';\nimport * as sliceJoin from './executors/slice_join_executor';\nimport * as spectral from './executors/spectral_executor';\nimport * as transformation from './executors/transformation_executor';\nimport {Node} from './types';\n\n/**\n * Executes the op defined by the node object.\n * @param node\n * @param tensorMap contains tensors for executed nodes and weights\n */\nexport function executeOp(\n    node: Node, tensorMap: NamedTensorsMap,\n    context: ExecutionContext): tfc.Tensor[]|Promise<tfc.Tensor[]> {\n  const value =\n      ((node: Node, tensorMap: NamedTensorsMap, context: ExecutionContext) => {\n        switch (node.category) {\n          case 'arithmetic':\n            return arithmetic.executeOp(node, tensorMap, context);\n          case 'basic_math':\n            return basicMath.executeOp(node, tensorMap, context);\n          case 'control':\n            return control.executeOp(node, tensorMap, context);\n          case 'convolution':\n            return convolution.executeOp(node, tensorMap, context);\n          case 'creation':\n            return creation.executeOp(node, tensorMap, context);\n          case 'dynamic':\n            return dynamic.executeOp(node, tensorMap, context);\n          case 'evaluation':\n            return evaluation.executeOp(node, tensorMap, context);\n          case 'image':\n            return image.executeOp(node, tensorMap, context);\n          case 'graph':\n            return graph.executeOp(node, tensorMap, context);\n          case 'logical':\n            return logical.executeOp(node, tensorMap, context);\n          case 'matrices':\n            return matrices.executeOp(node, tensorMap, context);\n          case 'normalization':\n            return normalization.executeOp(node, tensorMap, context);\n          case 'reduction':\n            return reduction.executeOp(node, tensorMap, context);\n          case 'slice_join':\n            return sliceJoin.executeOp(node, tensorMap, context);\n          case 'spectral':\n            return spectral.executeOp(node, tensorMap, context);\n          case 'transformation':\n            return transformation.executeOp(node, tensorMap, context);\n          case 'custom':\n            const opMapper = getRegisteredOp(node.op);\n            if (opMapper && opMapper.customExecutor) {\n              return opMapper.customExecutor(\n                  new NodeValueImpl(node, tensorMap, context));\n            } else {\n              throw TypeError(`Custom op ${node.op} is not registered.`);\n            }\n          default:\n            throw TypeError(\n                `Unknown op '${node.op}'. File an issue at ` +\n                `https://github.com/tensorflow/tfjs/issues so we can add it` +\n                `, or register a custom execution with tf.registerOp()`);\n        }\n      })(node, tensorMap, context);\n  if (value instanceof Promise) {\n    return value.then((data) => [].concat(data));\n  }\n  return [].concat(value);\n}\n","/**\n * @license\n * Copyright 2018 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport * as tfc from '@tensorflow/tfjs-core';\nimport {scalar} from '@tensorflow/tfjs-core';\n\nimport {NamedTensorsMap} from '../../data/types';\nimport {ExecutionContext} from '../../executor/execution_context';\nimport {TensorArray} from '../../executor/tensor_array';\nimport {Node} from '../types';\n\nimport {getParamValue, getTensor} from './utils';\n\nexport async function executeOp(\n    node: Node, tensorMap: NamedTensorsMap,\n    context: ExecutionContext): Promise<tfc.Tensor[]> {\n  switch (node.op) {\n    case 'LoopCond':\n      return [\n        (getParamValue('pred', node, tensorMap, context) as tfc.Tensor).clone()\n      ];\n    case 'Switch': {\n      const pred =\n          getParamValue('pred', node, tensorMap, context) as tfc.Tensor;\n      const data =\n          getParamValue('data', node, tensorMap, context) as tfc.Tensor;\n      // Outputs nodes :0 => false, :1 => true\n      return (await pred.data())[0] ? [undefined, data.clone()] :\n                                      [data.clone(), undefined];\n    }\n    case 'Merge':\n      const inputName = node.inputNames.find(\n          name => getTensor(name, tensorMap, context) !== undefined);\n      return inputName ? [getTensor(inputName, tensorMap, context).clone()] :\n                         undefined;\n\n    case 'Enter':\n      const frameId =\n          getParamValue('frameName', node, tensorMap, context) as string;\n      const data =\n          getParamValue('tensor', node, tensorMap, context) as tfc.Tensor;\n      context.enterFrame(frameId);\n      return [data.clone()];\n\n    case 'Exit':\n      const tensor =\n          getParamValue('tensor', node, tensorMap, context) as tfc.Tensor;\n      context.exitFrame();\n      return [tensor.clone()];\n\n    case 'NextIteration':\n      const input =\n          getParamValue('tensor', node, tensorMap, context) as tfc.Tensor;\n      context.nextIteration();\n      return [input.clone()];\n\n    case 'TensorArrayV3':\n      const size = getParamValue('size', node, tensorMap, context) as number;\n      const dtype =\n          getParamValue('dtype', node, tensorMap, context) as tfc.DataType;\n      const elementShape =\n          getParamValue('elementShape', node, tensorMap, context) as number[];\n      const dynamicSize =\n          getParamValue('dynamicSize', node, tensorMap, context) as boolean;\n      const clearAfterRead =\n          getParamValue('clearAfterRead', node, tensorMap, context) as boolean;\n      const identicalElementShapes =\n          getParamValue('identicalElementShapes', node, tensorMap, context) as\n          boolean;\n      const name = getParamValue('name', node, tensorMap, context) as string;\n      const tensorArray = new TensorArray(\n          name, dtype, size, elementShape, identicalElementShapes, dynamicSize,\n          clearAfterRead);\n      context.addTensorArray(tensorArray);\n      return [scalar(tensorArray.id), scalar(1.0)];\n\n    case 'TensorArrayWriteV3':\n      const id =\n          getParamValue('tensorArrayId', node, tensorMap, context) as number;\n      const index = getParamValue('index', node, tensorMap, context) as number;\n      const writeTensor =\n          getParamValue('tensor', node, tensorMap, context) as tfc.Tensor;\n      const writeTensorArray = context.getTensorArray(id);\n      writeTensorArray.write(index, writeTensor);\n      return [scalar(1.0)];\n\n    case 'TensorArrayReadV3':\n      const readId =\n          getParamValue('tensorArrayId', node, tensorMap, context) as number;\n      const readIndex =\n          getParamValue('index', node, tensorMap, context) as number;\n      const readTensorArray = context.getTensorArray(readId);\n      return [readTensorArray.read(readIndex)];\n\n    case 'TensorArrayGatherV3':\n      const gatherId =\n          getParamValue('tensorArrayId', node, tensorMap, context) as number;\n      const gatherIndices =\n          getParamValue('indices', node, tensorMap, context) as number[];\n      const gatherDtype =\n          getParamValue('dtype', node, tensorMap, context) as tfc.DataType;\n      const gatherTensorArray = context.getTensorArray(gatherId);\n      return [gatherTensorArray.gather(gatherIndices, gatherDtype)];\n\n    case 'TensorArrayScatterV3':\n      const scatterId =\n          getParamValue('tensorArrayId', node, tensorMap, context) as number;\n      const scatterIndices =\n          getParamValue('indices', node, tensorMap, context) as number[];\n      const scatterTensor =\n          getParamValue('tensor', node, tensorMap, context) as tfc.Tensor;\n      const scatterTensorArray = context.getTensorArray(scatterId);\n      scatterTensorArray.scatter(scatterIndices, scatterTensor);\n      return [scalar(1.0)];\n\n    case 'TensorArrayConcatV3':\n      const concatId =\n          getParamValue('tensorArrayId', node, tensorMap, context) as number;\n      const concatTensorArray = context.getTensorArray(concatId);\n      const concatDtype =\n          getParamValue('dtype', node, tensorMap, context) as tfc.DataType;\n      return [concatTensorArray.concat(concatDtype)];\n\n    case 'TensorArraySplitV3':\n      const splitId =\n          getParamValue('tensorArrayId', node, tensorMap, context) as number;\n      const splitTensor =\n          getParamValue('tensor', node, tensorMap, context) as tfc.Tensor;\n      const lengths =\n          getParamValue('lengths', node, tensorMap, context) as number[];\n      const splitTensorArray = context.getTensorArray(splitId);\n      splitTensorArray.split(lengths, splitTensor);\n      return [scalar(1.0)];\n\n    case 'TensorArraySizeV3':\n      const sizeId =\n          getParamValue('tensorArrayId', node, tensorMap, context) as number;\n      const sizeTensorArray = context.getTensorArray(sizeId);\n      return [scalar(sizeTensorArray.size(), 'int32')];\n\n    case 'TensorArrayCloseV3':\n      const closeId =\n          getParamValue('tensorArrayId', node, tensorMap, context) as number;\n      const closeTensorArray = context.getTensorArray(closeId);\n      closeTensorArray.clearAndClose();\n      return [];\n    default:\n      throw TypeError(`Node type ${node.op} is not implemented`);\n  }\n}\n\nexport const CATEGORY = 'control';\n","/**\n * @license\n * Copyright 2018 Google Inc. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport * as tfc from '@tensorflow/tfjs-core';\n\nimport {NamedTensorsMap} from '../../data/types';\nimport {ExecutionContext} from '../../executor/execution_context';\nimport {Node} from '../types';\nimport {getParamValue} from './utils';\n\nexport async function executeOp(\n    node: Node, tensorMap: NamedTensorsMap,\n    context: ExecutionContext): Promise<tfc.Tensor[]> {\n  switch (node.op) {\n    case 'NonMaxSuppressionV3':\n    case 'NonMaxSuppressionV2': {\n      const boxes =\n          getParamValue('boxes', node, tensorMap, context) as tfc.Tensor;\n      const scores =\n          getParamValue('scores', node, tensorMap, context) as tfc.Tensor;\n      const maxOutputSize =\n          getParamValue('maxOutputSize', node, tensorMap, context) as number;\n      const iouThreshold =\n          getParamValue('iouThreshold', node, tensorMap, context) as number;\n      const scoreThreshold =\n          getParamValue('scoreThreshold', node, tensorMap, context) as number;\n      return [await tfc.image.nonMaxSuppressionAsync(\n          boxes as tfc.Tensor2D, scores as tfc.Tensor1D, maxOutputSize,\n          iouThreshold, scoreThreshold)];\n    }\n    case 'Where': {\n      return [await tfc.whereAsync(\n          getParamValue('condition', node, tensorMap, context) as tfc.Tensor)];\n    }\n    case 'ListDiff': {\n      return await tfc.setdiff1dAsync(\n          getParamValue('x', node, tensorMap, context) as tfc.Tensor,\n          getParamValue('y', node, tensorMap, context) as tfc.Tensor);\n    }\n    default:\n      throw TypeError(`Node type ${node.op} is not implemented`);\n  }\n}\n\nexport const CATEGORY = 'dynamic';\n","/**\n * @license\n * Copyright 2018 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport {Tensor} from '@tensorflow/tfjs-core';\n\nimport {NamedTensorsMap, TensorArrayMap} from '../data/types';\n\nimport {TensorArray} from './tensor_array';\n\nexport interface ExecutionContextInfo {\n  id: number;           // the unique id of the context info\n  frameName: string;    // The frame name of the loop, this comes from\n                        // the TensorFlow NodeDef.\n  iterationId: number;  // The iteration id of the loop\n}\n\n/**\n * ExecutionContext captures the runtime environment of the node. It keeps\n * track of the current frame and iteration for the control flow ops.\n *\n * For example, typical Dynamic RNN model may contain loops, for which\n * TensorFlow will generate graphs with Enter/Exit nodes to control the\n * current execution frame, and NextIteration Nodes for iteration id increment.\n * For model with branch logic, TensorFLow will generate Switch/Merge ops.\n */\nexport class ExecutionContext {\n  private rootContext = {id: 0, frameName: '', iterationId: 0};\n  private contexts: ExecutionContextInfo[] = [this.rootContext];\n  private lastId = 0;\n  private _currentContextIds: string[];\n\n  constructor(\n      public readonly weightMap: NamedTensorsMap,\n      public readonly tensorArrayMap: TensorArrayMap) {\n    this.generateCurrentContextIds();\n  }\n\n  private newFrame(id: number, frameName: string) {\n    return {id, frameName, iterationId: 0};\n  }\n\n  /**\n   * Set the current context\n   * @param contexts: ExecutionContextInfo[] the current path of execution\n   * frames\n   */\n  set currentContext(contexts: ExecutionContextInfo[]) {\n    if (this.contexts !== contexts) {\n      this.contexts = contexts;\n      this.generateCurrentContextIds();\n    }\n  }\n\n  get currentContext(): ExecutionContextInfo[] {\n    return this.contexts;\n  }\n\n  /**\n   * Returns the current context in string format.\n   */\n  get currentContextId(): string {\n    return this._currentContextIds[0];\n  }\n\n  /**\n   * Returns the current context and all parent contexts in string format.\n   * This allow access to the nodes in the current and parent frames.\n   */\n  get currentContextIds(): string[] {\n    return this._currentContextIds;\n  }\n\n  private generateCurrentContextIds() {\n    const names = [];\n    for (let i = 0; i < this.contexts.length - 1; i++) {\n      const contexts = this.contexts.slice(0, this.contexts.length - i);\n      names.push(this.contextIdforContexts(contexts));\n    }\n    names.push('');\n    this._currentContextIds = names;\n  }\n\n  private contextIdforContexts(contexts: ExecutionContextInfo[]) {\n    return contexts ?\n        contexts\n            .map(\n                context => (context.id === 0 && context.iterationId === 0) ?\n                    '' :\n                    `${context.frameName}-${context.iterationId}`)\n            .join('/') :\n        '';\n  }\n\n  /**\n   * Enter a new frame, a new context is pushed on the current context list.\n   * @param frameId new frame id\n   */\n  enterFrame(frameId: string) {\n    if (this.contexts) {\n      this.lastId++;\n      this.contexts = this.contexts.slice();\n      this.contexts.push(this.newFrame(this.lastId, frameId));\n      this._currentContextIds.unshift(this.contextIdforContexts(this.contexts));\n    }\n  }\n\n  /**\n   * Exit the current frame, the last context is removed from the current\n   * context list.\n   */\n  exitFrame() {\n    if (this.contexts && this.contexts.length > 1) {\n      this.contexts = this.contexts.slice();\n      this.contexts.splice(-1);\n      this.currentContextIds.shift();\n    } else {\n      throw new Error('Cannot exit frame, the context is empty');\n    }\n  }\n\n  /**\n   * Enter the next iteration of a loop, the iteration id of last context is\n   * increased.\n   */\n  nextIteration() {\n    if (this.contexts && this.contexts.length > 0) {\n      this.contexts = this.contexts.slice();\n      this.lastId++;\n      const context =\n          Object.assign({}, this.contexts[this.contexts.length - 1]) as\n          ExecutionContextInfo;\n      context.iterationId += 1;\n      context.id = this.lastId;\n      this.contexts.splice(-1, 1, context);\n      this._currentContextIds.splice(\n          0, 1, this.contextIdforContexts(this.contexts));\n    } else {\n      throw new Error('Cannot increase frame iteration, the context is empty');\n    }\n  }\n\n  getWeight(name: string): Tensor[] {\n    return this.weightMap[name];\n  }\n\n  addTensorArray(tensorArray: TensorArray) {\n    this.tensorArrayMap[tensorArray.id] = tensorArray;\n  }\n\n  getTensorArray(id: number): TensorArray {\n    return this.tensorArrayMap[id];\n  }\n}\n","/**\n * @license\n * Copyright 2019 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {NamedTensorMap} from '@tensorflow/tfjs-core';\n\nimport {NamedTensorsMap} from '../data/types';\nimport {Graph, Node} from '../operations/types';\n\nexport interface ExecutionInfo {\n  inputs: NamedTensorMap;\n  outputs: Node[];\n  usedNodes: Set<string>;\n  missingInputs: string[];\n  dynamicNode: Node;\n  syncInputs: string[];\n}\n\n/**\n * Given graph inputs and desired outputs, find the minimal set of nodes\n * to execute in order to compute the outputs. In addition return other useful\n * info such:\n * - Missing inputs needed to compute the output.\n * - Whether the subgraph contains dynamic ops (control flow, dynamic shape).\n * - Alternative inputs in order to avoid async (dynamic op) execution.\n */\nexport function getExecutionSubgraph(\n    inputs: NamedTensorMap, outputs: Node[],\n    weightMap: NamedTensorsMap): ExecutionInfo {\n  const usedNodes = new Set<string>();\n  const missingInputs: string[] = [];\n  let dynamicNode: Node = null;\n  let syncInputs: string[] = null;\n\n  // Start with the outputs, going backwards and find all the nodes that are\n  // needed to compute those outputs.\n  const seen = new Set<string>();\n  const frontier = [...outputs];\n  while (frontier.length > 0) {\n    const node = frontier.pop();\n    if (isControlFlow(node) || isDynamicShape(node)) {\n      if (dynamicNode == null) {\n        dynamicNode = node;\n        syncInputs = dynamicNode.children.map(child => child.name)\n                         .filter(name => usedNodes.has(name));\n      }\n    }\n    usedNodes.add(node.name);\n\n    // Weights are dead end since we already have their values.\n    if (weightMap[node.name] != null) {\n      continue;\n    }\n    // This node is a dead end since it's one of the user-provided inputs.\n    if (inputs[node.name] != null) {\n      continue;\n    }\n    if (node.inputs.length === 0) {\n      missingInputs.push(node.name);\n      continue;\n    }\n    node.inputs.forEach(input => {\n      // Don't add to the frontier if it is already there.\n      if (seen.has(input.name)) {\n        return;\n      }\n      seen.add(input.name);\n      frontier.push(input);\n    });\n  }\n  return {inputs, outputs, usedNodes, missingInputs, dynamicNode, syncInputs};\n}\n\n/**\n * Given the execution info, return a list of nodes in topological order that\n * need to be executed to compute the output.\n */\nexport function getNodesInTopologicalOrder(\n    graph: Graph, weightMap: NamedTensorsMap,\n    executionInfo: ExecutionInfo): Node[] {\n  const {usedNodes, inputs} = executionInfo;\n  const frontier: Node[] = [];\n  const inputNodes = Object.keys(inputs).map(name => graph.nodes[name]);\n  inputNodes.forEach(input => {\n    if (usedNodes.has(input.name)) {\n      frontier.push(input);\n    }\n  });\n  graph.weights.forEach(weight => {\n    if (usedNodes.has(weight.name)) {\n      frontier.push(weight);\n    }\n  });\n  const seen = new Set<string>();\n  const orderedNodes: Node[] = [];\n  while (frontier.length > 0) {\n    const node = frontier.pop();\n    seen.add(node.name);\n    if (!weightMap[node.name]) {\n      orderedNodes.push(node);\n    }\n    node.children.forEach(child => {\n      if (!seen.has(child.name) && usedNodes.has(child.name) &&\n          child.inputs.every(input => seen.has(input.name))) {\n        frontier.push(child);\n      }\n    });\n  }\n  return orderedNodes;\n}\n\nconst CONTROL_FLOW_OPS = ['Switch', 'Merge', 'Enter', 'Exit', 'NextIteration'];\nconst DYNAMIC_SHAPE_OPS =\n    ['NonMaxSuppressionV2', 'NonMaxSuppressionV3', 'Where'];\n\nexport function isControlFlow(node: Node) {\n  return CONTROL_FLOW_OPS.indexOf(node.op) >= 0;\n}\n\nexport function isDynamicShape(node: Node) {\n  return DYNAMIC_SHAPE_OPS.indexOf(node.op) >= 0;\n}\n","/**\n * @license\n * Copyright 2018 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {DataType, NamedTensorMap, Tensor, tidy, util} from '@tensorflow/tfjs-core';\n\nimport {NamedTensorsMap, TensorArrayMap, TensorInfo} from '../data/types';\nimport {getNodeNameAndIndex, getParamValue, getTensor, getTensorsForCurrentContenxt, parseNodeName} from '../operations/executors/utils';\nimport {executeOp} from '../operations/operation_executor';\nimport {Graph, Node} from '../operations/types';\n\nimport {ExecutionContext, ExecutionContextInfo} from './execution_context';\nimport {getExecutionSubgraph, getNodesInTopologicalOrder, isControlFlow} from './model_analysis';\nimport {rewritePrelu} from './model_rewrite';\n\ninterface NodeWithContexts {\n  contexts: ExecutionContextInfo[];\n  node: Node;\n}\n\nexport class GraphExecutor {\n  private compiledMap: Map<string, Node[]> = new Map();\n  private _weightMap: NamedTensorsMap = {};\n  private weightIds: number[];\n  private placeholders: Node[];\n  private _outputs: Node[];\n  private SEPERATOR = ',';\n  get weightMap(): NamedTensorsMap {\n    return this._weightMap;\n  }\n  set weightMap(weightMap: NamedTensorsMap) {\n    const weightIds = Object.keys(weightMap).map(\n        key => weightMap[key].map(tensor => tensor.id));\n    this.weightIds = [].concat.apply([], weightIds);\n    this._weightMap = weightMap;\n  }\n\n  get inputs(): TensorInfo[] {\n    return this.placeholders.map(node => {\n      return {\n        name: node.name,\n        shape: node.attrParams['shape'] ?\n            node.attrParams['shape'].value as number[] :\n            undefined,\n        dtype: node.attrParams['dtype'] ?\n            node.attrParams['dtype'].value as DataType :\n            undefined\n      };\n    });\n  }\n\n  get outputs(): TensorInfo[] {\n    return this._outputs.map(node => {\n      return {\n        name: node.name,\n        shape: node.attrParams['shape'] ?\n            node.attrParams['shape'].value as number[] :\n            undefined,\n        dtype: node.attrParams['dtype'] ?\n            node.attrParams['dtype'].value as DataType :\n            undefined\n      };\n    });\n  }\n\n  get inputNodes(): string[] {\n    return this.placeholders.map(node => node.name);\n  }\n\n  get outputNodes(): string[] {\n    return this.outputs.map(node => node.name);\n  }\n\n  constructor(private graph: Graph) {\n    this.placeholders = graph.placeholders;\n    this._outputs = graph.outputs;\n  }\n\n  private getCompilationKey(inputs: Node[], outputs: Node[]): string {\n    const sortedInputs = inputs.map(node => node.name).sort();\n    const sortedOutputs = outputs.map(node => node.name).sort();\n    return sortedInputs.join(this.SEPERATOR) + '--' +\n        sortedOutputs.join(this.SEPERATOR);\n  }\n\n  /**\n   * Compiles the inference graph and returns the minimal set of nodes that are\n   * required for execution, in the correct execution order.\n   */\n  private compile(inputs: NamedTensorMap, outputs: Node[]): Node[] {\n    const executionInfo = getExecutionSubgraph(inputs, outputs, this.weightMap);\n    const {missingInputs, dynamicNode, syncInputs} = executionInfo;\n    if (dynamicNode != null) {\n      throw new Error(\n          `This execution contains the node '${dynamicNode.name}', which has ` +\n          `the dynamic op '${dynamicNode.op}'. Please use ` +\n          `model.executeAsync() instead. Alternatively, to avoid the ` +\n          `dynamic ops, specify the inputs [${syncInputs}]`);\n    }\n\n    if (missingInputs.length > 0) {\n      const outNames = outputs.map(n => n.name);\n      const inNames = Object.keys(inputs);\n      throw new Error(\n          `Cannot compute the outputs [${outNames}] from the provided inputs ` +\n          `[${inNames}]. Missing the following inputs: [${missingInputs}]`);\n    }\n\n    return getNodesInTopologicalOrder(\n        this.graph, this.weightMap, executionInfo);\n  }\n\n  fusePrelu() {\n    rewritePrelu(this.graph, this.weightMap);\n  }\n  /**\n   * Executes the inference for given input tensors.\n   * @param inputs Tensor map for the model inputs, keyed by the input node\n   * names.\n   * @param outputs output node name from the Tensorflow model, if no outputs\n   * are specified, the default outputs of the model would be used. You can\n   * inspect intermediate nodes of the model by adding them to the outputs\n   * array.\n   */\n  execute(inputs: NamedTensorMap, outputs: string[]): Tensor[] {\n    const names = Object.keys(inputs).sort();\n    this.checkInputs(inputs);\n    this.checkInputShapeAndType(inputs);\n    this.checkOutputs(outputs);\n    const inputNodes = names.map(name => this.graph.nodes[name]);\n    const outputNodes =\n        outputs.map(name => this.graph.nodes[parseNodeName(name)[0]]);\n    const compilationKey = this.getCompilationKey(inputNodes, outputNodes);\n    // Do nothing if the compiled graph cache contains the input.\n    let orderedNodes = this.compiledMap.get(compilationKey);\n    if (orderedNodes == null) {\n      orderedNodes = this.compile(inputs, outputNodes);\n      this.compiledMap.set(compilationKey, orderedNodes);\n    }\n    const tensorArrayMap: TensorArrayMap = {};\n    return tidy(() => {\n      const context = new ExecutionContext(this._weightMap, tensorArrayMap);\n      const tensorsMap: NamedTensorsMap = {...this.weightMap};\n      Object.keys(inputs).forEach(name => {\n        tensorsMap[name] = [inputs[name]];\n      });\n      const tensorsToKeep = this.getFrozenTensorIds(tensorsMap);\n      const intermediateTensorConsumerCount: {[key: number]: number} = {};\n      for (let i = 0; i < orderedNodes.length; i++) {\n        const node = orderedNodes[i];\n        if (!tensorsMap[node.name]) {\n          const tensors = executeOp(node, tensorsMap, context) as Tensor[];\n          if (tensors instanceof Promise) {\n            throw new Error(\n                `The execution of the op '${node.op}' returned a promise. ` +\n                `Please use model.executeAsync() instead.`);\n          }\n          tensorsMap[node.name] = tensors;\n          this.checkTensorForDisposal(\n              node.name, node, tensorsMap, context, tensorsToKeep, outputs,\n              intermediateTensorConsumerCount);\n        }\n      }\n      return outputs.map(name => getTensor(name, tensorsMap, context));\n    });\n  }\n\n  private getFrozenTensorIds(tensorMap: NamedTensorsMap): Set<number> {\n    const ids = [].concat.apply(\n        [],\n        Object.keys(tensorMap)\n            .map(key => tensorMap[key])\n            .map(tensors => tensors.map(tensor => tensor.id)));\n    return new Set(ids);\n  }\n  private checkTensorForDisposal(\n      nodeName: string, node: Node, tensorMap: NamedTensorsMap,\n      context: ExecutionContext, tensorsToKeep: Set<number>,\n      outputNames: string[],\n      intermediateTensorConsumerCount: {[key: string]: number}) {\n    // Skip output nodes and any control flow nodes, since its dependency is\n    // tricky to track correctly.\n    if (node.category === 'control' || outputNames.indexOf(nodeName) !== -1) {\n      return;\n    }\n\n    tensorMap[nodeName].forEach(tensor => {\n      if (tensor != null) {\n        intermediateTensorConsumerCount[tensor.id] =\n            (intermediateTensorConsumerCount[tensor.id] || 0) +\n            node.children.length;\n      }\n    });\n    node.inputs.forEach(input => {\n      // Skip any control flow nodes, since its dependency is tricky to track\n      // correctly.\n      if (input.category !== 'control') {\n        const tensors =\n            getTensorsForCurrentContenxt(input.name, tensorMap, context);\n        if (tensors != null) {\n          tensors.forEach(tensor => {\n            if (tensor && !tensorsToKeep.has(tensor.id)) {\n              const count = intermediateTensorConsumerCount[tensor.id];\n              if (count === 1) {\n                tensor.dispose();\n                delete intermediateTensorConsumerCount[tensor.id];\n              } else if (count != null) {\n                // only intermediate nodes has count set, inputs and weights are\n                // not.\n                intermediateTensorConsumerCount[tensor.id]--;\n              }\n            }\n          });\n        }\n      }\n    });\n  }\n  /**\n   * Executes the inference for given input tensors in Async fashion.\n   * @param inputs Tensor map for the model inputs, keyed by the input node\n   * names.\n   * @param outputs output node name from the Tensorflow model, if no outputs\n   * are specified, the default outputs of the model would be used. You can\n   * inspect intermediate nodes of the model by adding them to the outputs\n   * array.\n   */\n  async executeAsync(inputs: NamedTensorMap, outputs: string[]):\n      Promise<Tensor[]> {\n    this.checkInputs(inputs);\n    this.checkInputShapeAndType(inputs);\n    this.checkOutputs(outputs);\n    const tensorArrayMap: TensorArrayMap = {};\n    const context = new ExecutionContext(this._weightMap, tensorArrayMap);\n    // Graph with control flow op requires runtime evaluation of the execution\n    // order, while without control flow the execution order is pre-determined\n    // in the compile method.\n    const tensorMap =\n        await this.executeWithControlFlow(inputs, context, outputs);\n    const results = outputs.map(name => getTensor(name, tensorMap, context));\n\n    // dispose all the intermediate tensors\n    const outputIds = new Set<number>(results.map(t => t.id));\n    const inputIds =\n        new Set<number>(Object.keys(inputs).map(name => inputs[name].id));\n    Object.keys(tensorMap).forEach(key => {\n      const tensorArray = tensorMap[key];\n      tensorArray.forEach(tensor => {\n        if (tensor && !tensor.isDisposed && !outputIds.has(tensor.id) &&\n            !inputIds.has(tensor.id) &&\n            this.weightIds.indexOf(tensor.id) === -1) {\n          tensor.dispose();\n        }\n      });\n    });\n    return results;\n  }\n\n  /**\n   * When there are control flow nodes in the graph, the graph execution use\n   * ExecutionContext to keep track of the frames and loop iterators.\n   * @param inputs placeholder tensors for the graph.\n   * @param context the execution context object for current execution.\n   */\n  private async executeWithControlFlow(\n      inputs: NamedTensorMap, context: ExecutionContext,\n      outputNames: string[]): Promise<NamedTensorsMap> {\n    const names = Object.keys(inputs);\n    const inputNodes = names.map(name => this.graph.nodes[name]);\n    const outputNodes =\n        outputNames.map(name => this.graph.nodes[parseNodeName(name)[0]]);\n    const {usedNodes, missingInputs, dynamicNode, syncInputs} =\n        getExecutionSubgraph(inputs, outputNodes, this.weightMap);\n\n    const stack: NodeWithContexts[] =\n        [...inputNodes, ...this.graph.weights].map(node => {\n          return {node, contexts: context.currentContext};\n        });\n    const tensorsMap: NamedTensorsMap = {...this.weightMap};\n    Object.keys(inputs).forEach(name => {\n      tensorsMap[name] = [inputs[name]];\n    });\n    const intermediateTensorConsumerCount: {[key: number]: number} = {};\n    const tensorsToKeep = this.getFrozenTensorIds(tensorsMap);\n    const added: {[key: string]: boolean} = {};\n    while (stack.length > 0) {\n      const promises = this.processStack(\n          inputNodes, stack, context, tensorsMap, added, tensorsToKeep,\n          outputNames, intermediateTensorConsumerCount, usedNodes);\n      await Promise.all(promises);\n    }\n    if (dynamicNode == null) {\n      console.warn(\n          `This model execution did not contain any nodes with control flow ` +\n          `or dynamic output shapes. You can use model.execute() instead.`);\n    }\n    const missingOutputs =\n        outputNodes\n            .filter(\n                node => !isControlFlow(node) &&\n                    !getTensor(node.name, tensorsMap, context))\n            .map(node => node.name);\n    if (missingOutputs.length > 0) {\n      let alternativeMsg = '';\n      if (dynamicNode != null) {\n        alternativeMsg =\n            `Alternatively, to avoid the dynamic ops, use model.execute() ` +\n            `and specify the inputs [${syncInputs}]`;\n      }\n      throw new Error(\n          `Cannot compute the outputs [${missingOutputs}] from the provided ` +\n          `inputs [${names}]. Consider providing the following inputs: ` +\n          `[${missingInputs}]. ${alternativeMsg}`);\n    }\n    return tensorsMap;\n  }\n\n  private processStack(\n      inputNodes: Node[], stack: NodeWithContexts[], context: ExecutionContext,\n      tensorMap: NamedTensorsMap, added: {[key: string]: boolean},\n      tensorsToKeep: Set<number>, outputNames: string[],\n      intermediateTensorConsumerCount: {[key: number]: number},\n      usedNodes: Set<string>) {\n    const promises: Array<Promise<Tensor[]>> = [];\n    while (stack.length > 0) {\n      const item = stack.pop();\n      context.currentContext = item.contexts;\n      let nodeName = '';\n      // The tensor of the Enter op with isConstant set should be set\n      // in the parent scope, so it will be available as constant for the\n      // whole loop.\n      if (item.node.op === 'Enter' &&\n          getParamValue('isConstant', item.node, tensorMap, context)) {\n        [nodeName] = getNodeNameAndIndex(item.node.name, context);\n      }\n\n      // only process nodes that are not provided as input nodes.\n      if (inputNodes.indexOf(item.node) === -1) {\n        const tensors = executeOp(item.node, tensorMap, context);\n        if (!nodeName) {\n          [nodeName] = getNodeNameAndIndex(item.node.name, context);\n        }\n        const currentContext = context.currentContext;\n        if (tensors instanceof Promise) {\n          promises.push(tensors.then(t => {\n            tensorMap[nodeName] = t;\n            context.currentContext = currentContext;\n            this.checkTensorForDisposal(\n                nodeName, item.node, tensorMap, context, tensorsToKeep,\n                outputNames, intermediateTensorConsumerCount);\n            this.processChildNodes(\n                item.node, stack, context, tensorMap, added, usedNodes);\n            return t;\n          }));\n        } else {\n          tensorMap[nodeName] = tensors;\n          this.checkTensorForDisposal(\n              nodeName, item.node, tensorMap, context, tensorsToKeep,\n              outputNames, intermediateTensorConsumerCount);\n          this.processChildNodes(\n              item.node, stack, context, tensorMap, added, usedNodes);\n        }\n      } else {\n        this.processChildNodes(\n            item.node, stack, context, tensorMap, added, usedNodes);\n      }\n    }\n    return promises;\n  }\n\n  private processChildNodes(\n      node: Node, stack: NodeWithContexts[], context: ExecutionContext,\n      tensorMap: NamedTensorsMap, added: {[key: string]: boolean},\n      usedNodes: Set<string>) {\n    node.children.forEach((childNode) => {\n      const [nodeName, ] = getNodeNameAndIndex(childNode.name, context);\n      if (added[nodeName] || !usedNodes.has(childNode.name)) {\n        return;\n      }\n      // Merge op can be pushed if any of its inputs has value.\n      if (childNode.op === 'Merge') {\n        if (childNode.inputNames.some(name => {\n              return !!getTensor(name, tensorMap, context);\n            })) {\n          added[nodeName] = true;\n          stack.push({contexts: context.currentContext, node: childNode});\n        }\n      } else  // Otherwise all inputs must to have value.\n          if (childNode.inputNames.every(name => {\n                return !!getTensor(name, tensorMap, context);\n              })) {\n        added[nodeName] = true;\n        stack.push({contexts: context.currentContext, node: childNode});\n      }\n    });\n  }\n\n  /**\n   * Releases the memory used by the weight tensors.\n   */\n  dispose() {\n    Object.keys(this.weightMap)\n        .forEach(\n            key => this.weightMap[key].forEach(tensor => tensor.dispose()));\n  }\n\n  private checkInputShapeAndType(inputs: NamedTensorMap) {\n    Object.keys(inputs).forEach(name => {\n      const input = inputs[name];\n      const node = this.graph.nodes[name];\n      if (node.attrParams['shape'] && node.attrParams['shape'].value) {\n        const shape = node.attrParams['shape'].value as number[];\n        const match = shape.length === input.shape.length &&\n            input.shape.every(\n                (dim, index) => shape[index] === -1 || shape[index] === dim);\n        util.assert(\n            match,\n            () => `The shape of dict['${node.name}'] provided in ` +\n                `model.execute(dict) must be [${shape}], but was ` +\n                `[${input.shape}]`);\n      }\n      if (node.attrParams['dtype'] && node.attrParams['dtype'].value) {\n        util.assert(\n            input.dtype === node.attrParams['dtype'].value as string,\n            () => `The dtype of dict['${node.name}'] provided in ` +\n                `model.execute(dict) must be ` +\n                `${node.attrParams['dtype'].value}, but was ${input.dtype}`);\n      }\n    });\n  }\n\n  private checkInputs(inputs: NamedTensorMap) {\n    const notInGraph =\n        Object.keys(inputs).filter(name => !this.graph.nodes[name]);\n    if (notInGraph.length > 0) {\n      throw new Error(\n          `The dict provided in model.execute(dict) has ` +\n          `keys: [${notInGraph}] that are not part of graph`);\n    }\n  }\n\n  private checkOutputs(outputs: string[]): void {\n    outputs.forEach(name => {\n      const [normalizedName] = parseNodeName(name);\n      if (!this.graph.nodes[normalizedName]) {\n        throw new Error(`The output '${name}' is not found in the graph`);\n      }\n    });\n  }\n}\n","\n/**\n * @license\n * Copyright 2019 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport {neg} from '@tensorflow/tfjs-core';\nimport {NamedTensorsMap} from '../data/types';\n\nimport {Graph, Node} from '../operations/types';\n\n/**\n * This graph rewrite rule tries to identify the PRelu structure generated by\n * tf.keras, and convert it to tfjs core prelu op.\n *\n * The formula of PReLU is:\n * f(x) = alpha * x for x < 0, f(x) = x for x >= 0.\n *\n * `x` is the input, and `alpha` is a trainable tensor which can be broadcasted\n * to the shape of `x`.\n *\n * There's no native PRelu op in TensorFlow, so tf.keras generates the following\n * structure which does the equivalent calculation:\n * f(x) = Relu(x) + (-alpha * Relu(-x))\n *\n * Practically, alpha is always a constant in the inference graph.\n * Therefore, we're looking for the structure:\n *\n * f(x) = Add(Relu(x), Mul(negative_alpha, Relu(Neg(x))))\n *\n * And generate the follow sub graph:\n * f(x) = Prelu(x, neg(negative_alpha))\n *\n * @param graph Graph, model graph object\n * @param weightMap NamedTensorsMap, the weight map for the executor.\n */\n\nexport function rewritePrelu(graph: Graph, weightMap: NamedTensorsMap) {\n  for (const key in graph.nodes) {\n    const addNode = graph.nodes[key];\n    if (addNode == null || addNode.op !== 'Add' && addNode.op !== 'AddV2' ||\n        addNode.inputNames.length !== 2) {\n      continue;\n    }\n\n    const reluNode = addNode.inputs.find(input => input.op === 'Relu');\n    if (reluNode == null || reluNode.inputNames.length !== 1) {\n      continue;\n    }\n\n    const mulOp = addNode.inputs.find(input => input.op === 'Mul');\n    if (mulOp == null || mulOp.inputNames.length !== 2) {\n      continue;\n    }\n\n    const negAlphaTensorNode = mulOp.inputs.find(input => input.op === 'Const');\n\n    const reluNegInputNode = mulOp.inputs.find(input => input.op === 'Relu');\n\n    if (negAlphaTensorNode == null || reluNegInputNode == null ||\n        reluNegInputNode.inputNames.length !== 1) {\n      continue;\n    }\n\n    // This detects a Neg op followed by a separated Relu op.\n    const negInputNode = reluNegInputNode.inputs[0];\n    if (negInputNode == null || negInputNode.op !== 'Neg' ||\n        negInputNode.inputNames.length !== 1) {\n      continue;\n    }\n\n    if (reluNode.inputNames[0] !== negInputNode.inputNames[0]) {\n      continue;\n    }\n\n    const inputNode = reluNode.inputs[0];\n    const outputNodes = addNode.children;\n\n    // Construct a tensor for positive alpha (double negative).\n    const alphaTensorName = negAlphaTensorNode.name + '_neg';\n\n    const negNode: Node = {\n      name: alphaTensorName,\n      inputNames: [],\n      inputs: [],\n      attrParams: {},\n      category: 'graph',\n      children: [],\n      op: 'Const',\n      inputParams: {},\n      rawAttrs: {}\n    };\n\n    // Add the constant to weightMap\n    weightMap[alphaTensorName] = [neg(weightMap[negAlphaTensorNode.name][0])];\n    graph.weights.push(negNode);\n\n    // Construct the prelu node\n    const preluNode: Node = {\n      name: addNode.name + '_Prelu',\n      inputNames: [inputNode.name, negNode.name],\n      inputs: [inputNode, negNode],\n      attrParams: {},\n      category: 'custom',\n      children: outputNodes,\n      op: 'Prelu',\n      inputParams: {\n        'x': {inputIndexStart: 0, type: 'tensor'},\n        'alpha': {inputIndexStart: 1, type: 'tensor'}\n      }\n    };\n\n    negNode.children.push(preluNode);\n\n    // Clean up the children and inputs of input/output nodes of the subgraph.\n    const mulIndex = negAlphaTensorNode.children.indexOf(mulOp);\n    if (mulIndex > -1) {\n      negAlphaTensorNode.children.splice(mulIndex, 1);\n    }\n\n    const reluIndex = inputNode.children.indexOf(reluNode);\n    if (reluIndex > -1) {\n      inputNode.children.splice(reluIndex, 1);\n    }\n\n    const negIndex = inputNode.children.indexOf(negInputNode);\n    if (negIndex > -1) {\n      inputNode.children.splice(negIndex, 1);\n    }\n    inputNode.children.push(preluNode);\n\n    outputNodes.forEach(node => {\n      const addIndex = node.inputNames.indexOf(addNode.name);\n      if (addIndex > -1) {\n        node.inputNames[addIndex] = preluNode.name;\n        node.inputs[addIndex] = preluNode;\n      }\n    });\n\n    // The prelu node should be an output node.\n    if (outputNodes.length === 0) {\n      const addIndex = graph.outputs.indexOf(addNode);\n      if (addIndex > -1) {\n        graph.outputs.splice(addIndex, 1);\n      }\n      graph.outputs.push(preluNode);\n    }\n    // remove the nodes for keras generated prelu subgraph.\n    delete graph.nodes[addNode.name];\n    delete graph.nodes[mulOp.name];\n    delete graph.nodes[reluNode.name];\n    delete graph.nodes[reluNegInputNode.name];\n    delete graph.nodes[negInputNode.name];\n\n    // add the newly generated nodes.\n    graph.nodes[preluNode.name] = preluNode;\n    graph.nodes[negNode.name] = negNode;\n  }\n}\n","/**\n * @license\n * Copyright 2018 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport * as tf from '@tensorflow/tfjs-core';\nimport {InferenceModel, io, ModelPredictConfig, NamedTensorMap, Tensor} from '@tensorflow/tfjs-core';\n\nimport * as tensorflow from '../data/compiled_api';\nimport {NamedTensorsMap, TensorInfo} from '../data/types';\nimport {getRegisteredOp, registerOp} from '../operations/custom_op/register';\nimport {OperationMapper} from '../operations/operation_mapper';\n\nimport {GraphExecutor} from './graph_executor';\n\nexport const TFHUB_SEARCH_PARAM = '?tfjs-format=file';\nexport const DEFAULT_MODEL_NAME = 'model.json';\n/**\n * A `tf.GraphModel` is a directed, acyclic graph of built from\n * SavedModel GraphDef and allows inference exeuction.\n *\n * A `tf.GraphModel` can only be created by loading from a model converted from\n * a [TensorFlow SavedModel](https://www.tensorflow.org/guide/saved_model) using\n * the command line converter tool and loaded via `tf.loadGraphModel`.\n */\n/** @doc {heading: 'Models', subheading: 'Classes'} */\nexport class GraphModel implements InferenceModel {\n  private executor: GraphExecutor;\n  private version = 'n/a';\n  private handler: io.IOHandler;\n  // Returns the version information for the tensorflow model GraphDef.\n  get modelVersion(): string {\n    return this.version;\n  }\n\n  get inputNodes(): string[] {\n    return this.executor.inputNodes;\n  }\n\n  get outputNodes(): string[] {\n    return this.executor.outputNodes;\n  }\n\n  get inputs(): TensorInfo[] {\n    return this.executor.inputs;\n  }\n\n  get outputs(): TensorInfo[] {\n    return this.executor.outputs;\n  }\n\n  get weights(): NamedTensorsMap {\n    return this.executor.weightMap;\n  }\n\n  /**\n   * @param modelUrl url for the model, or an `io.IOHandler`.\n   * @param weightManifestUrl url for the weight file generated by\n   * scripts/convert.py script.\n   * @param requestOption options for Request, which allows to send credentials\n   * and custom headers.\n   * @param onProgress Optional, progress callback function, fired periodically\n   * before the load is completed.\n   */\n  constructor(\n      private modelUrl: string|io.IOHandler,\n      private loadOptions: io.LoadOptions = {}) {\n    if (loadOptions == null) {\n      this.loadOptions = {};\n    }\n  }\n\n  /**\n   * There's no native PRelu op in TensorFlow, so Keras generates the following\n   * structure which does the equivalent calculation:\n   * f(x) = Relu(x) + (-alpha * Relu(-x))\n   * Since tfjs-core has a prelu op, this method will fuse the TensorFlow\n   * generated ops into prelu op. It will also try to register a custom op that\n   * supports prelu op.\n   */\n  public fusePrelu() {\n    this.executor.fusePrelu();\n    if (getRegisteredOp('Prelu') == null) {\n      registerOp('Prelu', (node) => {\n        const x = node.inputs[0];\n        const alpha = node.inputs[1];\n        return tf.prelu(x, alpha);\n      });\n    }\n  }\n\n  private findIOHandler() {\n    const path = this.modelUrl;\n    if ((path as io.IOHandler).load != null) {\n      // Path is an IO Handler.\n      this.handler = path as io.IOHandler;\n    } else if (this.loadOptions.requestInit != null) {\n      this.handler = io.browserHTTPRequest(path as string, this.loadOptions);\n    } else {\n      const handlers =\n          io.getLoadHandlers(path as string, this.loadOptions.onProgress);\n      if (handlers.length === 0) {\n        // For backward compatibility: if no load handler can be found,\n        // assume it is a relative http path.\n        handlers.push(io.browserHTTPRequest(path as string, this.loadOptions));\n      } else if (handlers.length > 1) {\n        throw new Error(\n            `Found more than one (${handlers.length}) load handlers for ` +\n            `URL '${[path]}'`);\n      }\n      this.handler = handlers[0];\n    }\n  }\n\n  /**\n   * Loads the model and weight files, construct the in memory weight map and\n   * compile the inference graph.\n   */\n  async load(): Promise<boolean> {\n    this.findIOHandler();\n    if (this.handler.load == null) {\n      throw new Error(\n          'Cannot proceed with model loading because the IOHandler provided ' +\n          'does not have the `load` method implemented.');\n    }\n    const artifacts = await this.handler.load();\n    const graph = artifacts.modelTopology as tensorflow.IGraphDef;\n\n    this.version = `${graph.versions.producer}.${graph.versions.minConsumer}`;\n    const weightMap =\n        io.decodeWeights(artifacts.weightData, artifacts.weightSpecs);\n    this.executor =\n        new GraphExecutor(OperationMapper.Instance.transformGraph(graph));\n    this.executor.weightMap = this.convertTensorMapToTensorsMap(weightMap);\n    return true;\n  }\n\n  /**\n   * Execute the inference for the input tensors.\n   *\n   * @param input The input tensors, when there is single input for the model,\n   * inputs param should be a `tf.Tensor`. For models with mutliple inputs,\n   * inputs params should be in either `tf.Tensor`[] if the input order is\n   * fixed, or otherwise NamedTensorMap format.\n   *\n   * For model with multiple inputs, we recommend you use NamedTensorMap as the\n   * input type, if you use `tf.Tensor`[], the order of the array needs to\n   * follow the\n   * order of inputNodes array. @see {@link GraphModel.inputNodes}\n   *\n   * You can also feed any intermediate nodes using the NamedTensorMap as the\n   * input type. For example, given the graph\n   *    InputNode => Intermediate => OutputNode,\n   * you can execute the subgraph Intermediate => OutputNode by calling\n   *    model.execute('IntermediateNode' : tf.tensor(...));\n   *\n   * This is useful for models that uses tf.dynamic_rnn, where the intermediate\n   * state needs to be fed manually.\n   *\n   * For batch inference execution, the tensors for each input need to be\n   * concatenated together. For example with mobilenet, the required input shape\n   * is [1, 244, 244, 3], which represents the [batch, height, width, channel].\n   * If we are provide a batched data of 100 images, the input tensor should be\n   * in the shape of [100, 244, 244, 3].\n   *\n   * @param config Prediction configuration for specifying the batch size and\n   * output node names. Currently the batch size option is ignored for graph\n   * model.\n   *\n   * @returns Inference result tensors. The output would be single `tf.Tensor`\n   * if model has single output node, otherwise Tensor[] or NamedTensorMap[]\n   * will be returned for model with multiple outputs.\n   */\n  /** @doc {heading: 'Models', subheading: 'Classes'} */\n  predict(inputs: Tensor|Tensor[]|NamedTensorMap, config?: ModelPredictConfig):\n      Tensor|Tensor[]|NamedTensorMap {\n    return this.execute(inputs, this.outputNodes);\n  }\n\n  private normalizeInputs(inputs: Tensor|Tensor[]|\n                          NamedTensorMap): NamedTensorMap {\n    if (!(inputs instanceof Tensor) && !Array.isArray(inputs)) {\n      // The input is already a NamedTensorMap.\n      return inputs;\n    }\n    inputs = Array.isArray(inputs) ? inputs : [inputs];\n    if (inputs.length !== this.inputNodes.length) {\n      throw new Error(\n          'Input tensor count mismatch,' +\n          `the graph model has ${this.inputNodes.length} placeholders, ` +\n          `while there are ${inputs.length} input tensors.`);\n    }\n    return this.inputNodes.reduce((map, inputName, i) => {\n      map[inputName] = (inputs as Tensor[])[i];\n      return map;\n    }, {} as NamedTensorMap);\n  }\n\n  private normalizeOutputs(outputs: string|string[]): string[] {\n    outputs = outputs || this.outputNodes;\n    return !Array.isArray(outputs) ? [outputs] : outputs;\n  }\n\n  /**\n   * Executes inference for the model for given input tensors.\n   * @param inputs tensor, tensor array or tensor map of the inputs for the\n   * model, keyed by the input node names.\n   * @param outputs output node name from the Tensorflow model, if no\n   * outputs are specified, the default outputs of the model would be used.\n   * You can inspect intermediate nodes of the model by adding them to the\n   * outputs array.\n   *\n   * @returns A single tensor if provided with a single output or no outputs\n   * are provided and there is only one default output, otherwise return a\n   * tensor array. The order of the tensor array is the same as the outputs\n   * if provided, otherwise the order of outputNodes attribute of the model.\n   */\n  /** @doc {heading: 'Models', subheading: 'Classes'} */\n  execute(inputs: Tensor|Tensor[]|NamedTensorMap, outputs?: string|string[]):\n      Tensor|Tensor[] {\n    inputs = this.normalizeInputs(inputs);\n    outputs = this.normalizeOutputs(outputs);\n    const result = this.executor.execute(inputs, outputs);\n    return result.length > 1 ? result : result[0];\n  }\n  /**\n   * Executes inference for the model for given input tensors in async\n   * fashion, use this method when your model contains control flow ops.\n   * @param inputs tensor, tensor array or tensor map of the inputs for the\n   * model, keyed by the input node names.\n   * @param outputs output node name from the Tensorflow model, if no outputs\n   * are specified, the default outputs of the model would be used. You can\n   * inspect intermediate nodes of the model by adding them to the outputs\n   * array.\n   *\n   * @returns A Promise of single tensor if provided with a single output or\n   * no outputs are provided and there is only one default output, otherwise\n   * return a tensor map.\n   */\n  /** @doc {heading: 'Models', subheading: 'Classes'} */\n  async executeAsync(\n      inputs: Tensor|Tensor[]|NamedTensorMap,\n      outputs?: string|string[]): Promise<Tensor|Tensor[]> {\n    inputs = this.normalizeInputs(inputs);\n    outputs = this.normalizeOutputs(outputs);\n    const result = await this.executor.executeAsync(inputs, outputs);\n    return result.length > 1 ? result : result[0];\n  }\n\n  private convertTensorMapToTensorsMap(map: NamedTensorMap): NamedTensorsMap {\n    return Object.keys(map).reduce((newMap: NamedTensorsMap, key) => {\n      newMap[key] = [map[key]];\n      return newMap;\n    }, {});\n  }\n\n  /**\n   * Releases the memory used by the weight tensors.\n   */\n  /** @doc {heading: 'Models', subheading: 'Classes'} */\n  dispose() {\n    this.executor.dispose();\n  }\n}\n\n/**\n * Load a graph model given a URL to the model definition.\n *\n * Example of loading MobileNetV2 from a URL and making a prediction with a\n * zeros input:\n *\n * ```js\n * const modelUrl =\n *    'https://storage.googleapis.com/tfjs-models/savedmodel/mobilenet_v2_1.0_224/model.json';\n * const model = await tf.loadGraphModel(modelUrl);\n * const zeros = tf.zeros([1, 224, 224, 3]);\n * model.predict(zeros).print();\n * ```\n *\n * Example of loading MobileNetV2 from a TF Hub URL and making a prediction with\n * a zeros input:\n *\n * ```js\n * const modelUrl =\n *    'https://tfhub.dev/google/imagenet/mobilenet_v2_140_224/classification/2';\n * const model = await tf.loadGraphModel(modelUrl, {fromTFHub: true});\n * const zeros = tf.zeros([1, 224, 224, 3]);\n * model.predict(zeros).print();\n * ```\n * @param modelUrl The url or an `io.IOHandler` that loads the model.\n * @param options Options for the HTTP request, which allows to send credentials\n *    and custom headers.\n */\n/** @doc {heading: 'Models', subheading: 'Loading'} */\nexport async function loadGraphModel(\n    modelUrl: string|io.IOHandler,\n    options: io.LoadOptions = {}): Promise<GraphModel> {\n  if (modelUrl == null) {\n    throw new Error(\n        'modelUrl in loadGraphModel() cannot be null. Please provide a url ' +\n        'or an IOHandler that loads the model');\n  }\n  if (options == null) {\n    options = {};\n  }\n\n  if (options.fromTFHub) {\n    if ((modelUrl as io.IOHandler).load == null) {\n      if (!(modelUrl as string).endsWith('/')) {\n        modelUrl = (modelUrl as string) + '/';\n      }\n      modelUrl = `${modelUrl}${DEFAULT_MODEL_NAME}${TFHUB_SEARCH_PARAM}`;\n    }\n  }\n  const model = new GraphModel(modelUrl, options);\n  await model.load();\n  return model;\n}\n","/** @license See the LICENSE file. */\n\n// This code is auto-generated, do not modify this file!\nconst version = '1.2.8';\nexport {version};\n"],"names":["DataType","SaverDef","CUSTOM_OPS","registerOp","name","opFunc","opMapper","tfOpName","category","inputs","attrs","customExecutor","getRegisteredOp","getParamValue","paramName","node","tensorMap","context","inputParam","inputParams","undefined","inputIndexStart","start","end","inputIndexEnd","type","getTensor","inputNames","slice","map","data","Array","prototype","call","dataSync","attrParam","attrParams","value","tensorsMap","_a","nodeName","index","contextId","currentContextIds","find","getNodeNameWithContextId","getNodeNameAndIndex","inputName","currentContextId","parseNodeName","lastIndexOf","substring","Number","split","arr","size","res","i","length","push","CheckpointFormatVersion","tfName","notSupported","defaultValue","tfDeprecatedName","ops","arithmetic","basicMath","control","convolution","creation","dynamic","evaluation","logical","image","graph","matrices","normalization","reduction","sliceJoin","spectral","transformation","mappersJson","concat","apply","op","json","this","opMappers","reduce","mapper","Object","OperationMapper","_instance","placeholders","weights","nodes","_this","mapNode","outputs","allNodes","keys","forEach","key","children","attr","newNode","input","startsWith","substr","rawAttrs","param","getStringParam","getStringArrayParam","getNumberParam","getNumericArrayParam","getBoolParam","getBoolArrayParam","getTensorShapeParam","getTensorShapeArrayParam","getDtypeParam","getDtypeArrayParam","Error","parseStringParam","s","keepCase","isArray","String","fromCharCode","text","global","ENV","atob","Buffer","toString","decodeBase64","toLowerCase","def","b","parseInt","parseDtypeParam","tensorflow.DataType","DT_FLOAT","DT_INT32","DT_BOOL","DT_DOUBLE","DT_STRING","list","v","parseTensorShapeParam","shape","unknownRank","dim","f","getInput","getAttr","NodeValueImpl","tensor","executeOp","tfc.add","tfc.addN","tfc.mod","tfc.mul","tfc.div","tfc.floorDiv","tfc.sub","tfc.minimum","tfc.maximum","tfc.pow","tfc.squaredDifference","TypeError","tfc.abs","tfc.acos","tfc.acosh","tfc.asin","tfc.asinh","tfc.atan","tfc.atan2","tfc.atanh","tfc.ceil","tfc.complex","tfc.cos","tfc.cosh","tfc.elu","tfc.erf","tfc.exp","tfc.expm1","tfc.floor","tfc.log","tfc.log1p","tfc.imag","tfc.neg","tfc.reciprocal","tfc.real","tfc.relu","tfc.round","tfc.selu","tfc.sigmoid","tfc.sin","tfc.sign","tfc.sinh","tfc.softplus","tfc.sqrt","tfc.square","tfc.tanh","tfc.tan","tfc.clipByValue","tfc.rsqrt","tfc.prod","tfc.leakyRelu","dtype","maxSize","elementShape","identicalElementShapes","dynamicSize","clearAfterRead","id","TensorArray","nextId","closed_","tensors","dispose","tensorWithState","cleared","read","indices","t","assertShapesMatchAllowUndefinedSize","written","write","readMany","stack","maxIndex","Math","max","writeMany","unstack","totalLength","cumulativeLengths","len","elementPerRow","tidy","reshape","indices_1","sizes","shapeA","shapeB","errorMessagePrefix","util","assert","shapesEqualAllowUndefinedSize","n1","n2","stride","pad","dataFormat","toUpperCase","dilation","tfc.conv1d","dilations","tfc.conv2d","tfc.conv2dTranspose","tfc.depthwiseConv2d","tfc.conv3d","kernelSize","tfc.avgPool","tfc.maxPool","tfc.avgPool3d","tfc.maxPool3d","tfc.fill","stop_1","num","tfc.linspace","depth","onValue","offValue","tfc.oneHot","tfc.ones","tfc.onesLike","tfc.randomUniform","stop_2","step","tfc.range","mean","stdDev","seed","tfc.truncatedNormal","tfc.zeros","tfc.zerosLike","x","k","sorted","result","tfc.topk","values","clone","tfc.tensor1d","tfc.scalar","rank","message","summarize","console","warn","log","images","alignCorners","tfc.image","resizeBilinear","resizeNearestNeighbor","boxes","boxInd","cropSize","method","extrapolationValue","cropAndResize","tfc.equal","tfc.notEqual","tfc.greater","tfc.greaterEqual","tfc.less","tfc.lessEqual","tfc.logicalAnd","tfc.logicalNot","tfc.logicalOr","tfc.where","tfc.matMul","tfc.transpose","tfc.batchNorm","tfc.localResponseNormalization","tfc.softmax","tfc.logSoftmax","tfc.sparseToDense","axis","keepDims","tfc.max","tfc.mean","tfc.min","tfc.sum","tfc.all","tfc.any","tfc.argMax","tfc.argMin","tfc.concat","tfc.gather","asType","tfc.reverse","begin","tfc.slice","strides","beginMask","endMask","ellipsisMask","newAxisMask","shrinkAxisMask","tfc.stridedSlice","tfc.tidy","squeezedShape","squeeze","mapped","sameShape","tfc.util","arraysEqual","tfc.stack","tfc.unstack","reps","tfc.tile","numOrSizeSplits","tfc.split","tfc.scatterND","tfc.gatherND","sparseValues","tfc.fft","tfc.ifft","tfc.rfft","tfc.irfft","tfc.cast","tfc.expandDims","tfc.squeeze","tfc.reshape","tfc.pad","blockShape","paddings","tfc.spaceToBatchND","crops","tfc.batchToSpaceND","blockSize","tfc.depthToSpace","arithmetic.executeOp","basicMath.executeOp","pred","data_1","_b","frameId","enterFrame","exitFrame","nextIteration","name_1","tensorArray","addTensorArray","scalar","writeTensor","getTensorArray","readId","readIndex","gatherId","gatherIndices","gatherDtype","gather","scatterId","scatterIndices","scatterTensor","scatter","concatId","concatTensorArray","concatDtype","splitId","splitTensor","lengths","sizeId","sizeTensorArray","closeId","clearAndClose","control.executeOp","convolution.executeOp","creation.executeOp","scores","maxOutputSize","iouThreshold","scoreThreshold","nonMaxSuppressionAsync","tfc.whereAsync","tfc.setdiff1dAsync","dynamic.executeOp","evaluation.executeOp","image.executeOp","graph.executeOp","logical.executeOp","matrices.executeOp","normalization.executeOp","reduction.executeOp","sliceJoin.executeOp","spectral.executeOp","transformation.executeOp","Promise","then","weightMap","tensorArrayMap","frameName","iterationId","rootContext","generateCurrentContextIds","ExecutionContext","contexts","_currentContextIds","names","contextIdforContexts","join","lastId","newFrame","unshift","splice","shift","assign","getExecutionSubgraph","usedNodes","Set","missingInputs","dynamicNode","syncInputs","seen","frontier","pop","isControlFlow","isDynamicShape","child","filter","has","add","CONTROL_FLOW_OPS","DYNAMIC_SHAPE_OPS","indexOf","Map","_outputs","GraphExecutor","_weightMap","weightIds","sortedInputs","sort","sortedOutputs","SEPERATOR","executionInfo","outNames","n","inNames","weight","orderedNodes","every","getNodesInTopologicalOrder","addNode","reluNode","mulOp","negAlphaTensorNode","reluNegInputNode","negInputNode","inputNode","outputNodes","alphaTensorName","negNode","neg","preluNode","alpha","mulIndex","reluIndex","negIndex","addIndex","rewritePrelu","checkInputs","checkInputShapeAndType","checkOutputs","inputNodes","compilationKey","getCompilationKey","compiledMap","get","compile","set","tensorsToKeep","getFrozenTensorIds","intermediateTensorConsumerCount","checkTensorForDisposal","ids","outputNames","getTensorsForCurrentContenxt","count","executeWithControlFlow","results","outputIds","inputIds","isDisposed","currentContext","added","promises","processStack","all","missingOutputs","alternativeMsg","item","currentContext_1","processChildNodes","this_1","childNode","some","shape_1","match","notInGraph","normalizedName","TFHUB_SEARCH_PARAM","DEFAULT_MODEL_NAME","modelUrl","loadOptions","GraphModel","version","executor","fusePrelu","tf.prelu","path","load","handler","requestInit","io","browserHTTPRequest","handlers","getLoadHandlers","onProgress","findIOHandler","artifacts","modelTopology","versions","producer","minConsumer","decodeWeights","weightData","weightSpecs","Instance","transformGraph","convertTensorMapToTensorsMap","config","execute","Tensor","normalizeInputs","normalizeOutputs","executeAsync","newMap","options","fromTFHub","endsWith","model"],"mappings":";;;;;;;;;;;;;;;;wvDAoBA,ICQYA,EAyRKC,EDjSXC,cA0BUC,EAAWC,EAAcC,GACvC,IAAMC,GACJC,SAAUH,EACVI,SAAU,SACVC,UACAC,SACAC,eAAgBN,GAGlBH,EAAWE,GAAQE,WAULM,EAAgBR,GAC9B,OAAOF,EAAWE,YE3CJS,EACZC,EAAmBC,EAAYC,EAC/BC,GACF,IAAMC,EAAaH,EAAKI,YAAYL,GACpC,GAAII,QAA6CE,IAA/BF,EAAWG,gBAA+B,CAC1D,IAAMC,EAAQJ,EAAWG,gBACnBE,EAAmC,IAA7BL,EAAWM,mBACnBJ,OAC8BA,IAA7BF,EAAWM,cAA8BF,EAAQ,EACRJ,EAAWM,cACzD,GAAwB,WAApBN,EAAWO,KACb,OAAOC,EACHX,EAAKY,WAAWT,EAAWG,iBAAkBL,EAAWC,GAE9D,GAAwB,YAApBC,EAAWO,KAGb,OAFeV,EAAKY,WAAWC,MAAMN,EAAOC,GAE9BM,IAAI,SAAAzB,GAAQ,OAAAsB,EAAUtB,EAAMY,EAAWC,KAEvD,IAAMa,EAAOC,MAAMC,UAAUJ,MAAMK,KAC/BP,EAAUX,EAAKY,WAAWC,MAAMN,GAAO,GAAIN,EAAWC,GACjDiB,YACT,MAA2B,WAApBhB,EAAWO,KAAoBK,EAAK,GAAKA,EAElD,IAAMK,EAAYpB,EAAKqB,WAAWtB,GAClC,OAAOqB,GAAaA,EAAUE,eAShBX,EACZtB,EAAckC,EACdrB,GACI,IAAAsB,OAACC,OAAUC,OACXC,EAAYzB,EAAQ0B,kBAAkBC,KAAK,SAAAF,GAC/C,QAASJ,EAAWO,EAAyBL,EAAUE,MAGzD,YAAqBtB,IAAdsB,EACHJ,EAAWO,EAAyBL,EAAUE,IAAYD,QAC1DrB,WAoBU0B,EACZC,EAAmB9B,GACf,IAAAsB,OAACC,OAAUC,OAEjB,OACEI,EAAyBL,EAAUvB,GAAWA,EAAQ+B,kBACtDP,GAIJ,SAASI,EAAyBzC,EAAcsC,GAC9C,OAASA,EAAetC,MAAQsC,EAActC,WAGhC6C,EAAc7C,GAC5B,IAAMqC,EAAQrC,EAAK8C,YAAY,KAC/B,OAAe,IAAXT,GAAsBrC,EAAM,IAEfA,EAAK+C,UAAU,EAAGV,GACjBW,OAAOhD,EAAK+C,UAAUV,EAAQ,cAGlCY,EAAMC,EAAeC,GAEnC,IADA,IAAMC,KACGC,EAAI,EAAGA,EAAIH,EAAII,OAAQD,GAAKF,EACnCC,EAAIG,KAAKL,EAAI1B,MAAM6B,EAAGA,EAAIF,IAE5B,OAAOC,GDtFT,SAAYxD,GACVA,+BACAA,2BACAA,6BACAA,2BACAA,2BACAA,2BACAA,yBACAA,6BACAA,mCACAA,2BACAA,0BACAA,4BACAA,8BACAA,8BACAA,kCACAA,qCACAA,uCACAA,qCACAA,qCACAA,qCACAA,mCACAA,uCACAA,6CACAA,qCACAA,mCACAA,qCACAA,uCACAA,uCACAA,2CA7BF,CAAYA,IAAAA,OAyRZ,SAAiBC,IAEf,SAAY2D,GAAyBA,uBAAYA,eAAQA,eAAzD,CAAY3D,4BAAAA,+BAFd,CAAiBA,IAAAA,OElSV,4BAEHM,SAAY,MACZC,SAAY,aACZC,SACGa,MAAS,EAAGlB,KAAQ,IAAKqB,KAAQ,WACjCH,MAAS,EAAGlB,KAAQ,IAAKqB,KAAQ,WAEpCf,QACGmD,OAAU,IAAKzD,KAAQ,QAASqB,KAAQ,QAASqC,cAAgB,MAIpEvD,SAAY,QACZC,SAAY,aACZC,SACGa,MAAS,EAAGlB,KAAQ,IAAKqB,KAAQ,WACjCH,MAAS,EAAGlB,KAAQ,IAAKqB,KAAQ,WAEpCf,QACGmD,OAAU,IAAKzD,KAAQ,QAASqB,KAAQ,QAASqC,cAAgB,MAIpEvD,SAAY,OACZC,SAAY,aACZC,SAAYa,MAAS,EAAGC,IAAO,EAAGnB,KAAQ,UAAWqB,KAAQ,cAG7DlB,SAAY,UACZC,SAAY,aACZC,SACGa,MAAS,EAAGlB,KAAQ,IAAKqB,KAAQ,WACjCH,MAAS,EAAGlB,KAAQ,IAAKqB,KAAQ,WAEpCf,QACGmD,OAAU,IAAKzD,KAAQ,QAASqB,KAAQ,QAASqC,cAAgB,MAIpEvD,SAAY,MACZC,SAAY,aACZC,SACGa,MAAS,EAAGlB,KAAQ,IAAKqB,KAAQ,WACjCH,MAAS,EAAGlB,KAAQ,IAAKqB,KAAQ,WAEpCf,QACGmD,OAAU,IAAKzD,KAAQ,QAASqB,KAAQ,QAASqC,cAAgB,MAIpEvD,SAAY,UACZC,SAAY,aACZC,SACGa,MAAS,EAAGlB,KAAQ,IAAKqB,KAAQ,WACjCH,MAAS,EAAGlB,KAAQ,IAAKqB,KAAQ,WAEpCf,QACGmD,OAAU,IAAKzD,KAAQ,QAASqB,KAAQ,QAASqC,cAAgB,MAIpEvD,SAAY,MACZC,SAAY,aACZC,SACGa,MAAS,EAAGlB,KAAQ,IAAKqB,KAAQ,WACjCH,MAAS,EAAGlB,KAAQ,IAAKqB,KAAQ,WAEpCf,QACGmD,OAAU,IAAKzD,KAAQ,QAASqB,KAAQ,QAASqC,cAAgB,MAIpEvD,SAAY,WACZC,SAAY,aACZC,SACGa,MAAS,EAAGlB,KAAQ,IAAKqB,KAAQ,WACjCH,MAAS,EAAGlB,KAAQ,IAAKqB,KAAQ,WAEpCf,QACGmD,OAAU,IAAKzD,KAAQ,QAASqB,KAAQ,QAASqC,cAAgB,MAIpEvD,SAAY,MACZC,SAAY,aACZC,SACGa,MAAS,EAAGlB,KAAQ,IAAKqB,KAAQ,WACjCH,MAAS,EAAGlB,KAAQ,IAAKqB,KAAQ,WAEpCf,QACGmD,OAAU,IAAKzD,KAAQ,QAASqB,KAAQ,QAASqC,cAAgB,MAIpEvD,SAAY,UACZC,SAAY,aACZC,SACGa,MAAS,EAAGlB,KAAQ,IAAKqB,KAAQ,WACjCH,MAAS,EAAGlB,KAAQ,IAAKqB,KAAQ,aAIpClB,SAAY,UACZC,SAAY,aACZC,SACGa,MAAS,EAAGlB,KAAQ,IAAKqB,KAAQ,WACjCH,MAAS,EAAGlB,KAAQ,IAAKqB,KAAQ,aAIpClB,SAAY,MACZC,SAAY,aACZC,SACGa,MAAS,EAAGlB,KAAQ,IAAKqB,KAAQ,WACjCH,MAAS,EAAGlB,KAAQ,IAAKqB,KAAQ,WAEpCf,QACGmD,OAAU,IAAKzD,KAAQ,QAASqB,KAAQ,QAASqC,cAAgB,MAIpEvD,SAAY,oBACZC,SAAY,aACZC,SACGa,MAAS,EAAGlB,KAAQ,IAAKqB,KAAQ,WACjCH,MAAS,EAAGlB,KAAQ,IAAKqB,KAAQ,WAEpCf,QACGmD,OAAU,IAAKzD,KAAQ,QAASqB,KAAQ,QAASqC,cAAgB,MAIpEvD,SAAY,MACZC,SAAY,aACZC,SACGa,MAAS,EAAGlB,KAAQ,IAAKqB,KAAQ,WACjCH,MAAS,EAAGlB,KAAQ,IAAKqB,KAAQ,WAEpCf,QACGmD,OAAU,IAAKzD,KAAQ,QAASqB,KAAQ,QAASqC,cAAgB,MAIpEvD,SAAY,WACZC,SAAY,aACZC,SACGa,MAAS,EAAGlB,KAAQ,IAAKqB,KAAQ,WACjCH,MAAS,EAAGlB,KAAQ,IAAKqB,KAAQ,WAEpCf,QACEmD,OAAU,IACVzD,KAAQ,QACRqB,KAAQ,QACRqC,cAAgB,gCCxJlBvD,SAAY,MACZC,SAAY,aACZC,SACGa,MAAS,EAAGlB,KAAQ,IAAKqB,KAAQ,WAEpCf,QACGmD,OAAU,IAAKzD,KAAQ,QAASqB,KAAQ,QAASqC,cAAgB,MAIpEvD,SAAY,OACZC,SAAY,aACZC,SACGa,MAAS,EAAGlB,KAAQ,IAAKqB,KAAQ,WAEpCf,QACGmD,OAAU,IAAKzD,KAAQ,QAASqB,KAAQ,QAASqC,cAAgB,MAIpEvD,SAAY,OACZC,SAAY,aACZC,SACGa,MAAS,EAAGlB,KAAQ,IAAKqB,KAAQ,WAEpCf,QACGmD,OAAU,IAAKzD,KAAQ,QAASqB,KAAQ,QAASqC,cAAgB,MAIpEvD,SAAY,OACZC,SAAY,aACZC,SACGa,MAAS,EAAGlB,KAAQ,IAAKqB,KAAQ,WAEpCf,QACGmD,OAAU,IAAKzD,KAAQ,QAASqB,KAAQ,QAASqC,cAAgB,MAIpEvD,SAAY,QACZC,SAAY,aACZC,SACGa,MAAS,EAAGlB,KAAQ,IAAKqB,KAAQ,WACjCH,MAAS,EAAGlB,KAAQ,IAAKqB,KAAQ,WAEpCf,QACGmD,OAAU,IAAKzD,KAAQ,QAASqB,KAAQ,QAASqC,cAAgB,MAIpEvD,SAAY,OACZC,SAAY,aACZC,SACGa,MAAS,EAAGlB,KAAQ,IAAKqB,KAAQ,WAEpCf,QACGmD,OAAU,IAAKzD,KAAQ,QAASqB,KAAQ,QAASqC,cAAgB,MAIpEvD,SAAY,cACZC,SAAY,aACZC,SACGa,MAAS,EAAGlB,KAAQ,IAAKqB,KAAQ,WAEpCf,QACGmD,OAAU,iBAAkBzD,KAAQ,eAAgBqB,KAAQ,WAC5DoC,OAAU,iBAAkBzD,KAAQ,eAAgBqB,KAAQ,aAI/DlB,SAAY,UACZC,SAAY,aACZC,SACGa,MAAS,EAAGlB,KAAQ,OAAQqB,KAAQ,WACpCH,MAAS,EAAGlB,KAAQ,OAAQqB,KAAQ,WAEvCf,QACGmD,OAAU,IAAKzD,KAAQ,QAASqB,KAAQ,QAASqC,cAAgB,MAIpEvD,SAAY,aACZC,SAAY,aACZC,SACGa,MAAS,EAAGlB,KAAQ,IAAKqB,KAAQ,WAEpCf,QACGmD,OAAU,IAAKzD,KAAQ,QAASqB,KAAQ,QAASqC,cAAgB,MAIpEvD,SAAY,MACZC,SAAY,aACZC,SACGa,MAAS,EAAGlB,KAAQ,IAAKqB,KAAQ,WAEpCf,QACGmD,OAAU,IAAKzD,KAAQ,QAASqB,KAAQ,QAASqC,cAAgB,MAIpEvD,SAAY,OACZC,SAAY,aACZC,SACGa,MAAS,EAAGlB,KAAQ,IAAKqB,KAAQ,WAEpCf,QACGmD,OAAU,IAAKzD,KAAQ,QAASqB,KAAQ,QAASqC,cAAgB,MAIpEvD,SAAY,MACZC,SAAY,aACZC,SACGa,MAAS,EAAGlB,KAAQ,IAAKqB,KAAQ,WAEpCf,QACGmD,OAAU,IAAKzD,KAAQ,QAASqB,KAAQ,QAASqC,cAAgB,MAIpEvD,SAAY,MACZC,SAAY,aACZC,SACGa,MAAS,EAAGlB,KAAQ,IAAKqB,KAAQ,WAEpCf,QACGmD,OAAU,IAAKzD,KAAQ,QAASqB,KAAQ,QAASqC,cAAgB,MAIpEvD,SAAY,QACZC,SAAY,aACZC,SACGa,MAAS,EAAGlB,KAAQ,IAAKqB,KAAQ,WAEpCf,QACGmD,OAAU,IAAKzD,KAAQ,QAASqB,KAAQ,QAASqC,cAAgB,MAIpEvD,SAAY,MACZC,SAAY,aACZC,SACGa,MAAS,EAAGlB,KAAQ,IAAKqB,KAAQ,WAEpCf,QACGmD,OAAU,IAAKzD,KAAQ,QAASqB,KAAQ,QAASqC,cAAgB,MAIpEvD,SAAY,OACZC,SAAY,aACZC,SACGa,MAAS,EAAGlB,KAAQ,IAAKqB,KAAQ,WAEpCf,QACGmD,OAAU,IAAKzD,KAAQ,QAASqB,KAAQ,QAASqC,cAAgB,IAChED,OAAU,OACVzD,KAAQ,aACRqB,KAAQ,QACRqC,cAAgB,MAKpBvD,SAAY,MACZC,SAAY,aACZC,SACGa,MAAS,EAAGlB,KAAQ,IAAKqB,KAAQ,WAEpCf,QACGmD,OAAU,IAAKzD,KAAQ,QAASqB,KAAQ,QAASqC,cAAgB,MAIpEvD,SAAY,OACZC,SAAY,aACZC,SACGa,MAAS,EAAGlB,KAAQ,IAAKqB,KAAQ,WAEpCf,QACGmD,OAAU,IAAKzD,KAAQ,QAASqB,KAAQ,QAASqC,cAAgB,IAChED,OAAU,OACVzD,KAAQ,aACRqB,KAAQ,QACRqC,cAAgB,MAKpBvD,SAAY,OACZC,SAAY,aACZC,SACGa,MAAS,EAAGlB,KAAQ,IAAKqB,KAAQ,WAEpCf,QACGmD,OAAU,IAAKzD,KAAQ,QAASqB,KAAQ,QAASqC,cAAgB,MAIpEvD,SAAY,QACZC,SAAY,aACZC,SACGa,MAAS,EAAGlB,KAAQ,IAAKqB,KAAQ,WAEpCf,QACGmD,OAAU,IAAKzD,KAAQ,QAASqB,KAAQ,QAASqC,cAAgB,IAChED,OAAU,eACVzD,KAAQ,eACRqB,KAAQ,SACRsC,aAAgB,IAGhBF,OAAU,eACVzD,KAAQ,eACRqB,KAAQ,SACRsC,aAAgB,MAKpBxD,SAAY,OACZC,SAAY,aACZC,SACGa,MAAS,EAAGlB,KAAQ,IAAKqB,KAAQ,WAEpCf,QACGmD,OAAU,IAAKzD,KAAQ,QAASqB,KAAQ,QAASqC,cAAgB,MAIpEvD,SAAY,UACZC,SAAY,aACZC,SACGa,MAAS,EAAGlB,KAAQ,IAAKqB,KAAQ,WAEpCf,QACGmD,OAAU,IAAKzD,KAAQ,QAASqB,KAAQ,QAASqC,cAAgB,MAIpEvD,SAAY,MACZC,SAAY,aACZC,SACGa,MAAS,EAAGlB,KAAQ,IAAKqB,KAAQ,WAEpCf,QACGmD,OAAU,IAAKzD,KAAQ,QAASqB,KAAQ,QAASqC,cAAgB,MAIpEvD,SAAY,OACZC,SAAY,aACZC,SACGa,MAAS,EAAGlB,KAAQ,IAAKqB,KAAQ,WAEpCf,QACGmD,OAAU,IAAKzD,KAAQ,QAASqB,KAAQ,QAASqC,cAAgB,MAIpEvD,SAAY,OACZC,SAAY,aACZC,SACGa,MAAS,EAAGlB,KAAQ,IAAKqB,KAAQ,WAEpCf,QACGmD,OAAU,IAAKzD,KAAQ,QAASqB,KAAQ,QAASqC,cAAgB,MAIpEvD,SAAY,QACZC,SAAY,aACZC,SACGa,MAAS,EAAGlB,KAAQ,IAAKqB,KAAQ,WAEpCf,QACGmD,OAAU,IAAKzD,KAAQ,QAASqB,KAAQ,QAASqC,cAAgB,MAIpEvD,SAAY,SACZC,SAAY,aACZC,SACGa,MAAS,EAAGlB,KAAQ,IAAKqB,KAAQ,WAEpCf,QACGmD,OAAU,IAAKzD,KAAQ,QAASqB,KAAQ,QAASqC,cAAgB,MAIpEvD,SAAY,MACZC,SAAY,aACZC,SACGa,MAAS,EAAGlB,KAAQ,IAAKqB,KAAQ,WAEpCf,QACGmD,OAAU,IAAKzD,KAAQ,QAASqB,KAAQ,QAASqC,cAAgB,MAIpEvD,SAAY,OACZC,SAAY,aACZC,SACGa,MAAS,EAAGlB,KAAQ,IAAKqB,KAAQ,WAEpCf,QACGmD,OAAU,IAAKzD,KAAQ,QAASqB,KAAQ,QAASqC,cAAgB,MAIpEvD,SAAY,OACZC,SAAY,aACZC,SACGa,MAAS,EAAGlB,KAAQ,IAAKqB,KAAQ,WAEpCf,QACGmD,OAAU,IAAKzD,KAAQ,QAASqB,KAAQ,QAASqC,cAAgB,MAIpEvD,SAAY,QACZC,SAAY,aACZC,SACGa,MAAS,EAAGlB,KAAQ,IAAKqB,KAAQ,WAEpCf,QACGmD,OAAU,IAAKzD,KAAQ,QAASqB,KAAQ,QAASqC,cAAgB,MAIpEvD,SAAY,QACZC,SAAY,aACZC,SACGa,MAAS,EAAGlB,KAAQ,IAAKqB,KAAQ,WAEpCf,QACGmD,OAAU,IAAKzD,KAAQ,QAASqB,KAAQ,QAASqC,cAAgB,MAIpEvD,SAAY,QACZC,SAAY,aACZC,SACGa,MAAS,EAAGlB,KAAQ,IAAKqB,KAAQ,WAEpCf,QACGmD,OAAU,IAAKzD,KAAQ,QAASqB,KAAQ,QAASqC,cAAgB,MAIpEvD,SAAY,aACZC,SAAY,aACZC,SACGa,MAAS,EAAGlB,KAAQ,IAAKqB,KAAQ,WAEpCf,QACGmD,OAAU,IAAKzD,KAAQ,QAASqB,KAAQ,QAASqC,cAAgB,MAIpEvD,SAAY,WACZC,SAAY,aACZC,SACGa,MAAS,EAAGlB,KAAQ,IAAKqB,KAAQ,WAEpCf,QACGmD,OAAU,IAAKzD,KAAQ,QAASqB,KAAQ,QAASqC,cAAgB,MAIpEvD,SAAY,QACZC,SAAY,aACZC,SACGa,MAAS,EAAGlB,KAAQ,IAAKqB,KAAQ,WAEpCf,QACGmD,OAAU,IAAKzD,KAAQ,QAASqB,KAAQ,QAASqC,cAAgB,MAIpEvD,SAAY,QACZC,SAAY,aACZC,SACGa,MAAS,EAAGlB,KAAQ,IAAKqB,KAAQ,WAEpCf,QACGmD,OAAU,IAAKzD,KAAQ,QAASqB,KAAQ,QAASqC,cAAgB,MAIpEvD,SAAY,QACZC,SAAY,aACZC,SACGa,MAAS,EAAGlB,KAAQ,IAAKqB,KAAQ,WAEpCf,QACGmD,OAAU,IAAKzD,KAAQ,QAASqB,KAAQ,QAASqC,cAAgB,MAIpEvD,SAAY,MACZC,SAAY,aACZC,SACGa,MAAS,EAAGlB,KAAQ,IAAKqB,KAAQ,WAEpCf,QACGmD,OAAU,IAAKzD,KAAQ,QAASqB,KAAQ,QAASqC,cAAgB,MAIpEvD,SAAY,OACZC,SAAY,aACZC,SACGa,MAAS,EAAGlB,KAAQ,IAAKqB,KAAQ,WACjCH,MAAS,EAAGlB,KAAQ,OAAQqB,KAAQ,aAEvCf,QAEImD,OAAU,YACVzD,KAAQ,WACRqB,KAAQ,OACRqC,cAAgB,IAEjBD,OAAU,IAAKzD,KAAQ,QAASqB,KAAQ,QAASqC,cAAgB,MAIpEvD,SAAY,YACZC,SAAY,aACZC,SACGa,MAAS,EAAGlB,KAAQ,IAAKqB,KAAQ,WAEpCf,QAEImD,OAAU,QACVzD,KAAQ,QACRqB,KAAQ,SACRsC,aAAgB,KAGhBF,OAAU,IACVzD,KAAQ,QACRqB,KAAQ,QACRqC,cAAgB,gCC/bpBvD,SAAY,WACZC,SAAY,UACZC,SAAYa,MAAS,EAAGlB,KAAQ,OAAQqB,KAAQ,aAGhDlB,SAAY,SACZC,SAAY,UACZC,SACGa,MAAS,EAAGlB,KAAQ,OAAQqB,KAAQ,WACpCH,MAAS,EAAGlB,KAAQ,OAAQqB,KAAQ,aAIvClB,SAAY,QACZC,SAAY,UACZC,SACMa,MAAS,EAAGC,IAAO,EAAGnB,KAAQ,UAAWqB,KAAQ,cAGvDlB,SAAY,QACZC,SAAY,UACZC,SACGa,MAAS,EAAGlB,KAAQ,SAAUqB,KAAQ,WAEzCf,QACGmD,OAAU,IAAKzD,KAAQ,QAASqB,KAAQ,QAASqC,cAAgB,IACjED,OAAU,aAAczD,KAAQ,YAAaqB,KAAQ,WACrDoC,OAAU,cAAezD,KAAQ,aAAcqB,KAAQ,WAI1DlB,SAAY,OACZC,SAAY,UACZC,SACGa,MAAS,EAAGlB,KAAQ,SAAUqB,KAAQ,WAEzCf,QACGmD,OAAU,IAAKzD,KAAQ,QAASqB,KAAQ,QAASqC,cAAgB,MAIpEvD,SAAY,gBACZC,SAAY,UACZC,SACGa,MAAS,EAAGlB,KAAQ,SAAUqB,KAAQ,WAEzCf,QACGmD,OAAU,IAAKzD,KAAQ,QAASqB,KAAQ,QAASqC,cAAgB,MAIpEvD,SAAY,gBACZC,SAAY,UACZC,SACGa,MAAS,EAAGlB,KAAQ,OAAQqB,KAAQ,WAEvCf,QACGmD,OAAU,QAASzD,KAAQ,QAASqB,KAAQ,UAC5CoC,OAAU,gBAAiBzD,KAAQ,eAAgBqB,KAAQ,UAC3DoC,OAAU,eAAgBzD,KAAQ,cAAeqB,KAAQ,SACzDoC,OAAU,mBAAoBzD,KAAQ,iBAAkBqB,KAAQ,SAE/DoC,OAAU,2BACVzD,KAAQ,yBACRqB,KAAQ,SAEToC,OAAU,oBAAqBzD,KAAQ,OAAQqB,KAAQ,aAI1DlB,SAAY,qBACZC,SAAY,UACZC,SACGa,MAAS,EAAGlB,KAAQ,gBAAiBqB,KAAQ,WAC7CH,MAAS,EAAGlB,KAAQ,QAASqB,KAAQ,WACrCH,MAAS,EAAGlB,KAAQ,SAAUqB,KAAQ,WACtCH,MAAS,EAAGlB,KAAQ,SAAUqB,KAAQ,WAEzCf,QACGmD,OAAU,IAAKzD,KAAQ,QAASqB,KAAQ,QAASqC,cAAgB,MAIpEvD,SAAY,oBACZC,SAAY,UACZC,SACGa,MAAS,EAAGlB,KAAQ,gBAAiBqB,KAAQ,WAC7CH,MAAS,EAAGlB,KAAQ,QAASqB,KAAQ,WACrCH,MAAS,EAAGlB,KAAQ,SAAUqB,KAAQ,WAEzCf,QACEmD,OAAU,QACVzD,KAAQ,QACRqB,KAAQ,QACRqC,cAAgB,MAIlBvD,SAAY,sBACZC,SAAY,UACZC,SACGa,MAAS,EAAGlB,KAAQ,gBAAiBqB,KAAQ,WAC7CH,MAAS,EAAGlB,KAAQ,UAAWqB,KAAQ,aACvCH,MAAS,EAAGlB,KAAQ,SAAUqB,KAAQ,WAEzCf,QACGmD,OAAU,QAASzD,KAAQ,QAASqB,KAAQ,UAC5CoC,OAAU,gBAAiBzD,KAAQ,eAAgBqB,KAAQ,YAI9DlB,SAAY,uBACZC,SAAY,UACZC,SACGa,MAAS,EAAGlB,KAAQ,gBAAiBqB,KAAQ,WAC7CH,MAAS,EAAGlB,KAAQ,UAAWqB,KAAQ,aACvCH,MAAS,EAAGlB,KAAQ,SAAUqB,KAAQ,WACtCH,MAAS,EAAGlB,KAAQ,SAAUqB,KAAQ,WAEzCf,QAAWmD,OAAU,IAAKzD,KAAQ,QAASqB,KAAQ,YAGnDlB,SAAY,sBACZC,SAAY,UACZC,SACGa,MAAS,EAAGlB,KAAQ,gBAAiBqB,KAAQ,WAC7CH,MAAS,EAAGlB,KAAQ,SAAUqB,KAAQ,WAEzCf,QACGmD,OAAU,QAASzD,KAAQ,QAASqB,KAAQ,UAC3CoC,OAAU,wBACVzD,KAAQ,sBACRqB,KAAQ,QACRqC,cAAgB,MAKpBvD,SAAY,qBACZC,SAAY,UACZC,SACGa,MAAS,EAAGlB,KAAQ,gBAAiBqB,KAAQ,WAC7CH,MAAS,EAAGlB,KAAQ,SAAUqB,KAAQ,WACtCH,MAAS,EAAGlB,KAAQ,UAAWqB,KAAQ,aACvCH,MAAS,EAAGlB,KAAQ,SAAUqB,KAAQ,WAEzCf,QAAWmD,OAAU,IAAKzD,KAAQ,QAASqB,KAAQ,YAGnDlB,SAAY,oBACZC,SAAY,UACZC,SACGa,MAAS,EAAGlB,KAAQ,gBAAiBqB,KAAQ,WAC7CH,MAAS,EAAGlB,KAAQ,SAAUqB,KAAQ,aAIzClB,SAAY,qBACZC,SAAY,UACZC,SAAYa,MAAS,EAAGlB,KAAQ,gBAAiBqB,KAAQ,uCC/JzDlB,SAAY,UACZC,SAAY,cACZC,SACGa,MAAS,EAAGlB,KAAQ,IAAKqB,KAAQ,WAEpCf,QACGmD,OAAU,UAAWzD,KAAQ,UAAWqB,KAAQ,aAChDoC,OAAU,UAAWzD,KAAQ,MAAOqB,KAAQ,WAC3CoC,OAAU,cACVzD,KAAQ,aACRqB,KAAQ,SACRqC,cAAgB,IAEjBD,OAAU,QAASzD,KAAQ,aAAcqB,KAAQ,aACjDoC,OAAU,IAAKzD,KAAQ,QAASqB,KAAQ,QAASqC,cAAgB,MAIpEvD,SAAY,UACZC,SAAY,cACZC,SACGa,MAAS,EAAGlB,KAAQ,IAAKqB,KAAQ,WAEpCf,QACGmD,OAAU,UAAWzD,KAAQ,UAAWqB,KAAQ,aAChDoC,OAAU,UAAWzD,KAAQ,MAAOqB,KAAQ,WAC3CoC,OAAU,cACVzD,KAAQ,aACRqB,KAAQ,SACRqC,cAAgB,IAEjBD,OAAU,QAASzD,KAAQ,aAAcqB,KAAQ,aACjDoC,OAAU,IAAKzD,KAAQ,QAASqB,KAAQ,QAASqC,cAAgB,MAIpEvD,SAAY,YACZC,SAAY,cACZC,SACGa,MAAS,EAAGlB,KAAQ,IAAKqB,KAAQ,WAEpCf,QACGmD,OAAU,UAAWzD,KAAQ,UAAWqB,KAAQ,aAChDoC,OAAU,UAAWzD,KAAQ,MAAOqB,KAAQ,WAC3CoC,OAAU,cACVzD,KAAQ,aACRqB,KAAQ,SACRqC,cAAgB,IAEjBD,OAAU,QAASzD,KAAQ,aAAcqB,KAAQ,aACjDoC,OAAU,IAAKzD,KAAQ,QAASqB,KAAQ,QAASqC,cAAgB,MAIpEvD,SAAY,YACZC,SAAY,cACZC,SACGa,MAAS,EAAGlB,KAAQ,IAAKqB,KAAQ,WAEpCf,QACGmD,OAAU,UAAWzD,KAAQ,UAAWqB,KAAQ,aAChDoC,OAAU,UAAWzD,KAAQ,MAAOqB,KAAQ,WAC3CoC,OAAU,cACVzD,KAAQ,aACRqB,KAAQ,SACRqC,cAAgB,IAEjBD,OAAU,QAASzD,KAAQ,aAAcqB,KAAQ,aACjDoC,OAAU,IAAKzD,KAAQ,QAASqB,KAAQ,QAASqC,cAAgB,MAIpEvD,SAAY,SACZC,SAAY,cACZC,SACGa,MAAS,EAAGlB,KAAQ,IAAKqB,KAAQ,WACjCH,MAAS,EAAGlB,KAAQ,SAAUqB,KAAQ,WAEzCf,QACGmD,OAAU,SAAUzD,KAAQ,SAAUqB,KAAQ,WAC9CoC,OAAU,UAAWzD,KAAQ,MAAOqB,KAAQ,WAC3CoC,OAAU,cACVzD,KAAQ,aACRqB,KAAQ,SACRsC,aAAgB,QAEjBF,OAAU,IAAKzD,KAAQ,QAASqB,KAAQ,QAASqC,cAAgB,IAChED,OAAU,WACVzD,KAAQ,WACRqB,KAAQ,SACRsC,aAAgB,MAKpBxD,SAAY,SACZC,SAAY,cACZC,SACGa,MAAS,EAAGlB,KAAQ,IAAKqB,KAAQ,WACjCH,MAAS,EAAGlB,KAAQ,SAAUqB,KAAQ,WAEzCf,QACGmD,OAAU,IAAKzD,KAAQ,QAASqB,KAAQ,QAASqC,cAAgB,IACjED,OAAU,UAAWzD,KAAQ,UAAWqB,KAAQ,aAChDoC,OAAU,UAAWzD,KAAQ,MAAOqB,KAAQ,WAC5CoC,OAAU,gBAAiBzD,KAAQ,gBAAiBqB,KAAQ,SAC3DoC,OAAU,cACVzD,KAAQ,aACRqB,KAAQ,SACRsC,aAAgB,SAEjBF,OAAU,YAAazD,KAAQ,YAAaqB,KAAQ,eAIvDlB,SAAY,sBACZC,SAAY,cACZC,SACGa,MAAS,EAAGlB,KAAQ,IAAKqB,KAAQ,WACjCH,MAAS,EAAGlB,KAAQ,SAAUqB,KAAQ,WACtCH,MAAS,EAAGlB,KAAQ,cAAeqB,KAAQ,aAE9Cf,QACGmD,OAAU,UAAWzD,KAAQ,UAAWqB,KAAQ,aAChDoC,OAAU,UAAWzD,KAAQ,MAAOqB,KAAQ,WAC3CoC,OAAU,cACVzD,KAAQ,aACRqB,KAAQ,SACRqC,cAAgB,MAKpBvD,SAAY,kBACZC,SAAY,cACZC,SACGa,MAAS,EAAGlB,KAAQ,QAASqB,KAAQ,WACrCH,MAAS,EAAGlB,KAAQ,SAAUqB,KAAQ,WAEzCf,QACGmD,OAAU,UAAWzD,KAAQ,UAAWqB,KAAQ,aAChDoC,OAAU,UAAWzD,KAAQ,MAAOqB,KAAQ,WAC3CoC,OAAU,cACVzD,KAAQ,aACRqB,KAAQ,SACRsC,aAAgB,SAEjBF,OAAU,YAAazD,KAAQ,YAAaqB,KAAQ,eAIvDlB,SAAY,wBACZC,SAAY,cACZC,SACGa,MAAS,EAAGlB,KAAQ,QAASqB,KAAQ,WACrCH,MAAS,EAAGlB,KAAQ,SAAUqB,KAAQ,WAEzCf,QACGmD,OAAU,UAAWzD,KAAQ,UAAWqB,KAAQ,aAChDoC,OAAU,UAAWzD,KAAQ,MAAOqB,KAAQ,WAC3CoC,OAAU,cACVzD,KAAQ,aACRqB,KAAQ,SACRsC,aAAgB,SAEjBF,OAAU,YAAazD,KAAQ,YAAaqB,KAAQ,eAIvDlB,SAAY,SACZC,SAAY,cACZC,SACGa,MAAS,EAAGlB,KAAQ,IAAKqB,KAAQ,WACjCH,MAAS,EAAGlB,KAAQ,SAAUqB,KAAQ,WAEzCf,QACGmD,OAAU,UAAWzD,KAAQ,UAAWqB,KAAQ,aAChDoC,OAAU,UAAWzD,KAAQ,MAAOqB,KAAQ,WAC3CoC,OAAU,cACVzD,KAAQ,aACRqB,KAAQ,SACRsC,aAAgB,SAEjBF,OAAU,YAAazD,KAAQ,YAAaqB,KAAQ,yCCvLvDlB,SAAY,OACZC,SAAY,WACZC,SACGa,MAAS,EAAGlB,KAAQ,QAASqB,KAAQ,aACrCH,MAAS,EAAGlB,KAAQ,QAASqB,KAAQ,WAExCf,QAAWmD,OAAU,IAAKzD,KAAQ,QAASqB,KAAQ,YAGnDlB,SAAY,WACZC,SAAY,WACZC,SACGa,MAAS,EAAGlB,KAAQ,QAASqB,KAAQ,WACrCH,MAAS,EAAGlB,KAAQ,OAAQqB,KAAQ,WACpCH,MAAS,EAAGlB,KAAQ,MAAOqB,KAAQ,WAEtCf,QACGmD,OAAU,IAAKzD,KAAQ,QAASqB,KAAQ,QAASqC,cAAgB,MAIpEvD,SAAY,SACZC,SAAY,WACZC,SACGa,MAAS,EAAGlB,KAAQ,UAAWqB,KAAQ,WACvCH,MAAS,EAAGlB,KAAQ,QAASqB,KAAQ,WACrCH,MAAS,EAAGlB,KAAQ,UAAWqB,KAAQ,SAAUsC,aAAgB,IACjEzC,MAAS,EAAGlB,KAAQ,WAAYqB,KAAQ,SAAUsC,aAAgB,IAErErD,QAEImD,OAAU,OACVzD,KAAQ,OACRqB,KAAQ,SACRqC,cAAgB,IAEjBD,OAAU,IAAKzD,KAAQ,QAASqB,KAAQ,QAASqC,cAAgB,MAIpEvD,SAAY,OACZC,SAAY,WACZC,SACGa,MAAS,EAAGlB,KAAQ,QAASqB,KAAQ,aAExCf,QAAWmD,OAAU,IAAKzD,KAAQ,QAASqB,KAAQ,YAGnDlB,SAAY,WACZC,SAAY,WACZC,SACGa,MAAS,EAAGlB,KAAQ,IAAKqB,KAAQ,WAEpCf,QAAWmD,OAAU,QAASzD,KAAQ,QAASqB,KAAQ,YAGvDlB,SAAY,gBACZC,SAAY,WACZC,SACGa,MAAS,EAAGlB,KAAQ,QAASqB,KAAQ,aAExCf,QAEImD,OAAU,SACVzD,KAAQ,SACRqB,KAAQ,SACRsC,aAAgB,IAGhBF,OAAU,SACVzD,KAAQ,SACRqB,KAAQ,SACRsC,aAAgB,IAEjBF,OAAU,QAASzD,KAAQ,QAASqB,KAAQ,UAC5CoC,OAAU,OAAQzD,KAAQ,OAAQqB,KAAQ,SAAUsC,aAAgB,IACnEF,OAAU,QACVzD,KAAQ,QACRqB,KAAQ,SACRsC,aAAgB,EAChBD,cAAgB,IAEjBD,OAAU,IAAKzD,KAAQ,IAAKqB,KAAQ,SAAUqC,cAAgB,MAIjEvD,SAAY,QACZC,SAAY,WACZC,SACGa,MAAS,EAAGlB,KAAQ,QAASqB,KAAQ,WACrCH,MAAS,EAAGlB,KAAQ,OAAQqB,KAAQ,WACpCH,MAAS,EAAGlB,KAAQ,OAAQqB,KAAQ,SAAUsC,aAAgB,IAEjErD,QAAWmD,OAAU,OAAQzD,KAAQ,QAASqB,KAAQ,YAGtDlB,SAAY,kBACZC,SAAY,WACZC,SACGa,MAAS,EAAGlB,KAAQ,QAASqB,KAAQ,aAExCf,QAEImD,OAAU,QACVzD,KAAQ,OACRqB,KAAQ,SACRsC,aAAgB,IAGhBF,OAAU,SACVzD,KAAQ,SACRqB,KAAQ,SACRsC,aAAgB,IAEjBF,OAAU,OAAQzD,KAAQ,OAAQqB,KAAQ,WACzCoC,OAAU,QACVzD,KAAQ,QACRqB,KAAQ,SACRsC,aAAgB,EAChBD,cAAgB,IAEjBD,OAAU,QAASzD,KAAQ,QAASqB,KAAQ,UAC5CoC,OAAU,IAAKzD,KAAQ,IAAKqB,KAAQ,SAAUqC,cAAgB,MAIjEvD,SAAY,QACZC,SAAY,WACZC,SACGa,MAAS,EAAGlB,KAAQ,QAASqB,KAAQ,aAExCf,QAAWmD,OAAU,IAAKzD,KAAQ,QAASqB,KAAQ,YAGnDlB,SAAY,YACZC,SAAY,WACZC,SACGa,MAAS,EAAGlB,KAAQ,IAAKqB,KAAQ,WAEpCf,QAAWmD,OAAU,IAAKzD,KAAQ,QAASqB,KAAQ,sCC3InDlB,SAAY,sBACZC,SAAY,UACZC,SACGa,MAAS,EAAGlB,KAAQ,QAASqB,KAAQ,WACrCH,MAAS,EAAGlB,KAAQ,SAAUqB,KAAQ,WACtCH,MAAS,EAAGlB,KAAQ,gBAAiBqB,KAAQ,WAC7CH,MAAS,EAAGlB,KAAQ,eAAgBqB,KAAQ,aAI/ClB,SAAY,sBACZC,SAAY,UACZC,SACGa,MAAS,EAAGlB,KAAQ,QAASqB,KAAQ,WACrCH,MAAS,EAAGlB,KAAQ,SAAUqB,KAAQ,WACtCH,MAAS,EAAGlB,KAAQ,gBAAiBqB,KAAQ,WAC7CH,MAAS,EAAGlB,KAAQ,eAAgBqB,KAAQ,WAC5CH,MAAS,EAAGlB,KAAQ,iBAAkBqB,KAAQ,aAIjDlB,SAAY,QACZC,SAAY,UACZC,SACGa,MAAS,EAAGlB,KAAQ,YAAaqB,KAAQ,WAE5Cf,QACGmD,OAAU,IAAKzD,KAAQ,QAASqB,KAAQ,QAASqC,cAAgB,MAIpEvD,SAAY,WACZC,SAAY,UACZC,SACGa,MAAS,EAAGlB,KAAQ,IAAKqB,KAAQ,WACjCH,MAAS,EAAGlB,KAAQ,IAAKqB,KAAQ,WAEpCf,QACEmD,OAAU,IACVzD,KAAQ,QACRqB,KAAQ,QACRqC,cAAgB,gCC1CpBvD,SAAY,SACZC,SAAY,aACZC,SACGa,MAAS,EAAGlB,KAAQ,IAAKqB,KAAQ,WACjCH,MAAS,EAAGlB,KAAQ,IAAKqB,KAAQ,WAEpCf,QAAWmD,OAAU,SAAUzD,KAAQ,SAAUqB,KAAQ,qCCLvDlB,SAAY,yBACZC,SAAY,QACZC,SACGa,MAAS,EAAGlB,KAAQ,UAAWqB,KAAQ,WAE1Cf,QACGmD,OAAU,QAASzD,KAAQ,QAASqB,KAAQ,UAC5CoC,OAAU,QAASzD,KAAQ,QAASqB,KAAQ,YAI/ClB,SAAY,cACZC,SAAY,QACZE,QACGmD,OAAU,QAASzD,KAAQ,QAASqB,KAAQ,UAC5CoC,OAAU,QAASzD,KAAQ,QAASqB,KAAQ,YAGhDlB,SAAY,QAASC,SAAY,UAChCD,SAAY,WACZC,SAAY,QACZC,SAAYa,MAAS,EAAGlB,KAAQ,IAAKqB,KAAQ,aAG7ClB,SAAY,YACZC,SAAY,QACZC,SAAYa,MAAS,EAAGC,IAAO,EAAGnB,KAAQ,IAAKqB,KAAQ,cAGvDlB,SAAY,WACZC,SAAY,QACZC,SAAYa,MAAS,EAAGlB,KAAQ,IAAKqB,KAAQ,aAG7ClB,SAAY,OACZC,SAAY,QACZC,SAAYa,MAAS,EAAGlB,KAAQ,IAAKqB,KAAQ,aAG7ClB,SAAY,OACZC,SAAY,QACZC,SAAYa,MAAS,EAAGlB,KAAQ,IAAKqB,KAAQ,aAG7ClB,SAAY,QACZC,SAAY,QACZC,SAAYa,MAAS,EAAGlB,KAAQ,IAAKqB,KAAQ,aAG7ClB,SAAY,SACZC,SAAY,QACZC,SAAYa,MAAS,EAAGC,IAAO,EAAGnB,KAAQ,IAAKqB,KAAQ,cAGvDlB,SAAY,QACZC,SAAY,QACZC,SACGa,MAAS,EAAGlB,KAAQ,IAAKqB,KAAQ,WACjCH,MAAS,EAAGlB,KAAQ,OAAQqB,KAAQ,YAEvCf,QACGmD,OAAU,UAAWzD,KAAQ,UAAWqB,KAAQ,WAC/CoC,OAAU,UACVzD,KAAQ,SACRqB,KAAQ,SACRqC,cAAgB,IAGhBD,OAAU,YACVzD,KAAQ,YACRqB,KAAQ,SACRsC,aAAgB,MAIrBxD,SAAY,OAAQC,SAAY,QAASC,YACxCF,SAAY,eACZC,SAAY,QACZC,SAAYa,MAAS,EAAGlB,KAAQ,IAAKqB,KAAQ,aAG7ClB,SAAY,0BACZC,SAAY,QACZC,SACGa,MAAS,EAAGlB,KAAQ,IAAKqB,KAAQ,WAEpCf,QACGmD,OAAU,MAAOzD,KAAQ,MAAOqB,KAAQ,WACxCoC,OAAU,MAAOzD,KAAQ,MAAOqB,KAAQ,uCCxF3ClB,SAAY,iBACZC,SAAY,QACZC,SACGa,MAAS,EAAGlB,KAAQ,SAAUqB,KAAQ,WACtCH,MAAS,EAAGlB,KAAQ,OAAQqB,KAAQ,aAEvCf,QACGmD,OAAU,gBAAiBzD,KAAQ,eAAgBqB,KAAQ,SAC3DoC,OAAU,IAAKzD,KAAQ,QAASqB,KAAQ,QAASqC,cAAgB,MAIpEvD,SAAY,wBACZC,SAAY,QACZC,SACGa,MAAS,EAAGlB,KAAQ,SAAUqB,KAAQ,WACtCH,MAAS,EAAGlB,KAAQ,OAAQqB,KAAQ,aAEvCf,QACGmD,OAAU,gBAAiBzD,KAAQ,eAAgBqB,KAAQ,SAC3DoC,OAAU,IAAKzD,KAAQ,QAASqB,KAAQ,QAASqC,cAAgB,MAIpEvD,SAAY,gBACZC,SAAY,QACZC,SACGa,MAAS,EAAGlB,KAAQ,QAASqB,KAAQ,WACrCH,MAAS,EAAGlB,KAAQ,QAASqB,KAAQ,WACrCH,MAAS,EAAGlB,KAAQ,SAAUqB,KAAQ,WACtCH,MAAS,EAAGlB,KAAQ,WAAYqB,KAAQ,aAE3Cf,QACGmD,OAAU,SAAUzD,KAAQ,SAAUqB,KAAQ,WAC7CoC,OAAU,sBACVzD,KAAQ,qBACRqB,KAAQ,uCCpCZlB,SAAY,QACZC,SAAY,UACZC,SACGa,MAAS,EAAGlB,KAAQ,IAAKqB,KAAQ,WACjCH,MAAS,EAAGlB,KAAQ,IAAKqB,KAAQ,WAEpCf,QACGmD,OAAU,IAAKzD,KAAQ,QAASqB,KAAQ,QAASqC,cAAgB,MAIpEvD,SAAY,WACZC,SAAY,UACZC,SACGa,MAAS,EAAGlB,KAAQ,IAAKqB,KAAQ,WACjCH,MAAS,EAAGlB,KAAQ,IAAKqB,KAAQ,WAEpCf,QACGmD,OAAU,IAAKzD,KAAQ,QAASqB,KAAQ,QAASqC,cAAgB,MAIpEvD,SAAY,UACZC,SAAY,UACZC,SACGa,MAAS,EAAGlB,KAAQ,IAAKqB,KAAQ,WACjCH,MAAS,EAAGlB,KAAQ,IAAKqB,KAAQ,WAEpCf,QACGmD,OAAU,IAAKzD,KAAQ,QAASqB,KAAQ,QAASqC,cAAgB,MAIpEvD,SAAY,eACZC,SAAY,UACZC,SACGa,MAAS,EAAGlB,KAAQ,IAAKqB,KAAQ,WACjCH,MAAS,EAAGlB,KAAQ,IAAKqB,KAAQ,WAEpCf,QACGmD,OAAU,IAAKzD,KAAQ,QAASqB,KAAQ,QAASqC,cAAgB,MAIpEvD,SAAY,OACZC,SAAY,UACZC,SACGa,MAAS,EAAGlB,KAAQ,IAAKqB,KAAQ,WACjCH,MAAS,EAAGlB,KAAQ,IAAKqB,KAAQ,WAEpCf,QACGmD,OAAU,IAAKzD,KAAQ,QAASqB,KAAQ,QAASqC,cAAgB,MAIpEvD,SAAY,YACZC,SAAY,UACZC,SACGa,MAAS,EAAGlB,KAAQ,IAAKqB,KAAQ,WACjCH,MAAS,EAAGlB,KAAQ,IAAKqB,KAAQ,WAEpCf,QACGmD,OAAU,IAAKzD,KAAQ,QAASqB,KAAQ,QAASqC,cAAgB,MAIpEvD,SAAY,aACZC,SAAY,UACZC,SACGa,MAAS,EAAGlB,KAAQ,IAAKqB,KAAQ,WACjCH,MAAS,EAAGlB,KAAQ,IAAKqB,KAAQ,WAEpCf,QACGmD,OAAU,IAAKzD,KAAQ,QAASqB,KAAQ,QAASqC,cAAgB,MAIpEvD,SAAY,aACZC,SAAY,UACZC,SACGa,MAAS,EAAGlB,KAAQ,IAAKqB,KAAQ,WAEpCf,QACGmD,OAAU,IAAKzD,KAAQ,QAASqB,KAAQ,QAASqC,cAAgB,MAIpEvD,SAAY,YACZC,SAAY,UACZC,SACGa,MAAS,EAAGlB,KAAQ,IAAKqB,KAAQ,WACjCH,MAAS,EAAGlB,KAAQ,IAAKqB,KAAQ,WAEpCf,QACGmD,OAAU,IAAKzD,KAAQ,QAASqB,KAAQ,QAASqC,cAAgB,MAIpEvD,SAAY,SACZC,SAAY,UACZC,SACGa,MAAS,EAAGlB,KAAQ,YAAaqB,KAAQ,WACzCH,MAAS,EAAGlB,KAAQ,IAAKqB,KAAQ,WACjCH,MAAS,EAAGlB,KAAQ,IAAKqB,KAAQ,WAEpCf,QACEmD,OAAU,IACVzD,KAAQ,QACRqB,KAAQ,QACRqC,cAAgB,gCC7GlBvD,SAAY,SACZC,SAAY,WACZC,SACGa,MAAS,EAAGlB,KAAQ,IAAKqB,KAAQ,WACjCH,MAAS,EAAGlB,KAAQ,IAAKqB,KAAQ,WAEpCf,QAEImD,OAAU,cACVzD,KAAQ,aACRqB,KAAQ,OACRsC,cAAgB,IAGhBF,OAAU,cACVzD,KAAQ,aACRqB,KAAQ,OACRsC,cAAgB,IAEjBF,OAAU,IAAKzD,KAAQ,QAASqB,KAAQ,QAASqC,cAAgB,MAIpEvD,SAAY,cACZC,SAAY,WACZC,SACGa,MAAS,EAAGlB,KAAQ,IAAKqB,KAAQ,WACjCH,MAAS,EAAGlB,KAAQ,IAAKqB,KAAQ,WAEpCf,QAEImD,OAAU,QACVzD,KAAQ,aACRqB,KAAQ,OACRsC,cAAgB,IAGhBF,OAAU,QACVzD,KAAQ,aACRqB,KAAQ,OACRsC,cAAgB,IAEjBF,OAAU,IAAKzD,KAAQ,QAASqB,KAAQ,QAASqC,cAAgB,MAIpEvD,SAAY,gBACZC,SAAY,WACZC,SACGa,MAAS,EAAGlB,KAAQ,IAAKqB,KAAQ,WACjCH,MAAS,EAAGlB,KAAQ,IAAKqB,KAAQ,WAEpCf,QAEImD,OAAU,QACVzD,KAAQ,aACRqB,KAAQ,OACRsC,cAAgB,IAGhBF,OAAU,QACVzD,KAAQ,aACRqB,KAAQ,OACRsC,cAAgB,IAEjBF,OAAU,IAAKzD,KAAQ,QAASqB,KAAQ,QAASqC,cAAgB,MAIpEvD,SAAY,YACZC,SAAY,WACZC,SACGa,MAAS,EAAGlB,KAAQ,IAAKqB,KAAQ,WACjCH,MAAS,EAAGlB,KAAQ,OAAQqB,KAAQ,aAEvCf,QACEmD,OAAU,IACVzD,KAAQ,QACRqB,KAAQ,QACRqC,cAAgB,gCC/ElBvD,SAAY,iBACZC,SAAY,gBACZC,SACGa,MAAS,EAAGlB,KAAQ,IAAKqB,KAAQ,WACjCH,MAAS,EAAGlB,KAAQ,QAASqB,KAAQ,WACrCH,MAAS,EAAGlB,KAAQ,SAAUqB,KAAQ,WACtCH,MAAS,EAAGlB,KAAQ,OAAQqB,KAAQ,WACpCH,MAAS,EAAGlB,KAAQ,WAAYqB,KAAQ,WAE3Cf,QAEImD,OAAU,UACVzD,KAAQ,UACRqB,KAAQ,SACRsC,aAAgB,OAGhBF,OAAU,cACVzD,KAAQ,aACRqB,KAAQ,SACRqC,cAAgB,MAKpBvD,SAAY,mBACZC,SAAY,gBACZC,SACGa,MAAS,EAAGlB,KAAQ,IAAKqB,KAAQ,WACjCH,MAAS,EAAGlB,KAAQ,QAASqB,KAAQ,WACrCH,MAAS,EAAGlB,KAAQ,SAAUqB,KAAQ,WACtCH,MAAS,EAAGlB,KAAQ,OAAQqB,KAAQ,WACpCH,MAAS,EAAGlB,KAAQ,WAAYqB,KAAQ,WAE3Cf,QAEImD,OAAU,UACVzD,KAAQ,UACRqB,KAAQ,SACRsC,aAAgB,OAGhBF,OAAU,cACVzD,KAAQ,aACRqB,KAAQ,SACRqC,cAAgB,MAKpBvD,SAAY,mBACZC,SAAY,gBACZC,SACGa,MAAS,EAAGlB,KAAQ,IAAKqB,KAAQ,WACjCH,MAAS,EAAGlB,KAAQ,QAASqB,KAAQ,WACrCH,MAAS,EAAGlB,KAAQ,SAAUqB,KAAQ,WACtCH,MAAS,EAAGlB,KAAQ,OAAQqB,KAAQ,WACpCH,MAAS,EAAGlB,KAAQ,WAAYqB,KAAQ,WAE3Cf,QAEImD,OAAU,UACVzD,KAAQ,UACRqB,KAAQ,SACRsC,aAAgB,OAGhBF,OAAU,cACVzD,KAAQ,aACRqB,KAAQ,SACRqC,cAAgB,MAKpBvD,SAAY,MACZC,SAAY,gBACZC,SACGa,MAAS,EAAGlB,KAAQ,IAAKqB,KAAQ,WAEpCf,QAEImD,OAAU,eACVzD,KAAQ,SACRqB,KAAQ,SACRsC,aAAgB,IAEjBF,OAAU,OAAQzD,KAAQ,OAAQqB,KAAQ,SAAUsC,aAAgB,IAEnEF,OAAU,QACVzD,KAAQ,QACRqB,KAAQ,SACRsC,aAAgB,IAGhBF,OAAU,OACVzD,KAAQ,OACRqB,KAAQ,SACRsC,aAAgB,OAKpBxD,SAAY,UACZC,SAAY,gBACZC,SAAYa,MAAS,EAAGlB,KAAQ,IAAKqB,KAAQ,aAG7ClB,SAAY,aACZC,SAAY,gBACZC,SAAYa,MAAS,EAAGlB,KAAQ,IAAKqB,KAAQ,aAG7ClB,SAAY,gBACZC,SAAY,gBACZC,SACGa,MAAS,EAAGlB,KAAQ,gBAAiBqB,KAAQ,WAC7CH,MAAS,EAAGlB,KAAQ,cAAeqB,KAAQ,aAC3CH,MAAS,EAAGlB,KAAQ,eAAgBqB,KAAQ,WAC5CH,MAAS,EAAGlB,KAAQ,eAAgBqB,KAAQ,WAE/Cf,QACEmD,OAAU,mBACVzD,KAAQ,kBACRqB,KAAQ,OACRsC,cAAgB,EAChBD,cAAgB,gCC9HlBvD,SAAY,MACZC,SAAY,YACZC,SACGa,MAAS,EAAGlB,KAAQ,IAAKqB,KAAQ,WACjCH,MAAS,EAAGlB,KAAQ,OAAQqB,KAAQ,aAEvCf,QAAWmD,OAAU,YAAazD,KAAQ,WAAYqB,KAAQ,WAG9DlB,SAAY,OACZC,SAAY,YACZC,SACGa,MAAS,EAAGlB,KAAQ,IAAKqB,KAAQ,WACjCH,MAAS,EAAGlB,KAAQ,OAAQqB,KAAQ,aAEvCf,QAAWmD,OAAU,YAAazD,KAAQ,WAAYqB,KAAQ,WAG9DlB,SAAY,MACZC,SAAY,YACZC,SACGa,MAAS,EAAGlB,KAAQ,IAAKqB,KAAQ,WACjCH,MAAS,EAAGlB,KAAQ,OAAQqB,KAAQ,aAEvCf,QAAWmD,OAAU,YAAazD,KAAQ,WAAYqB,KAAQ,WAG9DlB,SAAY,MACZC,SAAY,YACZC,SACGa,MAAS,EAAGlB,KAAQ,IAAKqB,KAAQ,WACjCH,MAAS,EAAGlB,KAAQ,OAAQqB,KAAQ,aAEvCf,QAAWmD,OAAU,YAAazD,KAAQ,WAAYqB,KAAQ,WAG9DlB,SAAY,MACZC,SAAY,YACZC,SACGa,MAAS,EAAGlB,KAAQ,IAAKqB,KAAQ,WACjCH,MAAS,EAAGlB,KAAQ,OAAQqB,KAAQ,aAEvCf,QAAWmD,OAAU,YAAazD,KAAQ,WAAYqB,KAAQ,WAG9DlB,SAAY,MACZC,SAAY,YACZC,SACGa,MAAS,EAAGlB,KAAQ,IAAKqB,KAAQ,WACjCH,MAAS,EAAGlB,KAAQ,OAAQqB,KAAQ,aAEvCf,QAAWmD,OAAU,YAAazD,KAAQ,WAAYqB,KAAQ,WAG9DlB,SAAY,SACZC,SAAY,YACZC,SACGa,MAAS,EAAGlB,KAAQ,IAAKqB,KAAQ,WACjCH,MAAS,EAAGlB,KAAQ,OAAQqB,KAAQ,aAIvClB,SAAY,SACZC,SAAY,YACZC,SACGa,MAAS,EAAGlB,KAAQ,IAAKqB,KAAQ,WACjCH,MAAS,EAAGlB,KAAQ,OAAQqB,KAAQ,aAIvClB,SAAY,OACZC,SAAY,YACZC,SACGa,MAAS,EAAGlB,KAAQ,IAAKqB,KAAQ,WACjCH,MAAS,EAAGlB,KAAQ,OAAQqB,KAAQ,aAEvCf,QAAWmD,OAAU,YAAazD,KAAQ,WAAYqB,KAAQ,qCC5E9DlB,SAAY,WACZC,SAAY,aACZC,SACGa,MAAS,EAAGC,KAAQ,EAAGnB,KAAQ,UAAWqB,KAAQ,YAClDH,OAAU,EAAGlB,KAAQ,OAAQqB,KAAQ,aAIxClB,SAAY,SACZC,SAAY,aACZC,SACGa,MAAS,EAAGC,IAAO,EAAGnB,KAAQ,UAAWqB,KAAQ,YACjDH,MAAS,EAAGlB,KAAQ,OAAQqB,KAAQ,aAIvClB,SAAY,WACZC,SAAY,aACZC,SACGa,MAAS,EAAGlB,KAAQ,IAAKqB,KAAQ,WACjCH,MAAS,EAAGlB,KAAQ,UAAWqB,KAAQ,WACvCH,MAAS,EAAGlB,KAAQ,OAAQqB,KAAQ,SAAUsC,aAAgB,MAIjExD,SAAY,SACZC,SAAY,aACZC,SACGa,MAAS,EAAGlB,KAAQ,IAAKqB,KAAQ,WACjCH,MAAS,EAAGlB,KAAQ,UAAWqB,KAAQ,WAE1Cf,QACGmD,OAAU,OAAQzD,KAAQ,OAAQqB,KAAQ,SAAUsC,aAAgB,IACnEF,OAAU,mBACVzD,KAAQ,kBACRqB,KAAQ,OACRqC,cAAgB,MAKpBvD,SAAY,UACZC,SAAY,aACZC,SACGa,MAAS,EAAGlB,KAAQ,IAAKqB,KAAQ,WACjCH,MAAS,EAAGlB,KAAQ,OAAQqB,KAAQ,OAAQqC,cAAgB,MAI/DvD,SAAY,YACZC,SAAY,aACZC,SACGa,MAAS,EAAGlB,KAAQ,IAAKqB,KAAQ,WACjCH,MAAS,EAAGlB,KAAQ,OAAQqB,KAAQ,eAIvClB,SAAY,QACZC,SAAY,aACZC,SACGa,MAAS,EAAGlB,KAAQ,IAAKqB,KAAQ,WACjCH,MAAS,EAAGlB,KAAQ,QAASqB,KAAQ,aACrCH,MAAS,EAAGlB,KAAQ,OAAQqB,KAAQ,eAIvClB,SAAY,eACZC,SAAY,aACZC,SACGa,MAAS,EAAGlB,KAAQ,IAAKqB,KAAQ,WACjCH,MAAS,EAAGlB,KAAQ,QAASqB,KAAQ,aACrCH,MAAS,EAAGlB,KAAQ,MAAOqB,KAAQ,aACnCH,MAAS,EAAGlB,KAAQ,UAAWqB,KAAQ,aAE1Cf,QAEImD,OAAU,aACVzD,KAAQ,YACRqB,KAAQ,SACRsC,aAAgB,IAGhBF,OAAU,WACVzD,KAAQ,UACRqB,KAAQ,SACRsC,aAAgB,IAGhBF,OAAU,gBACVzD,KAAQ,cACRqB,KAAQ,SACRsC,aAAgB,IAGhBF,OAAU,gBACVzD,KAAQ,eACRqB,KAAQ,SACRsC,aAAgB,IAGhBF,OAAU,mBACVzD,KAAQ,iBACRqB,KAAQ,SACRsC,aAAgB,MAKpBxD,SAAY,OACZC,SAAY,aACZC,SACGa,MAAS,EAAGC,IAAO,EAAGnB,KAAQ,UAAWqB,KAAQ,YAEpDf,QACGmD,OAAU,OAAQzD,KAAQ,OAAQqB,KAAQ,SAAUsC,aAAgB,MAIvExD,SAAY,SACZC,SAAY,aACZC,SACGa,MAAS,EAAGlB,KAAQ,SAAUqB,KAAQ,WAEzCf,QACGmD,OAAU,OAAQzD,KAAQ,OAAQqB,KAAQ,SAAUsC,aAAgB,IACnEF,OAAU,MACVzD,KAAQ,MACRqB,KAAQ,SACRsC,aAAgB,EAChBD,cAAgB,MAKpBvD,SAAY,OACZC,SAAY,aACZC,SACGa,MAAS,EAAGlB,KAAQ,IAAKqB,KAAQ,WACjCH,MAAS,EAAGlB,KAAQ,OAAQqB,KAAQ,eAIvClB,SAAY,QACZC,SAAY,aACZC,SACGa,MAAS,EAAGlB,KAAQ,OAAQqB,KAAQ,SAAUsC,aAAgB,IAC9DzC,MAAS,EAAGlB,KAAQ,IAAKqB,KAAQ,WAEpCf,QACEmD,OAAU,YACVzD,KAAQ,kBACRqB,KAAQ,SACRsC,aAAgB,MAIlBxD,SAAY,SACZC,SAAY,aACZC,SACGa,MAAS,EAAGlB,KAAQ,IAAKqB,KAAQ,WACjCH,MAAS,EAAGlB,KAAQ,kBAAmBqB,KAAQ,aAC/CH,MAAS,EAAGlB,KAAQ,OAAQqB,KAAQ,SAAUsC,aAAgB,MAIjExD,SAAY,YACZC,SAAY,aACZC,SACGa,MAAS,EAAGlB,KAAQ,UAAWqB,KAAQ,WACvCH,MAAS,EAAGlB,KAAQ,SAAUqB,KAAQ,WACtCH,MAAS,EAAGlB,KAAQ,QAASqB,KAAQ,eAIxClB,SAAY,WACZC,SAAY,aACZC,SACGa,MAAS,EAAGlB,KAAQ,IAAKqB,KAAQ,WACjCH,MAAS,EAAGlB,KAAQ,UAAWqB,KAAQ,aAI1ClB,SAAY,gBACZC,SAAY,aACZC,SACGa,MAAS,EAAGlB,KAAQ,gBAAiBqB,KAAQ,WAC7CH,MAAS,EAAGlB,KAAQ,cAAeqB,KAAQ,aAC3CH,MAAS,EAAGlB,KAAQ,eAAgBqB,KAAQ,WAC5CH,MAAS,EAAGlB,KAAQ,eAAgBqB,KAAQ,WAE/Cf,QACEmD,OAAU,mBACVzD,KAAQ,kBACRqB,KAAQ,OACRsC,cAAgB,EAChBD,cAAgB,gCCnMlBvD,SAAY,MACZC,SAAY,WACZC,SAAYa,MAAS,EAAGlB,KAAQ,IAAKqB,KAAQ,aAG7ClB,SAAY,OACZC,SAAY,WACZC,SAAYa,MAAS,EAAGlB,KAAQ,IAAKqB,KAAQ,aAG7ClB,SAAY,OACZC,SAAY,WACZC,SACGa,MAAS,EAAGlB,KAAQ,IAAKqB,KAAQ,WAChCH,MAAS,EACTlB,KAAQ,aACRqB,KAAQ,SACRqC,cAAgB,MAKpBvD,SAAY,QACZC,SAAY,WACZC,SACGa,MAAS,EAAGlB,KAAQ,IAAKqB,KAAQ,WAChCH,MAAS,EACTlB,KAAQ,aACRqB,KAAQ,SACRqC,cAAgB,gCC7BpBvD,SAAY,OACZC,SAAY,iBACZC,SACGa,MAAS,EAAGlB,KAAQ,IAAKqB,KAAQ,WAEpCf,QAEImD,OAAU,OACVzD,KAAQ,SACRqB,KAAQ,QACRqC,cAAgB,IAEjBD,OAAU,OAAQzD,KAAQ,QAASqB,KAAQ,YAI9ClB,SAAY,aACZC,SAAY,iBACZC,SACGa,MAAS,EAAGlB,KAAQ,IAAKqB,KAAQ,WACjCH,MAAS,EAAGlB,KAAQ,OAAQqB,KAAQ,aAIvClB,SAAY,MACZC,SAAY,iBACZC,SACGa,MAAS,EAAGlB,KAAQ,IAAKqB,KAAQ,WACjCH,MAAS,EAAGlB,KAAQ,UAAWqB,KAAQ,aAE1Cf,QACEmD,OAAU,iBACVzD,KAAQ,gBACRqB,KAAQ,SACRsC,aAAgB,MAIlBxD,SAAY,QACZC,SAAY,iBACZC,SACGa,MAAS,EAAGlB,KAAQ,IAAKqB,KAAQ,WACjCH,MAAS,EAAGlB,KAAQ,UAAWqB,KAAQ,aACtCH,MAAS,EACTlB,KAAQ,gBACRqB,KAAQ,SACRsC,aAAgB,MAKpBxD,SAAY,UACZC,SAAY,iBACZC,SACGa,MAAS,EAAGlB,KAAQ,IAAKqB,KAAQ,WACjCH,MAAS,EAAGlB,KAAQ,QAASqB,KAAQ,eAIxClB,SAAY,UACZC,SAAY,iBACZC,SACGa,MAAS,EAAGlB,KAAQ,IAAKqB,KAAQ,WAEpCf,QACEmD,OAAU,OACVG,iBAAoB,eACpB5D,KAAQ,OACRqB,KAAQ,eAIVlB,SAAY,iBACZC,SAAY,iBACZC,SACGa,MAAS,EAAGlB,KAAQ,IAAKqB,KAAQ,WACjCH,MAAS,EAAGlB,KAAQ,aAAcqB,KAAQ,aAC1CH,MAAS,EAAGlB,KAAQ,WAAYqB,KAAQ,eAI3ClB,SAAY,iBACZC,SAAY,iBACZC,SACGa,MAAS,EAAGlB,KAAQ,IAAKqB,KAAQ,WACjCH,MAAS,EAAGlB,KAAQ,aAAcqB,KAAQ,aAC1CH,MAAS,EAAGlB,KAAQ,QAASqB,KAAQ,eAIxClB,SAAY,eACZC,SAAY,iBACZC,SACGa,MAAS,EAAGlB,KAAQ,IAAKqB,KAAQ,WAEpCf,QACGmD,OAAU,aAAczD,KAAQ,YAAaqB,KAAQ,WACrDoC,OAAU,cAAezD,KAAQ,aAAcqB,KAAQ,4BClE5D,aACE,IAAMwC,GACJC,EAAYC,EAAWC,EAASC,EAAaC,EAAUC,EACvDC,EAAYC,EAASC,EAAOC,EAAOC,EAAUC,EAAeC,EAC5DC,EAAWC,EAAUC,GAEjBC,KAA6BC,OAAOC,SAAUnB,EAAIpC,IAAI,SAAAwD,GAAM,OAAAA,EAAGC,QAErEC,KAAKC,UAAYN,EAAYO,OACzB,SAAC5D,EAAK6D,GAEJ,OADA7D,EAAI6D,EAAOnF,UAAYmF,EAChB7D,OA+LjB,OA/ME8D,sBAAkBC,kBAAlB,WACE,OAAOL,KAAKM,YAAcN,KAAKM,UAAY,IAAIN,uCAsBjDK,2BAAA,SAAejB,GAAf,WAEQmB,KACAC,KACAC,EAHUrB,EAAM5D,KAGA0E,OAA8B,SAAC5D,EAAKd,GAQxD,OAPAc,EAAId,EAAKX,MAAQ6F,EAAKC,QAAQnF,GACd,gBAAZA,EAAKsE,IACPS,EAAanC,KAAK9B,EAAId,EAAKX,OAEb,UAAZW,EAAKsE,IACPU,EAAQpC,KAAK9B,EAAId,EAAKX,OAEjByB,OAGHpB,KACA0F,KACAC,EAAWT,OAAOU,KAAKL,GAgB7B,OAfAI,EAASE,QAAQ,SAAAC,GACf,IAAMxF,EAAOiF,EAAMO,GACnBxF,EAAKY,WAAW2E,QAAQ,SAAAlG,GACf,IAAAoC,UACPzB,EAAKN,OAAOkD,KAAKqC,EAAMxD,IACvBwD,EAAMxD,GAAUgE,SAAS7C,KAAK5C,KAEL,IAAvBA,EAAKN,OAAOiD,QAAcjD,EAAOkD,KAAK5C,KAG5CqF,EAASE,QAAQ,SAAAC,GACf,IAAMxF,EAAOiF,EAAMO,GACU,IAAzBxF,EAAKyF,SAAS9C,QAAcyC,EAAQxC,KAAK5C,MAGvCiF,QAAOvF,SAAQ0F,UAASJ,UAASD,iBAGnCF,oBAAR,SAAgB7E,GAGd,IAAM2E,EACF9E,EAAgBG,EAAKsE,KAAOE,KAAKC,UAAUzE,EAAKsE,QACnC,MAAbtE,EAAK0F,OACP1F,EAAK0F,SAGP,IAAMC,GACJtG,KAAMW,EAAKX,KACXiF,GAAItE,EAAKsE,GACT7E,SAAUkF,EAAOlF,SACjBmB,YACKZ,EAAK4F,WACD9E,IAAI,SAAA8E,GAAS,OAAAA,EAAMC,WAAW,KAAOD,EAAME,OAAO,GAAKF,IAChElG,UACA+F,YACArF,eACAiB,cACA0E,SAAU/F,EAAK0F,MA8HjB,OA3HqB,MAAjBf,EAAOjF,SACTiG,EAAQvF,YACJuE,EAAOjF,OAAOgF,OACV,SAAC5D,EAAKkF,GAMJ,OALAlF,EAAIkF,EAAM3G,OACRqB,KAAMsF,EAAMtF,KACZJ,gBAAiB0F,EAAMzF,MACvBE,cAAeuF,EAAMxF,KAEhBM,QAIC,MAAhB6D,EAAOhF,QACTgG,EAAQtE,WACJsD,EAAOhF,MAAM+E,OAAoC,SAAC5D,EAAKkF,GACrD,IAAMtF,EAAOsF,EAAMtF,KACfY,OAAQjB,EACZ,OAAQ2F,EAAMtF,MACZ,IAAK,cAIWL,KAHdiB,EAAQ2E,EACJjG,EAAK0F,KAAMM,EAAMlD,OAAQkD,EAAMhD,gBAENgD,EAAM/C,mBACjC3B,EAAQ2E,EACJjG,EAAK0F,KAAMM,EAAM/C,iBACjB+C,EAAMhD,eAEZ,MACF,IAAK,gBAIW3C,KAHdiB,EAAQ4E,EACJlG,EAAK0F,KAAMM,EAAMlD,OAAQkD,EAAMhD,gBAENgD,EAAM/C,mBACjC3B,EAAQ4E,EACJlG,EAAK0F,KAAMM,EAAM/C,iBACjB+C,EAAMhD,eAEZ,MACF,IAAK,cAIW3C,KAHdiB,EAAQ6E,EACJnG,EAAK0F,KAAMM,EAAMlD,OAChBkD,EAAMhD,cAAgB,KACEgD,EAAM/C,mBACjC3B,EAAQ6E,EACJnG,EAAK0F,KAAMM,EAAM/C,iBACjB+C,EAAMhD,eAEZ,MACF,IAAK,gBAGW3C,KAFdiB,EAAQ8E,EACJpG,EAAK0F,KAAMM,EAAMlD,OAAQkD,EAAMhD,gBACNgD,EAAM/C,mBACjC3B,EAAQ8E,EACJpG,EAAK0F,KAAMM,EAAM/C,iBACjB+C,EAAMhD,eAEZ,MACF,IAAK,YAGW3C,KAFdiB,EAAQ+E,EACJrG,EAAK0F,KAAMM,EAAMlD,OAAQkD,EAAMhD,gBACNgD,EAAM/C,mBACjC3B,EAAQ+E,EACJrG,EAAK0F,KAAMM,EAAM/C,iBACjB+C,EAAMhD,eAEZ,MACF,IAAK,cAGW3C,KAFdiB,EAAQgF,EACJtG,EAAK0F,KAAMM,EAAMlD,OAAQkD,EAAMhD,gBACNgD,EAAM/C,mBACjC3B,EAAQgF,EACJtG,EAAK0F,KAAMM,EAAM/C,iBACjB+C,EAAMhD,eAEZ,MACF,IAAK,aAGW3C,KAFdiB,EAAQiF,EACJvG,EAAK0F,KAAMM,EAAMlD,OAAQkD,EAAMhD,gBACNgD,EAAM/C,mBACjC3B,EAAQiF,EACJvG,EAAK0F,KAAMM,EAAM/C,iBACjB+C,EAAMhD,eAEZ,MACF,IAAK,eAGW3C,KAFdiB,EAAQkF,EACJxG,EAAK0F,KAAMM,EAAMlD,OAAQkD,EAAMhD,gBACNgD,EAAM/C,mBACjC3B,EAAQkF,EACJxG,EAAK0F,KAAMM,EAAM/C,iBACjB+C,EAAMhD,eAEZ,MACF,IAAK,aAGW3C,KAFdiB,EAAQmF,EACJzG,EAAK0F,KAAMM,EAAMlD,OAAQkD,EAAMhD,gBACNgD,EAAM/C,mBACjC3B,EAAQmF,EACJzG,EAAK0F,KAAMM,EAAM/C,iBACjB+C,EAAMhD,eAEZ,MACF,IAAK,eAGW3C,KAFdiB,EAAQoF,EACJ1G,EAAK0F,KAAMM,EAAMlD,OAAQkD,EAAMhD,gBACNgD,EAAM/C,mBACjC3B,EAAQoF,EACJ1G,EAAK0F,KAAMM,EAAM/C,iBACjB+C,EAAMhD,eAEZ,MACF,IAAK,SACL,IAAK,UACH,MACF,QACE,MAAM,IAAI2D,MACN,2BAA2BX,EAAMtF,iBAAgBV,EAAKsE,IAG9D,OADAxD,EAAIkF,EAAM3G,OAASiC,QAAOZ,QACnBI,QAGR6E,iBAkBKiB,EAAiBC,EAAcC,GAC7C,IAAMxF,EACFN,MAAM+F,QAAQF,GAAKG,OAAOC,aAAa5C,MAAM,KAAMwC,YAhB5BK,GAE3B,IAAMC,EAASC,MAAID,OACnB,QAA2B,IAAhBA,EAAOE,KAChB,OAAOF,EAAOE,KAAKH,GACd,GAAsB,oBAAXI,OAChB,OAAO,IAAIA,OAAOJ,EAAM,UAAUK,WAElC,MAAM,IAAIZ,MACN,oFAOsDa,CAAaX,GACzE,OAAOC,EAAWxF,EAAQA,EAAMmG,uBAGlBxB,EACZtG,EAA+CN,EAAcqI,EAC7DZ,gBAAAA,MACF,IAAMd,EAAQrG,EAAMN,GACpB,OAAa,MAAT2G,EACKY,EAAiBZ,EAAMa,EAAGC,GAE5BY,WAGOrB,EACZ1G,EAA+CN,EAC/CqI,GACF,IAAM1B,EAAQrG,EAAMN,GACpB,OAAO2G,EAAQA,EAAM2B,EAAID,WAGXvB,EACZxG,EAA+CN,EAC/CqI,GACF,IAAM1B,EAAQrG,EAAMN,OACdiC,EACY,MAAd0E,EAAS,EAAYA,EAAS,EAAmB,MAAdA,EAAS,EAAYA,EAAS,EAAI0B,EACzE,MAAyB,iBAAVpG,EAAsBA,EACAsG,SAAStG,EAAiB,aAGjDuG,EAAgBvG,GAK9B,OAJuB,qBAErBA,EAAQwG,EAAoBxG,IAEtBA,GACN,KAAKwG,EAAoBC,SACvB,MAAO,UACT,KAAKD,EAAoBE,SACvB,MAAO,QACT,KAAKF,EAAoBG,QACvB,MAAO,OACT,KAAKH,EAAoBI,UACvB,MAAO,UACT,KAAKJ,EAAoBK,UACvB,MAAO,SACT,QAGE,OAAO,eAIG1B,EACZ9G,EAA+CN,EAC/CqI,GACF,IAAM1B,EAAQrG,EAAMN,GACpB,OAAI2G,GAASA,EAAMtF,KACVmH,EAAgB7B,EAAMtF,MAExBgH,WAGOhB,EACZ/G,EAA+CN,EAC/CqI,GACF,IAAM1B,EAAQrG,EAAMN,GACpB,OAAI2G,GAASA,EAAMoC,MAAQpC,EAAMoC,KAAK1H,KAC7BsF,EAAMoC,KAAK1H,KAAKI,IAAI,SAAAuH,GAAK,OAAAR,EAAgBQ,KAE3CX,WAGOY,EAAsBC,GAEpC,IAAIA,EAAMC,YAGV,OAAiB,MAAbD,EAAME,IACDF,EAAME,IAAI3H,IACb,SAAA2H,GAAO,MAAqB,iBAAbA,EAAIjG,KACfiG,EAAIjG,KACJoF,SAASa,EAAIjG,KAAgB,kBAKzB+D,EACZ5G,EAA+CN,EAC/CqI,GACF,IAAM1B,EAAQrG,EAAMN,GACpB,OAAI2G,GAASA,EAAMuC,MACVD,EAAsBtC,EAAMuC,OAE9Bb,WAGOtB,EACZzG,EAA+CN,EAC/CqI,GACF,IAAM1B,EAAQrG,EAAMN,GACpB,OAAI2G,IACOA,EAAMoC,KAAKM,GAAK1C,EAAMoC,KAAKM,EAAE/F,OAASqD,EAAMoC,KAAKM,EAAI1C,EAAMoC,KAAK1F,QAC7D5B,IACG,SAAAuH,GAAK,MAAc,iBAANA,EAAkBA,EACAT,SAASS,EAAa,MAG/DX,WAGOxB,EACZvG,EAA+CN,EAAcqI,EAC7DZ,gBAAAA,MACF,IAAMd,EAAQrG,EAAMN,GACpB,OAAI2G,GAASA,EAAMoC,MAAQpC,EAAMoC,KAAKvB,EAC7Bb,EAAMoC,KAAKvB,EAAE/F,IAAI,SAACuH,GACvB,OAAOzB,EAAiByB,EAAGvB,KAGxBY,WAGOlB,EACZ7G,EAA+CN,EAC/CqI,GACF,IAAM1B,EAAQrG,EAAMN,GACpB,OAAI2G,GAASA,EAAMoC,MAAQpC,EAAMoC,KAAKG,MAC7BvC,EAAMoC,KAAKG,MAAMzH,IAAI,SAACuH,GAC3B,OAAOC,EAAsBD,KAG1BX,WAGOpB,EACZ3G,EAA+CN,EAC/CqI,GACF,IAAM1B,EAAQrG,EAAMN,GACpB,OAAI2G,GAASA,EAAMoC,MAAQpC,EAAMoC,KAAKT,EAC7B3B,EAAMoC,KAAKT,EAEbD,ECnYT,iBAGE,WACY1H,EAAoBC,EACpBC,GAFZ,WACYsE,UAAAxE,EAAoBwE,eAAAvE,EACpBuE,aAAAtE,EAJIsE,eACAA,cAIdA,KAAK9E,OAASM,EAAKY,WAAWE,IAAI,SAAAzB,GAAQ,OAAA6F,EAAKyD,SAAStJ,KACnC,MAAjBW,EAAK+F,WACPvB,KAAK7E,MAAQiF,OAAOU,KAAKtF,EAAK+F,UACZrB,OAAO,SAAC/E,EAAmC6F,GAE1C,OADA7F,EAAM6F,GAAON,EAAK0D,QAAQpD,GACnB7F,QA+DhC,OAtDUkJ,qBAAR,SAAiBxJ,GACf,OAAOsB,EAAUtB,EAAMmF,KAAKvE,UAAWuE,KAAKtE,UAOtC2I,oBAAR,SAAgBxJ,EAAc2D,GAC5B,IAAM1B,EAAQkD,KAAKxE,KAAK+F,SAAS1G,GACjC,GAAoB,MAAhBiC,EAAMwH,OACR,OAAOnI,EAAUtB,EAAMmF,KAAKvE,UAAWuE,KAAKtE,SAE9C,GAAe,MAAXoB,EAAMoB,GAAwB,MAAXpB,EAAMoH,EAC3B,OAAOvC,EAAe3B,KAAKxE,KAAK+F,SAAU1G,EAAM2D,GAElD,GAAe,MAAX1B,EAAMuF,EACR,OAAOZ,EAAezB,KAAKxE,KAAK+F,SAAU1G,EAAM2D,GAElD,GAAe,MAAX1B,EAAMqG,EACR,OAAOtB,EAAa7B,KAAKxE,KAAK+F,SAAU1G,EAAM2D,GAEhD,GAAmB,MAAf1B,EAAMiH,MACR,OAAOhC,EACH/B,KAAKxE,KAAK+F,SAAU1G,EAAM2D,GAEhC,GAAkB,MAAd1B,EAAMZ,KACR,OAAO+F,EAAcjC,KAAKxE,KAAK+F,SAAU1G,EAAM2D,GAEjD,GAAkB,MAAd1B,EAAM8G,KAAc,CACtB,GAAoB,MAAhB9G,EAAM8G,KAAK1F,GAA6B,MAAhBpB,EAAM8G,KAAKM,EACrC,OAAOtC,EACH5B,KAAKxE,KAAK+F,SAAU1G,EAAM2D,GAEhC,GAAoB,MAAhB1B,EAAM8G,KAAKvB,EACb,OAAOX,EACH1B,KAAKxE,KAAK+F,SAAU1G,EAAM2D,GAEhC,GAAwB,MAApB1B,EAAM8G,KAAKG,MACb,OAAO/B,EACHhC,KAAKxE,KAAK+F,SAAU1G,EAAM2D,GAEhC,GAAoB,MAAhB1B,EAAM8G,KAAKT,EACb,OAAOrB,EACH9B,KAAKxE,KAAK+F,SAAU1G,EAAM2D,GAEhC,GAAuB,MAAnB1B,EAAM8G,KAAK1H,KACb,OAAOgG,EACHlC,KAAKxE,KAAK+F,SAAU1G,EAAM2D,GAIlC,OAAOA,QC3EA+F,EAAgC,SAAC/I,EACAC,EACAC,GAE1C,OAAQF,EAAKsE,IACX,IAAK,UACL,IAAK,QACL,IAAK,MACH,OAAQ0E,MACHlJ,EAAc,IAAKE,EAAMC,EAAWC,GACrCJ,EAAc,IAAKE,EAAMC,EAAWC,KAE1C,IAAK,OACH,OAAQ+I,OACJnJ,EAAc,UAAWE,EAAMC,EAAWC,KAEhD,IAAK,WACL,IAAK,MACH,OAAQgJ,MACJpJ,EAAc,IAAKE,EAAMC,EAAWC,GACpCJ,EAAc,IAAKE,EAAMC,EAAWC,KAC1C,IAAK,MACH,OAAQiJ,MACJrJ,EAAc,IAAKE,EAAMC,EAAWC,GACpCJ,EAAc,IAAKE,EAAMC,EAAWC,KAC1C,IAAK,UACL,IAAK,MACH,OAAQkJ,MACJtJ,EAAc,IAAKE,EAAMC,EAAWC,GACpCJ,EAAc,IAAKE,EAAMC,EAAWC,KAE1C,IAAK,WACH,OAAQmJ,WACJvJ,EAAc,IAAKE,EAAMC,EAAWC,GACpCJ,EAAc,IAAKE,EAAMC,EAAWC,KAE1C,IAAK,MACH,OAAQoJ,MACJxJ,EAAc,IAAKE,EAAMC,EAAWC,GACpCJ,EAAc,IAAKE,EAAMC,EAAWC,KAE1C,IAAK,UACH,OAAQqJ,UACJzJ,EAAc,IAAKE,EAAMC,EAAWC,GACpCJ,EAAc,IAAKE,EAAMC,EAAWC,KAE1C,IAAK,UACH,OAAQsJ,UACJ1J,EAAc,IAAKE,EAAMC,EAAWC,GACpCJ,EAAc,IAAKE,EAAMC,EAAWC,KAE1C,IAAK,MACH,OAAQuJ,MACJ3J,EAAc,IAAKE,EAAMC,EAAWC,GACpCJ,EAAc,IAAKE,EAAMC,EAAWC,KAE1C,IAAK,oBACH,OAAQwJ,oBACJ5J,EAAc,IAAKE,EAAMC,EAAWC,GACpCJ,EAAc,IAAKE,EAAMC,EAAWC,KAE1C,QACE,MAAMyJ,UAAU,aAAa3J,EAAKsE,4BC9D7ByE,EAAgC,SAAC/I,EACAC,EACAC,GAE1C,OAAQF,EAAKsE,IACX,IAAK,MACL,IAAK,aACH,OAAQsF,MACJ9J,EAAc,IAAKE,EAAMC,EAAWC,KAC1C,IAAK,OACH,OAAQ2J,OACJ/J,EAAc,IAAKE,EAAMC,EAAWC,KAC1C,IAAK,QACH,OAAQ4J,QACJhK,EAAc,IAAKE,EAAMC,EAAWC,KAC1C,IAAK,OACH,OAAQ6J,OACJjK,EAAc,IAAKE,EAAMC,EAAWC,KAC1C,IAAK,QACH,OAAQ8J,QACJlK,EAAc,IAAKE,EAAMC,EAAWC,KAC1C,IAAK,OACH,OAAQ+J,OACJnK,EAAc,IAAKE,EAAMC,EAAWC,KAC1C,IAAK,QACH,OAAQgK,QACJpK,EAAc,IAAKE,EAAMC,EAAWC,GACpCJ,EAAc,IAAKE,EAAMC,EAAWC,KAC1C,IAAK,QACH,OAAQiK,QACJrK,EAAc,IAAKE,EAAMC,EAAWC,KAC1C,IAAK,OACH,OAAQkK,OACJtK,EAAc,IAAKE,EAAMC,EAAWC,KAC1C,IAAK,UACH,OAAQmK,UACJvK,EAAc,OAAQE,EAAMC,EAAWC,GACvCJ,EAAc,OAAQE,EAAMC,EAAWC,KAC7C,IAAK,MACH,OAAQoK,MACJxK,EAAc,IAAKE,EAAMC,EAAWC,KAC1C,IAAK,OACH,OAAQqK,OACJzK,EAAc,IAAKE,EAAMC,EAAWC,KAC1C,IAAK,MACH,OAAQsK,MACJ1K,EAAc,IAAKE,EAAMC,EAAWC,KAC1C,IAAK,MACH,OAAQuK,MACJ3K,EAAc,IAAKE,EAAMC,EAAWC,KAC1C,IAAK,MACH,OAAQwK,MACJ5K,EAAc,IAAKE,EAAMC,EAAWC,KAC1C,IAAK,QACH,OAAQyK,QACJ7K,EAAc,IAAKE,EAAMC,EAAWC,KAE1C,IAAK,QACH,OAAQ0K,QACJ9K,EAAc,IAAKE,EAAMC,EAAWC,KAC1C,IAAK,MACH,OAAQ2K,MACJ/K,EAAc,IAAKE,EAAMC,EAAWC,KAC1C,IAAK,QACH,OAAQ4K,QACJhL,EAAc,IAAKE,EAAMC,EAAWC,KAE1C,IAAK,OACH,OAAQ6K,OACJjL,EAAc,IAAKE,EAAMC,EAAWC,KAE1C,IAAK,MACH,OAAQ8K,MACJlL,EAAc,IAAKE,EAAMC,EAAWC,KAC1C,IAAK,aACH,OAAQ+K,aACJnL,EAAc,IAAKE,EAAMC,EAAWC,KAE1C,IAAK,OACH,OAAQgL,OACJpL,EAAc,IAAKE,EAAMC,EAAWC,KAC1C,IAAK,OACH,OAAQiL,OACJrL,EAAc,IAAKE,EAAMC,EAAWC,KAC1C,IAAK,QACH,OAAQkL,QACJtL,EAAc,IAAKE,EAAMC,EAAWC,KAE1C,IAAK,OACH,OAAQmL,OACJvL,EAAc,IAAKE,EAAMC,EAAWC,KAC1C,IAAK,UACH,OAAQoL,UACJxL,EAAc,IAAKE,EAAMC,EAAWC,KAC1C,IAAK,MACH,OAAQqL,MACJzL,EAAc,IAAKE,EAAMC,EAAWC,KAC1C,IAAK,OACH,OAAQsL,OACJ1L,EAAc,IAAKE,EAAMC,EAAWC,KAE1C,IAAK,OACH,OAAQuL,OACJ3L,EAAc,IAAKE,EAAMC,EAAWC,KAE1C,IAAK,WACH,OAAQwL,WACJ5L,EAAc,IAAKE,EAAMC,EAAWC,KAE1C,IAAK,OACH,OAAQyL,OACJ7L,EAAc,IAAKE,EAAMC,EAAWC,KAE1C,IAAK,SACH,OAAQ0L,SACJ9L,EAAc,IAAKE,EAAMC,EAAWC,KAE1C,IAAK,OACH,OAAQ2L,OACJ/L,EAAc,IAAKE,EAAMC,EAAWC,KAE1C,IAAK,MACH,OAAQ4L,MACJhM,EAAc,IAAKE,EAAMC,EAAWC,KAC1C,IAAK,QACL,IAAK,cACH,OAAQ6L,cACJjM,EAAc,IAAKE,EAAMC,EAAWC,GACpCJ,EAAc,eAAgBE,EAAMC,EAAWC,GAC/CJ,EAAc,eAAgBE,EAAMC,EAAWC,KACrD,IAAK,QACH,OAAQ8L,QAAUrL,EAAUX,EAAKY,WAAW,GAAIX,EAAWC,KAC7D,IAAK,OACH,OAAQ+L,OACJnM,EAAc,IAAKE,EAAMC,EAAWC,GACpCJ,EAAc,OAAQE,EAAMC,EAAWC,KAC7C,IAAK,YACH,OAAQgM,YACJpM,EAAc,IAAKE,EAAMC,EAAWC,GACpCJ,EAAc,QAASE,EAAMC,EAAWC,KAC9C,QACE,MAAMyJ,UAAU,aAAa3J,EAAKsE,yCCpItC,WACoBjF,EAA8B8M,EACtCC,EAAyBC,EACjBC,EACAC,EACAC,GAJAhI,UAAAnF,EAA8BmF,WAAA2H,EACtC3H,aAAA4H,EAAyB5H,kBAAA6H,EACjB7H,4BAAA8H,EACA9H,iBAAA+H,EACA/H,oBAAAgI,EARZhI,gBACAA,cAAU,EAQhBA,KAAKiI,GAAKC,EAAYC,SAgS1B,OA7RE/H,sBAAI8H,0BAAJ,WACE,OAAOlI,KAAKoI,yCAMdF,0BAAA,WACElI,KAAKqI,QAAQtH,QAAQ,SAAAuD,GAAU,OAAAA,EAAOA,OAAOgE,YAC7CtI,KAAKqI,WACLrI,KAAKoI,SAAU,GAGjBF,iBAAA,WACE,OAAOlI,KAAKqI,QAAQlK,QAOtB+J,iBAAA,SAAKhL,GACH,GAAI8C,KAAKoI,QACP,MAAM,IAAIjG,MAAM,eAAenC,KAAKnF,kCAGtC,GAAIqC,EAAQ,GAAKA,GAAS8C,KAAKqI,QAAQlK,OACrC,MAAM,IAAIgE,MAAM,4BAA4BjF,0BACxC8C,KAAKqI,QAAQlK,QAGnB,IAAMoK,EAAkBvI,KAAKqI,QAAQnL,GACrC,GAAIqL,EAAgBC,QAClB,MAAM,IAAIrG,MACN,eAAenC,KAAKnF,+BAChBqC,0GASV,OALI8C,KAAKgI,iBACPO,EAAgBC,SAAU,GAG5BD,EAAgBE,MAAO,EAChBF,EAAgBjE,QAMzB4D,qBAAA,SAASQ,GAAT,WACE,OAAOA,EAAQpM,IAAI,SAAAY,GAAS,OAAAwD,EAAK+H,KAAKvL,MAQxCgL,kBAAA,SAAMhL,EAAeoH,GACnB,GAAItE,KAAKoI,QACP,MAAM,IAAIjG,MAAM,eAAenC,KAAKnF,kCAGtC,GAAIqC,EAAQ,IAAM8C,KAAK+H,aAAe7K,GAAS8C,KAAK4H,QAClD,MAAM,IAAIzF,MAAM,2BACZjF,gDAAmD8C,KAAK4H,SAG9D,IAAMe,EAAI3I,KAAKqI,QAAQnL,OAEvB,GAAIoH,EAAOqD,QAAU3H,KAAK2H,MACxB,MAAM,IAAIxF,MAAM,eACZnC,KAAKnF,+CAA8CqC,6CAEnDoH,EAAOqD,oCAAmC3H,KAAK2H,WAcrD,GAVoB,IAAhB3H,KAAKhC,QACiB,MAArBgC,KAAK6H,cAAqD,IAA7B7H,KAAK6H,aAAa1J,SAClD6B,KAAK6H,aAAevD,EAAOP,OAG7B/D,KAAK4I,oCACD5I,KAAK6H,aAAcvD,EAAOP,MAC1B,eAAe/D,KAAKnF,+CAChBqC,OAEJyL,GAAKA,EAAEF,KACT,MAAM,IAAItG,MACN,eAAenC,KAAKnF,+CAChBqC,yCAGV,GAAIyL,GAAKA,EAAEE,QACT,MAAM,IAAI1G,MACN,eAAenC,KAAKnF,+CAChBqC,4CAGVyL,EAAErE,OAASA,EACXqE,EAAEE,SAAU,EAEZ7I,KAAKqI,QAAQnL,GAASyL,GAMxBT,sBAAA,SAAUQ,EAAmBL,GAA7B,WACE,GAAIK,EAAQvK,SAAWkK,EAAQlK,OAC7B,MAAM,IAAIgE,MACN,eAAenC,KAAKnF,mEAEhB6N,EAAQvK,4CACRkK,EAAQlK,YAGlBuK,EAAQ3H,QAAQ,SAAC7C,EAAGhB,GAAU,OAAAwD,EAAKoI,MAAM5K,EAAGmK,EAAQnL,OAWtDgL,mBAAA,SAAOQ,EAAoBf,GACzB,GAAMA,GAASA,IAAU3H,KAAK2H,MAC5B,MAAM,IAAIxF,MAAM,wBACZnC,KAAK2H,qCAAoCA,GAG/C,IAAKe,EAAS,CACZA,KACA,IAAK,IAAIxK,EAAI,EAAGA,EAAI8B,KAAKhC,OAAQE,IAC/BwK,EAAQtK,KAAKF,GAIjB,GAAuB,IAAnBwK,EAAQvK,OACV,OAAOmG,aAAY,GAAG1E,OAAOI,KAAK6H,eAKpC,IAAMQ,EAAUrI,KAAK+I,SAASL,GAK9B,OAHA1I,KAAK4I,oCACD5I,KAAK6H,aAAcQ,EAAQ,GAAGtE,MAAO,gCAElCiF,QAAMX,EAAS,IAMxBH,mBAAA,SAAOP,GACL,GAAMA,GAASA,IAAU3H,KAAK2H,MAC5B,MAAM,IAAIxF,MAAM,wBACZnC,KAAK2H,qCAAoCA,GAG/C,GAAoB,IAAhB3H,KAAKhC,OACP,OAAOsG,aAAY,GAAG1E,OAAOI,KAAK6H,eAIpC,IADA,IAAMa,KACGxK,EAAI,EAAGA,EAAI8B,KAAKhC,OAAQE,IAC/BwK,EAAQtK,KAAKF,GAGf,IAAMmK,EAAUrI,KAAK+I,SAASL,GAO9B,OALA1I,KAAK4I,oCACD5I,KAAK6H,aAAcQ,EAAQ,GAAGtE,MAC9B,mDACI/D,KAAK6H,yCAAwCQ,EAAQ,GAAGtE,WAEzDnE,SAAOyI,EAAS,IASzBH,oBAAA,SAAQQ,EAAmBpE,GACzB,GAAIA,EAAOqD,QAAU3H,KAAK2H,MACxB,MAAM,IAAIxF,MAAM,wBACZnC,KAAK2H,+BAA8BrD,EAAOqD,OAGhD,GAAIe,EAAQvK,SAAWmG,EAAOP,MAAM,GAClC,MAAM,IAAI5B,MAAM,sDACZuG,EAAQvK,eAAcmG,EAAOP,MAAM,IAGzC,IAAMkF,EAAWC,KAAKC,UAALD,KAAYR,GAE7B,IAAK1I,KAAK+H,aAAekB,GAAYjJ,KAAK4H,QACxC,MAAM,IAAIzF,MACN,mCAAmC8G,WAAiBjJ,KAAK4H,aAG/D5H,KAAKoJ,UAAUV,EAASW,UAAQ/E,EAAQ,KAS1C4D,kBAAA,SAAM/J,EAAkBmG,GAAxB,WACE,GAAIA,EAAOqD,QAAU3H,KAAK2H,MACxB,MAAM,IAAIxF,MAAM,wBACZnC,KAAK2H,+BAA8BrD,EAAOqD,OAEhD,IAAI2B,EAAc,EACZC,EAAoBpL,EAAO7B,IAAI,SAAAkN,GAEnC,OADAF,GAAeE,IAIjB,GAAIF,IAAgBhF,EAAOP,MAAM,GAC/B,MAAM,IAAI5B,MAAM,qGAEZmH,8BAAuChF,EAAOP,OAGpD,IAAK/D,KAAK+H,aAAe5J,EAAOA,SAAW6B,KAAK4H,QAC9C,MAAM,IAAIzF,MACN,2DACInC,KAAK4H,gBAAezJ,EAAOA,yEAIrC,IAAMsL,EAAgC,IAAhBH,EAAoB,EAAIhF,EAAOtG,KAAOsL,EACtDjB,KACNqB,OAAK,WACHpF,EAASA,EAAOqF,SAAS,EAAGL,EAAaG,IACzC,IAAK,IAAIvL,EAAI,EAAGA,EAAIC,EAAOA,SAAUD,EAAG,CACtC,IACM0L,GAAW,EADa,IAAN1L,EAAW,EAAIqL,EAAkBrL,EAAI,GACzB,GAC9B2L,GAAS,EAAG1L,EAAOD,GAAIuL,GAC7BpB,EAAQnK,GAAK7B,QAAMiI,EAAQsF,EAASC,GAAOF,QAAQjJ,EAAKmH,cAE1D,OAAOQ,IAGT,IADA,IAAMK,KACGxK,EAAI,EAAGA,EAAIC,EAAOA,OAAQD,IACjCwK,EAAQxK,GAAKA,EAEf8B,KAAKoJ,UAAUV,EAASL,IAQlBH,gDAAR,SACI4B,EAAkBC,EAAkBC,gBAAAA,MACtCC,OAAKC,OACDlK,KAAKmK,8BAA8BL,EAAQC,GAC3C,WACI,OAAAC,EAAqB,WAAWF,UAAcC,mBAGhD7B,0CAAR,SAAsCkC,EAAcC,GAClD,GAAID,EAAGjM,SAAWkM,EAAGlM,OACnB,OAAO,EAET,IAAK,IAAID,EAAI,EAAGA,EAAIkM,EAAGjM,OAAQD,IAC7B,IAAe,IAAXkM,EAAGlM,KAAwB,IAAXmM,EAAGnM,IAAakM,EAAGlM,KAAOmM,EAAGnM,GAC/C,OAAO,EAGX,OAAO,GAxSMgK,SAAS,OCLnB,IAAI3D,EACP,SAAC/I,EAAYC,EACZC,GACC,OAAQF,EAAKsE,IACX,IAAK,SACH,IAAMwK,EACFhP,EAAc,SAAUE,EAAMC,EAAWC,GACvC6O,EAAMjP,EAAc,MAAOE,EAAMC,EAAWC,GAC5C8O,EACDlP,EAAc,aAAcE,EAAMC,EAAWC,GACzC+O,cACHC,EACFpP,EAAc,WAAYE,EAAMC,EAAWC,GAC/C,OAAQiP,SACJrP,EAAc,IAAKE,EAAMC,EAAWC,GACpCJ,EAAc,SAAUE,EAAMC,EAAWC,GACzC4O,EAAQC,EAAyBC,EACjCE,IAEN,IAAK,SACGJ,EACFhP,EAAc,UAAWE,EAAMC,EAAWC,GACxC6O,EAAMjP,EAAc,MAAOE,EAAMC,EAAWC,GAC5C8O,EACDlP,EAAc,aAAcE,EAAMC,EAAWC,GACzC+O,cALT,IAMMG,EACFtP,EAAc,YAAaE,EAAMC,EAAWC,GAChD,OAAQmP,SACJvP,EAAc,IAAKE,EAAMC,EAAWC,GAEpCJ,EAAc,SAAUE,EAAMC,EAAWC,IACxC4O,EAAO,GAAIA,EAAO,IAAKC,EACxBC,GAAgCI,EAAU,GAAIA,EAAU,MAE9D,IAAK,sBACL,IAAK,kBACH,IAAM7G,EAAQzI,EACI,cAAeE,EAAMC,EACrBC,GAEZ4O,EACFhP,EAAc,UAAWE,EAAMC,EAAWC,GACxC6O,EAAMjP,EAAc,MAAOE,EAAMC,EAAWC,GAClD,OAAQoP,kBACJxP,EAAc,IAAKE,EAAMC,EAAWC,GAEpCJ,EAAc,SAAUE,EAAMC,EAAWC,GACzCqI,GAAQuG,EAAO,GAAIA,EAAO,IAAKC,IAErC,IAAK,wBACL,IAAK,kBACGD,EACFhP,EAAc,UAAWE,EAAMC,EAAWC,GACxC6O,EAAMjP,EAAc,MAAOE,EAAMC,EAAWC,GAC5CkP,EACFtP,EAAc,YAAaE,EAAMC,EAAWC,GAC1C8O,EACDlP,EAAc,aAAcE,EAAMC,EAAWC,GACzC+O,cAET,OAAQM,kBACJzP,EAAc,QAASE,EAAMC,EAAWC,GAExCJ,EAAc,SAAUE,EAAMC,EAAWC,IACxC4O,EAAO,GAAIA,EAAO,IAAKC,EACxBC,GAAgCI,EAAU,GAAIA,EAAU,MAE9D,IAAK,SACGN,EACFhP,EAAc,UAAWE,EAAMC,EAAWC,GACxC6O,EAAMjP,EAAc,MAAOE,EAAMC,EAAWC,GAC5C8O,EACDlP,EAAc,aAAcE,EAAMC,EAAWC,GACzC+O,cACHG,EACFtP,EAAc,YAAaE,EAAMC,EAAWC,GAChD,OAAQsP,SACJ1P,EAAc,IAAKE,EAAMC,EAAWC,GAEpCJ,EAAc,SAAUE,EAAMC,EAAWC,IAExC4O,EAAO,GAAIA,EAAO,GAAIA,EAAO,IAAKC,EACnCC,GACCI,EAAU,GAAIA,EAAU,GAAIA,EAAU,MAG7C,IAAK,UACGN,EACFhP,EAAc,UAAWE,EAAMC,EAAWC,GACxC6O,EAAMjP,EAAc,MAAOE,EAAMC,EAAWC,GAFlD,IAGMuP,EACF3P,EAAc,aAAcE,EAAMC,EAAWC,GAEjD,OAAQwP,UACJ5P,EAAc,IAAKE,EAAMC,EAAWC,IAEnCuP,EAAW,GAAIA,EAAW,KAAMX,EAAO,GAAIA,EAAO,IACnDC,IAGN,IAAK,UACGD,EACFhP,EAAc,UAAWE,EAAMC,EAAWC,GACxC6O,EAAMjP,EAAc,MAAOE,EAAMC,EAAWC,GAC5CuP,EACF3P,EAAc,aAAcE,EAAMC,EAAWC,GAEjD,OAAQyP,UACJ7P,EAAc,IAAKE,EAAMC,EAAWC,IAEnCuP,EAAW,GAAIA,EAAW,KAAMX,EAAO,GAAIA,EAAO,IACnDC,IAGN,IAAK,YACGD,EACFhP,EAAc,UAAWE,EAAMC,EAAWC,GACxC6O,EAAMjP,EAAc,MAAOE,EAAMC,EAAWC,GAC5CuP,EACF3P,EAAc,aAAcE,EAAMC,EAAWC,GAEjD,OAAQ0P,YACJ9P,EAAc,IAAKE,EAAMC,EAAWC,IACnCuP,EAAW,GAAIA,EAAW,GAAIA,EAAW,KACzCX,EAAO,GAAIA,EAAO,GAAIA,EAAO,IAAKC,IAGzC,IAAK,YACGD,EACFhP,EAAc,UAAWE,EAAMC,EAAWC,GACxC6O,EAAMjP,EAAc,MAAOE,EAAMC,EAAWC,GAC5CuP,EACF3P,EAAc,aAAcE,EAAMC,EAAWC,GAEjD,OAAQ2P,YACJ/P,EAAc,IAAKE,EAAMC,EAAWC,IACnCuP,EAAW,GAAIA,EAAW,GAAIA,EAAW,KACzCX,EAAO,GAAIA,EAAO,GAAIA,EAAO,IAAKC,IAGzC,QACE,MAAMpF,UAAU,aAAa3J,EAAKsE,4BC9IjCyE,EAAgC,SAAC/I,EACAC,EACAC,GAE1C,OAAQF,EAAKsE,IACX,IAAK,OACH,IAAMiE,EACFzI,EAAc,QAASE,EAAMC,EAAWC,GACtCiM,EACFrM,EAAc,QAASE,EAAMC,EAAWC,GACtCoB,EAAQxB,EAAc,QAASE,EAAMC,EAAWC,GACtD,OAAQ4P,OAASvH,EAAOjH,EAAO6K,IAEjC,IAAK,WACH,IAAM5L,EAAQT,EAAc,QAASE,EAAMC,EAAWC,GAChD6P,EAAOjQ,EAAc,OAAQE,EAAMC,EAAWC,GAC9C8P,EAAMlQ,EAAc,MAAOE,EAAMC,EAAWC,GAClD,OAAQ+P,WAAa1P,EAAOwP,EAAMC,IAEpC,IAAK,SACH,IAAM9C,EACFpN,EAAc,UAAWE,EAAMC,EAAWC,GACxCgQ,EAAQpQ,EAAc,QAASE,EAAMC,EAAWC,GAChDiQ,EACFrQ,EAAc,UAAWE,EAAMC,EAAWC,GACxCkQ,EACFtQ,EAAc,WAAYE,EAAMC,EAAWC,GAC/C,OAAQmQ,SAAWnD,EAASgD,EAAOC,EAASC,IAE9C,IAAK,OACH,OAAQE,OACJxQ,EAAc,QAASE,EAAMC,EAAWC,GACxCJ,EAAc,QAASE,EAAMC,EAAWC,KAE9C,IAAK,WACH,OAAQqQ,WACJzQ,EAAc,IAAKE,EAAMC,EAAWC,KAE1C,IAAK,gBACH,OAAQsQ,gBAEJ1Q,EAAc,QAASE,EAAMC,EAAWC,GACxCJ,EAAc,SAAUE,EAAMC,EAAWC,GACzCJ,EAAc,SAAUE,EAAMC,EAAWC,GACzCJ,EAAc,QAASE,EAAMC,EAAWC,KAE9C,IAAK,QACGK,EAAQT,EAAc,QAASE,EAAMC,EAAWC,GAAtD,IACMuQ,EAAO3Q,EAAc,OAAQE,EAAMC,EAAWC,GAC9CwQ,EAAO5Q,EAAc,OAAQE,EAAMC,EAAWC,GACpD,OAAQyQ,QACJpQ,EAAOkQ,EAAMC,EACb5Q,EAAc,QAASE,EAAMC,EAAWC,KAG9C,IAAK,kBACGqI,EACFzI,EAAc,QAASE,EAAMC,EAAWC,GAD5C,IAEM0Q,EAAO9Q,EAAc,OAAQE,EAAMC,EAAWC,GAC9C2Q,EACF/Q,EAAc,SAAUE,EAAMC,EAAWC,GACvC4Q,EAAOhR,EAAc,OAAQE,EAAMC,EAAWC,GACpD,OAAQ6Q,kBACJxI,EAAOqI,EAAMC,EACb/Q,EAAc,QAASE,EAAMC,EAAWC,GAExC4Q,IAEN,IAAK,QACH,OAAQE,QACJlR,EAAc,QAASE,EAAMC,EAAWC,GACxCJ,EAAc,QAASE,EAAMC,EAAWC,KAE9C,IAAK,YACH,OAAQ+Q,YACJnR,EAAc,IAAKE,EAAMC,EAAWC,KAE1C,QACE,MAAMyJ,UAAU,aAAa3J,EAAKsE,4BC9EjC,IAAIyE,EACP,SAAC/I,EAAYC,EACZC,GACC,OAAQF,EAAKsE,IACX,IAAK,SACH,IAAM4M,EAAIpR,EAAc,IAAKE,EAAMC,EAAWC,GACxCiR,EAAIrR,EAAc,IAAKE,EAAMC,EAAWC,GACxCkR,EACFtR,EAAc,SAAUE,EAAMC,EAAWC,GACvCmR,EAASC,OAASJ,EAAGC,EAAGC,GAC9B,OAAQC,EAAOE,OAAQF,EAAOnE,SAEhC,QACE,MAAMvD,UAAU,aAAa3J,EAAKsE,4BCbjCyE,EAAgC,SAAC/I,EACAC,EACAC,GAE1C,OAAQF,EAAKsE,IACX,IAAK,QACH,OAAOrE,EAAUD,EAAKX,MAExB,IAAK,yBACH,IAAMqI,EACF5H,EAAc,UAAWE,EAAMC,EAAWC,GAC9C,OAAQS,EAAUX,EAAKX,KAAMY,EAAWC,IAAYwH,GACtD,IAAK,cACH,OAAQ/G,EAAUX,EAAKX,KAAMY,EAAWC,IAC1C,IAAK,WACL,IAAK,eACL,IAAK,0BACH,OACGJ,EAAc,IAAKE,EAAMC,EAAWC,GAAwBsR,SAEjE,IAAK,YACH,OAAQ1R,EAAc,IAAKE,EAAMC,EAAWC,GACvCY,IAAI,SAACqM,GAAkB,OAAAA,EAAEqE,UAChC,IAAK,WAGH,OADK1R,EAAc,IAAKE,EAAMC,EAAWC,GACxBsR,SACnB,IAAK,QACH,OAAQC,WACH3R,EAAc,IAAKE,EAAMC,EAAWC,GAAwBqI,MAC7D,UACN,IAAK,SACH,OAAQzI,EAAc,IAAKE,EAAMC,EAAWC,GACvCY,IAAI,SAACqM,GAAkB,OAAAsE,WAAatE,EAAE5E,SAC7C,IAAK,OACH,OAAQmJ,SACH5R,EAAc,IAAKE,EAAMC,EAAWC,GAAwBsC,KAC7D,UACN,IAAK,OACH,OAAQkP,SACH5R,EAAc,IAAKE,EAAMC,EAAWC,GAAwByR,KAC7D,UACN,IAAK,OACH,SACF,IAAK,QACH,IAAM/L,EAAQ9F,EAAc,IAAKE,EAAMC,EAAWC,GAC5Ca,EACFjB,EAAc,OAAQE,EAAMC,EAAWC,GACrC0R,EACF9R,EAAc,UAAWE,EAAMC,EAAWC,GACxC2R,EACF/R,EAAc,YAAaE,EAAMC,EAAWC,GAChD4R,QAAQC,KACJ,kGAEJD,QAAQE,IAAIJ,GACZ,IAAK,IAAIlP,EAAI,EAAGA,EAAI3B,EAAK4B,OAAQD,IAC/BoP,QAAQE,IACJhR,MAAMC,UAAUJ,MAAMK,KAAKH,EAAK2B,GAAGvB,YAAYN,MAAM,EAAGgR,IAE9D,OAAQjM,GAEV,QACE,MAAM+D,UAAU,aAAa3J,EAAKsE,4BC/D7ByE,GAAgC,SAAC/I,EACAC,EACAC,GAE1C,OAAQF,EAAKsE,IACX,IAAK,iBACH,IAAM2N,EACFnS,EAAc,SAAUE,EAAMC,EAAWC,GACvCsC,EAAO1C,EAAc,OAAQE,EAAMC,EAAWC,GAC9CgS,EACFpS,EAAc,eAAgBE,EAAMC,EAAWC,GACnD,OAAQiS,QAAUC,eACdH,GAAwCzP,EAAK,GAAIA,EAAK,IACtD0P,IAEN,IAAK,wBACGD,EACFnS,EAAc,SAAUE,EAAMC,EAAWC,GACvCsC,EAAO1C,EAAc,OAAQE,EAAMC,EAAWC,GAC9CgS,EACFpS,EAAc,eAAgBE,EAAMC,EAAWC,GACnD,OAAQiS,QAAUE,sBACdJ,GAAwCzP,EAAK,GAAIA,EAAK,IACtD0P,IAEN,IAAK,gBACH,IAAMvO,EACF7D,EAAc,QAASE,EAAMC,EAAWC,GACtCoS,EACFxS,EAAc,QAASE,EAAMC,EAAWC,GACtCqS,EACFzS,EAAc,SAAUE,EAAMC,EAAWC,GACvCsS,EACF1S,EAAc,WAAYE,EAAMC,EAAWC,GACzCuS,EACF3S,EAAc,SAAUE,EAAMC,EAAWC,GACvCwS,EACF5S,EAAc,qBAAsBE,EAAMC,EAAWC,GAEzD,OAAQiS,QAAUQ,cACdhP,EAAuB2O,EAAuBC,EAC9CC,EAA8BC,EAC9BC,IAEN,QACE,MAAM/I,UAAU,aAAa3J,EAAKsE,4BC7C7ByE,GAAgC,SAAC/I,EACAC,EACAC,GAE1C,OAAQF,EAAKsE,IACX,IAAK,QACH,OAAQsO,QACJ9S,EAAc,IAAKE,EAAMC,EAAWC,GACpCJ,EAAc,IAAKE,EAAMC,EAAWC,KAE1C,IAAK,WACH,OAAQ2S,WACJ/S,EAAc,IAAKE,EAAMC,EAAWC,GACpCJ,EAAc,IAAKE,EAAMC,EAAWC,KAE1C,IAAK,UACH,OAAQ4S,UACJhT,EAAc,IAAKE,EAAMC,EAAWC,GACpCJ,EAAc,IAAKE,EAAMC,EAAWC,KAE1C,IAAK,eACH,OAAQ6S,eACJjT,EAAc,IAAKE,EAAMC,EAAWC,GACpCJ,EAAc,IAAKE,EAAMC,EAAWC,KAE1C,IAAK,OACH,OAAQ8S,OACJlT,EAAc,IAAKE,EAAMC,EAAWC,GACpCJ,EAAc,IAAKE,EAAMC,EAAWC,KAE1C,IAAK,YACH,OAAQ+S,YACJnT,EAAc,IAAKE,EAAMC,EAAWC,GACpCJ,EAAc,IAAKE,EAAMC,EAAWC,KAE1C,IAAK,aACH,OAAQgT,aACJpT,EAAc,IAAKE,EAAMC,EAAWC,GACpCJ,EAAc,IAAKE,EAAMC,EAAWC,KAE1C,IAAK,aACH,OAAQiT,aACJrT,EAAc,IAAKE,EAAMC,EAAWC,KAE1C,IAAK,YACH,OAAQkT,YACJtT,EAAc,IAAKE,EAAMC,EAAWC,GACpCJ,EAAc,IAAKE,EAAMC,EAAWC,KAE1C,IAAK,SACH,OAAQmT,QACJvT,EAAc,YAAaE,EAAMC,EAAWC,GAC5CJ,EAAc,IAAKE,EAAMC,EAAWC,GACpCJ,EAAc,IAAKE,EAAMC,EAAWC,KAE1C,QACE,MAAMyJ,UAAU,aAAa3J,EAAKsE,4BCxD7ByE,GAAgC,SAAC/I,EACAC,EACAC,GAE1C,OAAQF,EAAKsE,IACX,IAAK,cACL,IAAK,gBACL,IAAK,SACH,OAAQgP,SACJxT,EAAc,IAAKE,EAAMC,EAAWC,GACpCJ,EAAc,IAAKE,EAAMC,EAAWC,GACpCJ,EAAc,aAAcE,EAAMC,EAAWC,GAC7CJ,EAAc,aAAcE,EAAMC,EAAWC,KACnD,IAAK,YACH,OAAQqT,YACJzT,EAAc,IAAKE,EAAMC,EAAWC,GACpCJ,EAAc,OAAQE,EAAMC,EAAWC,KAE7C,QACE,MAAMyJ,UAAU,aAAa3J,EAAKsE,4BCnB7ByE,GAAgC,SAAC/I,EACAC,EACAC,GAE1C,OAAQF,EAAKsE,IACX,IAAK,iBACL,IAAK,mBASL,IAAK,mBACH,OAAQkP,YACJ1T,EAAc,IAAKE,EAAMC,EAAWC,GACpCJ,EAAc,OAAQE,EAAMC,EAAWC,GACvCJ,EAAc,WAAYE,EAAMC,EAAWC,GAC3CJ,EAAc,SAAUE,EAAMC,EAAWC,GACzCJ,EAAc,QAASE,EAAMC,EAAWC,GACxCJ,EAAc,UAAWE,EAAMC,EAAWC,KAEhD,IAAK,MACH,OAAQuT,6BACJ3T,EAAc,IAAKE,EAAMC,EAAWC,GAEpCJ,EAAc,SAAUE,EAAMC,EAAWC,GACzCJ,EAAc,OAAQE,EAAMC,EAAWC,GACvCJ,EAAc,QAASE,EAAMC,EAAWC,GACxCJ,EAAc,OAAQE,EAAMC,EAAWC,KAE7C,IAAK,UACH,OAAQwT,UACJ5T,EAAc,IAAKE,EAAMC,EAAWC,KAE1C,IAAK,aACH,OAAQyT,aACJ7T,EAAc,IAAKE,EAAMC,EAAWC,KAE1C,IAAK,gBACH,OAAQ0T,gBACJ9T,EAAc,gBAAiBE,EAAMC,EAAWC,GAEhDJ,EAAc,cAAeE,EAAMC,EAAWC,GAC9CJ,EAAc,eAAgBE,EAAMC,EAAWC,GAC/CJ,EAAc,eAAgBE,EAAMC,EAAWC,KAGrD,QACE,MAAMyJ,UAAU,aAAa3J,EAAKsE,4BCnD7ByE,GAAgC,SAAC/I,EACAC,EACAC,GAE1C,OAAQF,EAAKsE,IACX,IAAK,MACH,IAAMuP,EAAO/T,EAAc,OAAQE,EAAMC,EAAWC,GAC9C4T,EACFhU,EAAc,WAAYE,EAAMC,EAAWC,GAC/C,OAAQ6T,MACJjU,EAAc,IAAKE,EAAMC,EAAWC,GAAwB2T,EAC5DC,IAEN,IAAK,OACGD,EAAO/T,EAAc,OAAQE,EAAMC,EAAWC,GAC9C4T,EACFhU,EAAc,WAAYE,EAAMC,EAAWC,GAC/C,OAAQ8T,OACJlU,EAAc,IAAKE,EAAMC,EAAWC,GAAwB2T,EAC5DC,IAEN,IAAK,MACGD,EAAO/T,EAAc,OAAQE,EAAMC,EAAWC,GAC9C4T,EACFhU,EAAc,WAAYE,EAAMC,EAAWC,GAC/C,OAAQ+T,MACJnU,EAAc,IAAKE,EAAMC,EAAWC,GAAwB2T,EAC5DC,IAEN,IAAK,MACGD,EAAO/T,EAAc,OAAQE,EAAMC,EAAWC,GAC9C4T,EACFhU,EAAc,WAAYE,EAAMC,EAAWC,GAC/C,OAAQgU,MACJpU,EAAc,IAAKE,EAAMC,EAAWC,GAAwB2T,EAC5DC,IAEN,IAAK,MACGD,EAAO/T,EAAc,OAAQE,EAAMC,EAAWC,GAC9C4T,EACFhU,EAAc,WAAYE,EAAMC,EAAWC,GAC/C,OAAQiU,MACJrU,EAAc,IAAKE,EAAMC,EAAWC,GAAwB2T,EAC5DC,IAEN,IAAK,MACGD,EAAO/T,EAAc,OAAQE,EAAMC,EAAWC,GAC9C4T,EACFhU,EAAc,WAAYE,EAAMC,EAAWC,GAC/C,OAAQkU,MACJtU,EAAc,IAAKE,EAAMC,EAAWC,GAAwB2T,EAC5DC,IAEN,IAAK,SACGD,EAAO/T,EAAc,OAAQE,EAAMC,EAAWC,GACpD,OAAQmU,SACJvU,EAAc,IAAKE,EAAMC,EAAWC,GAAwB2T,IAElE,IAAK,SACGA,EAAO/T,EAAc,OAAQE,EAAMC,EAAWC,GACpD,OAAQoU,SACJxU,EAAc,IAAKE,EAAMC,EAAWC,GAAwB2T,IAElE,IAAK,OACGA,EAAO/T,EAAc,OAAQE,EAAMC,EAAWC,GAC9C4T,EACFhU,EAAc,WAAYE,EAAMC,EAAWC,GAC/C,OAAQ+L,OACJnM,EAAc,IAAKE,EAAMC,EAAWC,GAAwB2T,EAC5DC,IAEN,QACE,MAAMnK,UAAU,aAAa3J,EAAKsE,4BCxE7ByE,GAAgC,SAAC/I,EACAC,EACAC,GAE1C,OAAQF,EAAKsE,IACX,IAAK,WACL,IAAK,SACH,IAAMuP,EAAO/T,EAAc,OAAQE,EAAMC,EAAWC,GAC9CR,EACFI,EAAc,UAAWE,EAAMC,EAAWC,GAC9C,OAAQqU,SAAW7U,EAAQmU,IAE7B,IAAK,WACL,IAAK,SACGA,EAAO/T,EAAc,OAAQE,EAAMC,EAAWC,GAApD,IACM0F,EAAQ9F,EAAc,IAAKE,EAAMC,EAAWC,GAC5CgN,EACFpN,EAAc,UAAWE,EAAMC,EAAWC,GAC9C,OAAQsU,SAAW5O,EAAOsH,EAAQuH,OAAO,SAAUZ,IAErD,IAAK,YACL,IAAK,UACGA,EAAO/T,EAAc,OAAQE,EAAMC,EAAWC,GAC9C0F,EAAQ9F,EAAc,IAAKE,EAAMC,EAAWC,GAClD,OAAQwU,UAAY9O,EAAOiO,IAE7B,IAAK,QAEH,IAAMc,EAAQ7U,EAAc,QAASE,EAAMC,EAAWC,GAEhDsC,EAAO1C,EAAc,OAAQE,EAAMC,EAAWC,GACpD,OAAQ0U,QACJ9U,EAAc,IAAKE,EAAMC,EAAWC,GAAwByU,EAC5DnS,IAEN,IAAK,eACGmS,EACF7U,EAAc,QAASE,EAAMC,EAAWC,GAD5C,IAEMM,EAAMV,EAAc,MAAOE,EAAMC,EAAWC,GAC5C2U,EACF/U,EAAc,UAAWE,EAAMC,EAAWC,GACxC4U,EACFhV,EAAc,YAAaE,EAAMC,EAAWC,GAC1C6U,EACFjV,EAAc,UAAWE,EAAMC,EAAWC,GACxC8U,EACFlV,EAAc,eAAgBE,EAAMC,EAAWC,GAC7C+U,EACFnV,EAAc,cAAeE,EAAMC,EAAWC,GAC5CgV,EACFpV,EAAc,iBAAkBE,EAAMC,EAAWC,GAC/C4I,EAAShJ,EAAc,IAAKE,EAAMC,EAAWC,GACnD,GAAqB,IAAjByU,EAAMhS,QAAgBmG,EAAOP,MAAM5F,OAAS,EAC9C,IAAK,IAAID,EAAI,EAAGA,EAAIoG,EAAOP,MAAM5F,OAAQD,IACvCiS,EAAM/R,KAAK,GACXpC,EAAIoC,KAAKkG,EAAOP,MAAM7F,IACtBmS,EAAQjS,KAAKiS,EAAQ,IAGzB,OAAQM,eACJrM,EAAQ6L,EAAOnU,EAAKqU,EAASC,EAAWC,EAASC,EACjDC,EAAaC,IAEnB,IAAK,OACH,OAAOE,OAAS,WACd,IAAMvB,EAAO/T,EAAc,OAAQE,EAAMC,EAAWC,GAC9C2M,EACF/M,EAAc,UAAWE,EAAMC,EAAWC,GAExCqI,EAAQsE,EAAQ,GAAGtE,MACnB8M,EAAgBxI,EAAQ,GAAGyI,UAAU/M,MACrCgN,EAAS1I,EAAQ/L,IAAI,SAAAgI,GACzB,IAAM0M,EAAYC,OAASC,YAAY5M,EAAOP,MAAOA,GACrD,IAAKiN,IACAC,OAASC,YAAY5M,EAAOwM,UAAU/M,MAAO8M,GAChD,MAAM,IAAI1O,MAAM,0CAElB,OAAO6O,EAAY1M,EAASA,EAAOqF,QAAQ5F,KAE7C,OAAQoN,QAAUJ,EAAQ1B,MAG9B,IAAK,SACH,OAAOuB,OAAS,WACd,IAAMvB,EAAO/T,EAAc,OAAQE,EAAMC,EAAWC,GAC9C4I,EACFhJ,EAAc,SAAUE,EAAMC,EAAWC,GAC7C,OAAO0V,UAAY9M,EAAQ+K,KAG/B,IAAK,OACH,IAAMgC,EAAO/V,EAAc,OAAQE,EAAMC,EAAWC,GACpD,OAAQ4V,OACJhW,EAAc,IAAKE,EAAMC,EAAWC,GAAwB2V,IAElE,IAAK,QACL,IAAK,SACGhC,EAAO/T,EAAc,OAAQE,EAAMC,EAAWC,GAApD,IACM6V,EACFjW,EAAc,kBAAmBE,EAAMC,EAAWC,GAEtD,OAAO8V,QACHlW,EAAc,IAAKE,EAAMC,EAAWC,GACpC6V,EAAiBlC,GAEvB,IAAK,YACG3G,EACFpN,EAAc,UAAWE,EAAMC,EAAWC,GAD9C,IAEMqR,EACFzR,EAAc,SAAUE,EAAMC,EAAWC,GACvCqI,EACFzI,EAAc,QAASE,EAAMC,EAAWC,GAC5C,OAAQ+V,YAAc/I,EAASqE,EAAQhJ,IAEzC,IAAK,WACH,IAAM2I,EAAIpR,EAAc,IAAKE,EAAMC,EAAWC,GACxCgN,EACFpN,EAAc,UAAWE,EAAMC,EAAWC,GAC9C,OAAQgW,WAAahF,EAAGhE,IAE1B,IAAK,gBACGA,EACFpN,EAAc,gBAAiBE,EAAMC,EAAWC,GAE9CqI,EACFzI,EAAc,cAAeE,EAAMC,EAAWC,GAJlD,IAKMiW,EACFrW,EAAc,eAAgBE,EAAMC,EAAWC,GAC7C8C,EACFlD,EAAc,eAAgBE,EAAMC,EAAWC,GACnD,OAAQ0T,gBACJ1G,EAASiJ,EAAc5N,EACvB4N,EAAahK,QAAUnJ,EAAamJ,MAChCnJ,EACAA,EAAayR,OAAO0B,EAAahK,SAE3C,QACE,MAAMxC,UAAU,aAAa3J,EAAKsE,4BCzI7ByE,GACP,SAAC/I,EAAYC,EACZC,GACC,OAAQF,EAAKsE,IACX,IAAK,MACH,OAAQ8R,MACJtW,EAAc,IAAKE,EAAMC,EAAWC,KAE1C,IAAK,OACH,OAAQmW,OACJvW,EAAc,IAAKE,EAAMC,EAAWC,KAE1C,IAAK,OACH,OAAQoW,OACJxW,EAAc,IAAKE,EAAMC,EAAWC,KAE1C,IAAK,QACH,OAAQqW,QACJzW,EAAc,IAAKE,EAAMC,EAAWC,KAE1C,QACE,MAAMyJ,UAAU,aAAa3J,EAAKsE,4BCrBjCyE,GAAgC,SAAC/I,EACAC,EACAC,GAE1C,OAAQF,EAAKsE,IACX,IAAK,OACH,OAAQkS,OACJ1W,EAAc,IAAKE,EAAMC,EAAWC,GACpCJ,EAAc,QAASE,EAAMC,EAAWC,KAG9C,IAAK,aACH,IAAM2T,EAAO/T,EAAc,OAAQE,EAAMC,EAAWC,GACpD,OAAQuW,aACJ3W,EAAc,IAAKE,EAAMC,EAAWC,GAAwB2T,IAElE,IAAK,UACGA,EAAO/T,EAAc,OAAQE,EAAMC,EAAWC,GACpD,OAAQwW,UACJ5W,EAAc,IAAKE,EAAMC,EAAWC,GAAwB2T,IAGlE,IAAK,UACH,OAAQ8C,UACJ7W,EAAc,IAAKE,EAAMC,EAAWC,GACpCJ,EAAc,QAASE,EAAMC,EAAWC,KAE9C,IAAK,QACL,IAAK,MACH,OAAQ0W,MACJ9W,EAAc,IAAKE,EAAMC,EAAWC,GACpCoC,EACIxC,EAAc,UAAWE,EAAMC,EAAWC,GAC1C,GACJJ,EAAc,gBAAiBE,EAAMC,EAAWC,KAEtD,IAAK,iBACH,IAAM2W,EACF/W,EAAc,aAAcE,EAAMC,EAAWC,GAC3C4W,EAAWxU,EACbxC,EAAc,WAAYE,EAAMC,EAAWC,GAAsB,GACrE,OAAQ6W,iBACJjX,EAAc,IAAKE,EAAMC,EAAWC,GACpC2W,EAAYC,IAElB,IAAK,iBACGD,EACF/W,EAAc,aAAcE,EAAMC,EAAWC,GADjD,IAEM8W,EAAQ1U,EACVxC,EAAc,QAASE,EAAMC,EAAWC,GAAsB,GAClE,OAAQ+W,iBACJnX,EAAc,IAAKE,EAAMC,EAAWC,GACpC2W,EAAYG,IAElB,IAAK,eACH,IAAME,EACFpX,EAAc,YAAaE,EAAMC,EAAWC,GAC1C8O,EACDlP,EAAc,aAAcE,EAAMC,EAAWC,GACrC+O,cAEb,OAAQkI,eACJrX,EAAc,IAAKE,EAAMC,EAAWC,GACpCgX,EAAWlI,IAEjB,QACE,MAAMrF,UAAU,aAAa3J,EAAKsE,qCC5CxByE,GACZ/I,EAAYC,EACZC,GACF,IAAMoB,EACF,SAAEtB,EAAYC,EAA4BC,GACxC,OAAQF,EAAKP,UACX,IAAK,aACH,OAAO2X,EAAqBpX,EAAMC,EAAWC,GAC/C,IAAK,aACH,OAAOmX,EAAoBrX,EAAMC,EAAWC,GAC9C,IAAK,UACH,gBC9BRF,EAAYC,EACZC,4KACMF,EAAKsE,QACN,WAAA,gBAIA,SAAA,gBASA,QAAA,gBAMA,QAAA,gBAQA,OAAA,gBAMA,gBAAA,gBAMA,gBAAA,gBAoBA,qBAAA,gBAUA,oBAAA,iBAQA,sBAAA,iBAUA,uBAAA,iBAWA,sBAAA,iBAQA,qBAAA,iBAWA,oBAAA,iBAMA,qBAAA,iCA1HH,UACGxE,EAAc,OAAQE,EAAMC,EAAWC,GAAwBsR,iBAQ1D,OALF8F,EACFxX,EAAc,OAAQE,EAAMC,EAAWC,GACrCqX,EACFzX,EAAc,OAAQE,EAAMC,EAAWC,MAE7BoX,EAAKvW,eAAnB,SAAQyW,SAAmB,SAAMnX,EAAWkX,EAAK/F,UAChB+F,EAAK/F,aAASnR,WAK/C,UAFM2B,EAAYhC,EAAKY,WAAWiB,KAC9B,SAAAxC,GAAQ,YAAwCgB,IAAxCM,EAAUtB,EAAMY,EAAWC,OACnBS,EAAUqB,EAAW/B,EAAWC,GAASsR,cAC1CnR,UAQnB,OALMoX,EACF3X,EAAc,YAAaE,EAAMC,EAAWC,GAC1Ca,EACFjB,EAAc,SAAUE,EAAMC,EAAWC,GAC7CA,EAAQwX,WAAWD,OACX1W,EAAKyQ,iBAMb,OAHM1I,EACFhJ,EAAc,SAAUE,EAAMC,EAAWC,GAC7CA,EAAQyX,gBACA7O,EAAO0I,iBAMf,OAHM5L,EACF9F,EAAc,SAAUE,EAAMC,EAAWC,GAC7CA,EAAQ0X,oBACAhS,EAAM4L,iBAoBd,OAjBMhP,EAAO1C,EAAc,OAAQE,EAAMC,EAAWC,GAC9CiM,EACFrM,EAAc,QAASE,EAAMC,EAAWC,GACtCmM,EACFvM,EAAc,eAAgBE,EAAMC,EAAWC,GAC7CqM,EACFzM,EAAc,cAAeE,EAAMC,EAAWC,GAC5CsM,EACF1M,EAAc,iBAAkBE,EAAMC,EAAWC,GAC/CoM,EACFxM,EAAc,yBAA0BE,EAAMC,EAAWC,GAEvD2X,EAAO/X,EAAc,OAAQE,EAAMC,EAAWC,GAC9C4X,EAAc,IAAIpL,EACpBmL,EAAM1L,EAAO3J,EAAM6J,EAAcC,EAAwBC,EACzDC,GACJtM,EAAQ6X,eAAeD,OACfE,SAAOF,EAAYrL,IAAKuL,SAAO,YAUvC,OAPMvL,EACF3M,EAAc,gBAAiBE,EAAMC,EAAWC,GAC9CwB,EAAQ5B,EAAc,QAASE,EAAMC,EAAWC,GAChD+X,EACFnY,EAAc,SAAUE,EAAMC,EAAWC,GACpBA,EAAQgY,eAAezL,GAC/Ba,MAAM5L,EAAOuW,OACtBD,SAAO,aAQf,OALMG,EACFrY,EAAc,gBAAiBE,EAAMC,EAAWC,GAC9CkY,EACFtY,EAAc,QAASE,EAAMC,EAAWC,OACpBA,EAAQgY,eAAeC,GACvBlL,KAAKmL,aAU7B,OAPMC,EACFvY,EAAc,gBAAiBE,EAAMC,EAAWC,GAC9CoY,EACFxY,EAAc,UAAWE,EAAMC,EAAWC,GACxCqY,EACFzY,EAAc,QAASE,EAAMC,EAAWC,OAClBA,EAAQgY,eAAeG,GACvBG,OAAOF,EAAeC,aAWhD,OARME,EACF3Y,EAAc,gBAAiBE,EAAMC,EAAWC,GAC9CwY,EACF5Y,EAAc,UAAWE,EAAMC,EAAWC,GACxCyY,EACF7Y,EAAc,SAAUE,EAAMC,EAAWC,GAClBA,EAAQgY,eAAeO,GAC/BG,QAAQF,EAAgBC,OACnCX,SAAO,aAQf,OALMa,EACF/Y,EAAc,gBAAiBE,EAAMC,EAAWC,GAC9C4Y,EAAoB5Y,EAAQgY,eAAeW,GAC3CE,EACFjZ,EAAc,QAASE,EAAMC,EAAWC,OACpC4Y,EAAkB1U,OAAO2U,aAWjC,OARMC,EACFlZ,EAAc,gBAAiBE,EAAMC,EAAWC,GAC9C+Y,EACFnZ,EAAc,SAAUE,EAAMC,EAAWC,GACvCgZ,EACFpZ,EAAc,UAAWE,EAAMC,EAAWC,GACrBA,EAAQgY,eAAec,GAC/B1W,MAAM4W,EAASD,OACxBjB,SAAO,aAMf,OAHMmB,EACFrZ,EAAc,gBAAiBE,EAAMC,EAAWC,GAC9CkZ,EAAkBlZ,EAAQgY,eAAeiB,OACvCnB,SAAOoB,EAAgB5W,OAAQ,mBAOvC,OAJM6W,EACFvZ,EAAc,gBAAiBE,EAAMC,EAAWC,GAC3BA,EAAQgY,eAAemB,GAC/BC,+BAGjB,MAAM3P,UAAU,aAAa3J,EAAKsE,+BDvGrBiV,CAAkBvZ,EAAMC,EAAWC,GAC5C,IAAK,cACH,OAAOsZ,EAAsBxZ,EAAMC,EAAWC,GAChD,IAAK,WACH,OAAOuZ,EAAmBzZ,EAAMC,EAAWC,GAC7C,IAAK,UACH,gBEvCRF,EAAYC,EACZC,gHACMF,EAAKsE,QACN,0BACA,sBAAA,gBAeA,QAAA,gBAIA,WAAA,+BARK,OAVFgO,EACFxS,EAAc,QAASE,EAAMC,EAAWC,GACtCwZ,EACF5Z,EAAc,SAAUE,EAAMC,EAAWC,GACvCyZ,EACF7Z,EAAc,gBAAiBE,EAAMC,EAAWC,GAC9C0Z,EACF9Z,EAAc,eAAgBE,EAAMC,EAAWC,GAC7C2Z,EACF/Z,EAAc,iBAAkBE,EAAMC,EAAWC,MACvCiS,QAAU2H,uBACpBxH,EAAuBoH,EAAwBC,EAC/CC,EAAcC,WAFlB,UAAQrC,kBAKA,SAAMuC,aACVja,EAAc,YAAaE,EAAMC,EAAWC,YADhD,UAAQsX,kBAID,SAAMwC,iBACTla,EAAc,IAAKE,EAAMC,EAAWC,GACpCJ,EAAc,IAAKE,EAAMC,EAAWC,YAFxC,SAAOsX,iBAKP,MAAM7N,UAAU,aAAa3J,EAAKsE,+BFUrB2V,CAAkBja,EAAMC,EAAWC,GAC5C,IAAK,aACH,OAAOga,EAAqBla,EAAMC,EAAWC,GAC/C,IAAK,QACH,OAAOia,GAAgBna,EAAMC,EAAWC,GAC1C,IAAK,QACH,OAAOka,EAAgBpa,EAAMC,EAAWC,GAC1C,IAAK,UACH,OAAOma,GAAkBra,EAAMC,EAAWC,GAC5C,IAAK,WACH,OAAOoa,GAAmBta,EAAMC,EAAWC,GAC7C,IAAK,gBACH,OAAOqa,GAAwBva,EAAMC,EAAWC,GAClD,IAAK,YACH,OAAOsa,GAAoBxa,EAAMC,EAAWC,GAC9C,IAAK,aACH,OAAOua,GAAoBza,EAAMC,EAAWC,GAC9C,IAAK,WACH,OAAOwa,GAAmB1a,EAAMC,EAAWC,GAC7C,IAAK,iBACH,OAAOya,GAAyB3a,EAAMC,EAAWC,GACnD,IAAK,SACH,IAAMX,EAAWM,EAAgBG,EAAKsE,IACtC,GAAI/E,GAAYA,EAASK,eACvB,OAAOL,EAASK,eACZ,IAAIiJ,EAAc7I,EAAMC,EAAWC,IAEvC,MAAMyJ,UAAU,aAAa3J,EAAKsE,0BAEtC,QACE,MAAMqF,UACF,eAAe3J,EAAKsE,2IA5C9B,CAgDGtE,EAAMC,EAAWC,GACxB,OAAIoB,aAAiBsZ,QACZtZ,EAAMuZ,KAAK,SAAC9Z,GAAS,SAAGqD,OAAOrD,QAE9BqD,OAAO9C,GGjEnB,kBAME,WACoBwZ,EACAC,GADAvW,eAAAsW,EACAtW,oBAAAuW,EAPZvW,kBAAeiI,GAAI,EAAGuO,UAAW,GAAIC,YAAa,GAClDzW,eAAoCA,KAAK0W,aACzC1W,YAAS,EAMfA,KAAK2W,4BAsHT,OAnHUC,qBAAR,SAAiB3O,EAAYuO,GAC3B,OAAQvO,KAAIuO,YAAWC,YAAa,IAQtCrW,sBAAIwW,kCAOJ,WACE,OAAO5W,KAAK6W,cARd,SAAmBA,GACb7W,KAAK6W,WAAaA,IACpB7W,KAAK6W,SAAWA,EAChB7W,KAAK2W,8DAWTvW,sBAAIwW,oCAAJ,WACE,OAAO5W,KAAK8W,mBAAmB,oCAOjC1W,sBAAIwW,qCAAJ,WACE,OAAO5W,KAAK8W,oDAGNF,sCAAR,WAEE,IADA,IAAMG,KACG7Y,EAAI,EAAGA,EAAI8B,KAAK6W,SAAS1Y,OAAS,EAAGD,IAAK,CACjD,IAAM2Y,EAAW7W,KAAK6W,SAASxa,MAAM,EAAG2D,KAAK6W,SAAS1Y,OAASD,GAC/D6Y,EAAM3Y,KAAK4B,KAAKgX,qBAAqBH,IAEvCE,EAAM3Y,KAAK,IACX4B,KAAK8W,mBAAqBC,GAGpBH,iCAAR,SAA6BC,GAC3B,OAAOA,EACHA,EACKva,IACG,SAAAZ,GAAW,OAAgB,IAAfA,EAAQuM,IAAoC,IAAxBvM,EAAQ+a,YACpC,GACG/a,EAAQ8a,cAAa9a,EAAQ+a,cACvCQ,KAAK,KACV,IAONL,uBAAA,SAAW3D,GACLjT,KAAK6W,WACP7W,KAAKkX,SACLlX,KAAK6W,SAAW7W,KAAK6W,SAASxa,QAC9B2D,KAAK6W,SAASzY,KAAK4B,KAAKmX,SAASnX,KAAKkX,OAAQjE,IAC9CjT,KAAK8W,mBAAmBM,QAAQpX,KAAKgX,qBAAqBhX,KAAK6W,aAQnED,sBAAA,WACE,KAAI5W,KAAK6W,UAAY7W,KAAK6W,SAAS1Y,OAAS,GAK1C,MAAM,IAAIgE,MAAM,2CAJhBnC,KAAK6W,SAAW7W,KAAK6W,SAASxa,QAC9B2D,KAAK6W,SAASQ,QAAQ,GACtBrX,KAAK5C,kBAAkBka,SAU3BV,0BAAA,WACE,KAAI5W,KAAK6W,UAAY7W,KAAK6W,SAAS1Y,OAAS,GAY1C,MAAM,IAAIgE,MAAM,yDAXhBnC,KAAK6W,SAAW7W,KAAK6W,SAASxa,QAC9B2D,KAAKkX,SACL,IAAMxb,EACF0E,OAAOmX,UAAWvX,KAAK6W,SAAS7W,KAAK6W,SAAS1Y,OAAS,IAE3DzC,EAAQ+a,aAAe,EACvB/a,EAAQuM,GAAKjI,KAAKkX,OAClBlX,KAAK6W,SAASQ,QAAQ,EAAG,EAAG3b,GAC5BsE,KAAK8W,mBAAmBO,OACpB,EAAG,EAAGrX,KAAKgX,qBAAqBhX,KAAK6W,YAM7CD,sBAAA,SAAU/b,GACR,OAAOmF,KAAKsW,UAAUzb,IAGxB+b,2BAAA,SAAetD,GACbtT,KAAKuW,eAAejD,EAAYrL,IAAMqL,GAGxCsD,2BAAA,SAAe3O,GACb,OAAOjI,KAAKuW,eAAetO,kBC5HfuP,GACZtc,EAAwB0F,EACxB0V,GAUF,IATA,IAAMmB,EAAY,IAAIC,IAChBC,KACFC,EAAoB,KACpBC,EAAuB,KAIrBC,EAAO,IAAIJ,IACXK,EAAenX,UACdmX,EAAS5Z,OAAS,GAAG,CAC1B,IAAM3C,EAAOuc,EAASC,OAClBC,GAAczc,IAAS0c,GAAe1c,KACrB,MAAfoc,IAEFC,GADAD,EAAcpc,GACWyF,SAAS3E,IAAI,SAAA6b,GAAS,OAAAA,EAAMtd,OACnCud,OAAO,SAAAvd,GAAQ,OAAA4c,EAAUY,IAAIxd,MAGnD4c,EAAUa,IAAI9c,EAAKX,MAGS,MAAxByb,EAAU9a,EAAKX,QAIM,MAArBK,EAAOM,EAAKX,QAGW,IAAvBW,EAAKN,OAAOiD,OAIhB3C,EAAKN,OAAO6F,QAAQ,SAAAK,GAEd0W,EAAKO,IAAIjX,EAAMvG,QAGnBid,EAAKQ,IAAIlX,EAAMvG,MACfkd,EAAS3Z,KAAKgD,MATduW,EAAcvZ,KAAK5C,EAAKX,QAY5B,OAAQK,SAAQ0F,UAAS6W,YAAWE,gBAAeC,cAAaC,cAyClE,IAAMU,IAAoB,SAAU,QAAS,QAAS,OAAQ,iBACxDC,IACD,sBAAuB,sBAAuB,kBAEnCP,GAAczc,GAC5B,OAAO+c,GAAiBE,QAAQjd,EAAKsE,KAAO,WAG9BoY,GAAe1c,GAC7B,OAAOgd,GAAkBC,QAAQjd,EAAKsE,KAAO,ECpG/C,kBAqDE,WAAoBV,GAAAY,WAAAZ,EApDZY,iBAAmC,IAAI0Y,IACvC1Y,mBAIAA,eAAY,IAgDlBA,KAAKO,aAAenB,EAAMmB,aAC1BP,KAAK2Y,SAAWvZ,EAAMwB,QAqX1B,OAraER,sBAAIwY,6BAAJ,WACE,OAAO5Y,KAAK6Y,gBAEd,SAAcvC,GACZ,IAAMwC,EAAY1Y,OAAOU,KAAKwV,GAAWha,IACrC,SAAA0E,GAAO,OAAAsV,EAAUtV,GAAK1E,IAAI,SAAAgI,GAAU,OAAAA,EAAO2D,OAC/CjI,KAAK8Y,aAAelZ,OAAOC,SAAUiZ,GACrC9Y,KAAK6Y,WAAavC,mCAGpBlW,sBAAIwY,0BAAJ,WACE,OAAO5Y,KAAKO,aAAajE,IAAI,SAAAd,GAC3B,OACEX,KAAMW,EAAKX,KACXkJ,MAAOvI,EAAKqB,WAAkB,MAC1BrB,EAAKqB,WAAkB,MAAEC,WACzBjB,EACJ8L,MAAOnM,EAAKqB,WAAkB,MAC1BrB,EAAKqB,WAAkB,MAAEC,WACzBjB,sCAKVuE,sBAAIwY,2BAAJ,WACE,OAAO5Y,KAAK2Y,SAASrc,IAAI,SAAAd,GACvB,OACEX,KAAMW,EAAKX,KACXkJ,MAAOvI,EAAKqB,WAAkB,MAC1BrB,EAAKqB,WAAkB,MAAEC,WACzBjB,EACJ8L,MAAOnM,EAAKqB,WAAkB,MAC1BrB,EAAKqB,WAAkB,MAAEC,WACzBjB,sCAKVuE,sBAAIwY,8BAAJ,WACE,OAAO5Y,KAAKO,aAAajE,IAAI,SAAAd,GAAQ,OAAAA,EAAKX,wCAG5CuF,sBAAIwY,+BAAJ,WACE,OAAO5Y,KAAKY,QAAQtE,IAAI,SAAAd,GAAQ,OAAAA,EAAKX,wCAQ/B+d,8BAAR,SAA0B1d,EAAgB0F,GACxC,IAAMmY,EAAe7d,EAAOoB,IAAI,SAAAd,GAAQ,OAAAA,EAAKX,OAAMme,OAC7CC,EAAgBrY,EAAQtE,IAAI,SAAAd,GAAQ,OAAAA,EAAKX,OAAMme,OACrD,OAAOD,EAAa9B,KAAKjX,KAAKkZ,WAAa,KACvCD,EAAchC,KAAKjX,KAAKkZ,YAOtBN,oBAAR,SAAgB1d,EAAwB0F,GACtC,IAAMuY,EAAgB3B,GAAqBtc,EAAQ0F,EAASZ,KAAKsW,WAC1DqB,kBAAeC,gBAAaC,eACnC,GAAmB,MAAfD,EACF,MAAM,IAAIzV,MACN,qCAAqCyV,EAAY/c,qCAC9B+c,EAAY9X,+GAEK+X,OAG1C,GAAIF,EAAcxZ,OAAS,EAAG,CAC5B,IAAMib,EAAWxY,EAAQtE,IAAI,SAAA+c,GAAK,OAAAA,EAAExe,OAC9Bye,EAAUlZ,OAAOU,KAAK5F,GAC5B,MAAM,IAAIiH,MACN,+BAA+BiX,iCAC3BE,uCAA4C3B,OAGtD,gBD9BAvY,EAAckX,EACd6C,GACK,IAAA1B,cAAWvc,WACZ6c,KACa3X,OAAOU,KAAK5F,GAAQoB,IAAI,SAAAzB,GAAQ,OAAAuE,EAAMqB,MAAM5F,KACpDkG,QAAQ,SAAAK,GACbqW,EAAUY,IAAIjX,EAAMvG,OACtBkd,EAAS3Z,KAAKgD,KAGlBhC,EAAMoB,QAAQO,QAAQ,SAAAwY,GAChB9B,EAAUY,IAAIkB,EAAO1e,OACvBkd,EAAS3Z,KAAKmb,KAKlB,IAFA,IAAMzB,EAAO,IAAIJ,IACX8B,KACCzB,EAAS5Z,OAAS,GAAG,CAC1B,IAAM3C,EAAOuc,EAASC,MACtBF,EAAKQ,IAAI9c,EAAKX,MACTyb,EAAU9a,EAAKX,OAClB2e,EAAapb,KAAK5C,GAEpBA,EAAKyF,SAASF,QAAQ,SAAAoX,IACfL,EAAKO,IAAIF,EAAMtd,OAAS4c,EAAUY,IAAIF,EAAMtd,OAC7Csd,EAAMjd,OAAOue,MAAM,SAAArY,GAAS,OAAA0W,EAAKO,IAAIjX,EAAMvG,SAC7Ckd,EAAS3Z,KAAK+Z,KAIpB,OAAOqB,ECAEE,CACH1Z,KAAKZ,MAAOY,KAAKsW,UAAW6C,IAGlCP,sBAAA,qBC7E2BxZ,EAAckX,kBAC9BtV,GACT,IAAM2Y,EAAUva,EAAMqB,MAAMO,GAC5B,GAAe,MAAX2Y,GAAkC,QAAfA,EAAQ7Z,IAA+B,UAAf6Z,EAAQ7Z,IACrB,IAA9B6Z,EAAQvd,WAAW+B,wBAIvB,IAAMyb,EAAWD,EAAQze,OAAOmC,KAAK,SAAA+D,GAAS,MAAa,SAAbA,EAAMtB,KACpD,GAAgB,MAAZ8Z,GAAmD,IAA/BA,EAASxd,WAAW+B,wBAI5C,IAAM0b,EAAQF,EAAQze,OAAOmC,KAAK,SAAA+D,GAAS,MAAa,QAAbA,EAAMtB,KACjD,GAAa,MAAT+Z,GAA6C,IAA5BA,EAAMzd,WAAW+B,wBAItC,IAAM2b,EAAqBD,EAAM3e,OAAOmC,KAAK,SAAA+D,GAAS,MAAa,UAAbA,EAAMtB,KAEtDia,EAAmBF,EAAM3e,OAAOmC,KAAK,SAAA+D,GAAS,MAAa,SAAbA,EAAMtB,KAE1D,GAA0B,MAAtBga,GAAkD,MAApBC,GACS,IAAvCA,EAAiB3d,WAAW+B,wBAKhC,IAAM6b,EAAeD,EAAiB7e,OAAO,GAC7C,GAAoB,MAAhB8e,GAA4C,QAApBA,EAAala,IACF,IAAnCka,EAAa5d,WAAW+B,wBAI5B,GAAIyb,EAASxd,WAAW,KAAO4d,EAAa5d,WAAW,oBAIvD,IAAM6d,EAAYL,EAAS1e,OAAO,GAC5Bgf,EAAcP,EAAQ1Y,SAGtBkZ,EAAkBL,EAAmBjf,KAAO,OAE5Cuf,GACJvf,KAAMsf,EACN/d,cACAlB,UACA2B,cACA5B,SAAU,QACVgG,YACAnB,GAAI,QACJlE,eACA2F,aAIF+U,EAAU6D,IAAoBE,MAAI/D,EAAUwD,EAAmBjf,MAAM,KACrEuE,EAAMoB,QAAQpC,KAAKgc,GAGnB,IAAME,GACJzf,KAAM8e,EAAQ9e,KAAO,SACrBuB,YAAa6d,EAAUpf,KAAMuf,EAAQvf,MACrCK,QAAS+e,EAAWG,GACpBvd,cACA5B,SAAU,SACVgG,SAAUiZ,EACVpa,GAAI,QACJlE,aACE8Q,GAAM5Q,gBAAiB,EAAGI,KAAM,UAChCqe,OAAUze,gBAAiB,EAAGI,KAAM,YAIxCke,EAAQnZ,SAAS7C,KAAKkc,GAGtB,IAAME,EAAWV,EAAmB7Y,SAASwX,QAAQoB,GACjDW,GAAY,GACdV,EAAmB7Y,SAASoW,OAAOmD,EAAU,GAG/C,IAAMC,EAAYR,EAAUhZ,SAASwX,QAAQmB,GACzCa,GAAa,GACfR,EAAUhZ,SAASoW,OAAOoD,EAAW,GAGvC,IAAMC,EAAWT,EAAUhZ,SAASwX,QAAQuB,GAe5C,GAdIU,GAAY,GACdT,EAAUhZ,SAASoW,OAAOqD,EAAU,GAEtCT,EAAUhZ,SAAS7C,KAAKkc,GAExBJ,EAAYnZ,QAAQ,SAAAvF,GAClB,IAAMmf,EAAWnf,EAAKY,WAAWqc,QAAQkB,EAAQ9e,MAC7C8f,GAAY,IACdnf,EAAKY,WAAWue,GAAYL,EAAUzf,KACtCW,EAAKN,OAAOyf,GAAYL,KAKD,IAAvBJ,EAAY/b,OAAc,CAC5B,IAAMwc,EAAWvb,EAAMwB,QAAQ6X,QAAQkB,GACnCgB,GAAY,GACdvb,EAAMwB,QAAQyW,OAAOsD,EAAU,GAEjCvb,EAAMwB,QAAQxC,KAAKkc,UAGdlb,EAAMqB,MAAMkZ,EAAQ9e,aACpBuE,EAAMqB,MAAMoZ,EAAMhf,aAClBuE,EAAMqB,MAAMmZ,EAAS/e,aACrBuE,EAAMqB,MAAMsZ,EAAiBlf,aAC7BuE,EAAMqB,MAAMuZ,EAAanf,MAGhCuE,EAAMqB,MAAM6Z,EAAUzf,MAAQyf,EAC9Blb,EAAMqB,MAAM2Z,EAAQvf,MAAQuf,GAtH9B,IAAK,IAAMpZ,KAAO5B,EAAMqB,QAAbO,GD6ET4Z,CAAa5a,KAAKZ,MAAOY,KAAKsW,YAWhCsC,oBAAA,SAAQ1d,EAAwB0F,GAAhC,WACQmW,EAAQ3W,OAAOU,KAAK5F,GAAQ8d,OAClChZ,KAAK6a,YAAY3f,GACjB8E,KAAK8a,uBAAuB5f,GAC5B8E,KAAK+a,aAAana,GAClB,IAAMoa,EAAajE,EAAMza,IAAI,SAAAzB,GAAQ,OAAA6F,EAAKtB,MAAMqB,MAAM5F,KAChDqf,EACFtZ,EAAQtE,IAAI,SAAAzB,GAAQ,OAAA6F,EAAKtB,MAAMqB,MAAM/C,EAAc7C,GAAM,MACvDogB,EAAiBjb,KAAKkb,kBAAkBF,EAAYd,GAEtDV,EAAexZ,KAAKmb,YAAYC,IAAIH,GACpB,MAAhBzB,IACFA,EAAexZ,KAAKqb,QAAQngB,EAAQgf,GACpCla,KAAKmb,YAAYG,IAAIL,EAAgBzB,IAEvC,IAAMjD,KACN,OAAO7M,OAAK,WACV,IAAMhO,EAAU,IAAIkb,GAAiBlW,EAAKmY,WAAYtC,GAChDxZ,OAAkC2D,EAAK4V,WAC7ClW,OAAOU,KAAK5F,GAAQ6F,QAAQ,SAAAlG,GAC1BkC,EAAWlC,IAASK,EAAOL,MAI7B,IAFA,IAAM0gB,EAAgB7a,EAAK8a,mBAAmBze,GACxC0e,KACGvd,EAAI,EAAGA,EAAIsb,EAAarb,OAAQD,IAAK,CAC5C,IAAM1C,EAAOge,EAAatb,GAC1B,IAAKnB,EAAWvB,EAAKX,MAAO,CAC1B,IAAMwN,EAAU9D,GAAU/I,EAAMuB,EAAYrB,GAC5C,GAAI2M,aAAmB+N,QACrB,MAAM,IAAIjU,MACN,4BAA4B3G,EAAKsE,qEAGvC/C,EAAWvB,EAAKX,MAAQwN,EACxB3H,EAAKgb,uBACDlgB,EAAKX,KAAMW,EAAMuB,EAAYrB,EAAS6f,EAAe3a,EACrD6a,IAGR,OAAO7a,EAAQtE,IAAI,SAAAzB,GAAQ,OAAAsB,EAAUtB,EAAMkC,EAAYrB,QAInDkd,+BAAR,SAA2Bnd,GACzB,IAAMkgB,KAAS/b,OAAOC,SAElBO,OAAOU,KAAKrF,GACPa,IAAI,SAAA0E,GAAO,OAAAvF,EAAUuF,KACrB1E,IAAI,SAAA+L,GAAW,OAAAA,EAAQ/L,IAAI,SAAAgI,GAAU,OAAAA,EAAO2D,QACrD,OAAO,IAAIyP,IAAIiE,IAET/C,mCAAR,SACI3b,EAAkBzB,EAAYC,EAC9BC,EAA2B6f,EAC3BK,EACAH,GAGoB,YAAlBjgB,EAAKP,WAA6D,IAAnC2gB,EAAYnD,QAAQxb,KAIvDxB,EAAUwB,GAAU8D,QAAQ,SAAAuD,GACZ,MAAVA,IACFmX,EAAgCnX,EAAO2D,KAClCwT,EAAgCnX,EAAO2D,KAAO,GAC/CzM,EAAKyF,SAAS9C,UAGtB3C,EAAKN,OAAO6F,QAAQ,SAAAK,GAGlB,GAAuB,YAAnBA,EAAMnG,SAAwB,CAChC,IAAMoN,WvCtIVxN,EAAckC,EACdrB,GACF,OAAOqB,EAAWO,EAAyBzC,EAAMa,EAAQ+B,mBuCqI/Coe,CAA6Bza,EAAMvG,KAAMY,EAAWC,GACzC,MAAX2M,GACFA,EAAQtH,QAAQ,SAAAuD,GACd,GAAIA,IAAWiX,EAAclD,IAAI/T,EAAO2D,IAAK,CAC3C,IAAM6T,EAAQL,EAAgCnX,EAAO2D,IACvC,IAAV6T,GACFxX,EAAOgE,iBACAmT,EAAgCnX,EAAO2D,KAC5B,MAAT6T,GAGTL,EAAgCnX,EAAO2D,cAiB/C2Q,yBAAN,SAAmB1d,EAAwB0F,kHAWrC,OATJZ,KAAK6a,YAAY3f,GACjB8E,KAAK8a,uBAAuB5f,GAC5B8E,KAAK+a,aAAana,GACZ2V,KACA7a,EAAU,IAAIkb,GAAiB5W,KAAK6Y,WAAYtC,MAK5CvW,KAAK+b,uBAAuB7gB,EAAQQ,EAASkF,WAiBvD,OAlBMnF,EACFuB,SACEgf,EAAUpb,EAAQtE,IAAI,SAAAzB,GAAQ,OAAAsB,EAAUtB,EAAMY,EAAWC,KAGzDugB,EAAY,IAAIvE,IAAYsE,EAAQ1f,IAAI,SAAAqM,GAAK,OAAAA,EAAEV,MAC/CiU,EACF,IAAIxE,IAAYtX,OAAOU,KAAK5F,GAAQoB,IAAI,SAAAzB,GAAQ,OAAAK,EAAOL,GAAMoN,MACjE7H,OAAOU,KAAKrF,GAAWsF,QAAQ,SAAAC,GACTvF,EAAUuF,GAClBD,QAAQ,SAAAuD,IACdA,GAAWA,EAAO6X,YAAeF,EAAU5D,IAAI/T,EAAO2D,KACrDiU,EAAS7D,IAAI/T,EAAO2D,MACkB,IAAvCvH,EAAKoY,UAAUL,QAAQnU,EAAO2D,KAChC3D,EAAOgE,iBAIN0T,SASKpD,mCAAd,SACI1d,EAAwBQ,EACxBkgB,sIACI7E,EAAQ3W,OAAOU,KAAK5F,GACpB8f,EAAajE,EAAMza,IAAI,SAAAzB,GAAQ,OAAA6F,EAAKtB,MAAMqB,MAAM5F,KAChDqf,EACF0B,EAAYtf,IAAI,SAAAzB,GAAQ,OAAA6F,EAAKtB,MAAMqB,MAAM/C,EAAc7C,GAAM,MAC3DmC,EACFwa,GAAqBtc,EAAQgf,EAAala,KAAKsW,WAD5CmB,cAAWE,kBAAeC,gBAAaC,eAGxC7O,EACEgS,SAAehb,KAAKZ,MAAMoB,SAASlE,IAAI,SAAAd,GACzC,OAAQA,OAAMqb,SAAUnb,EAAQ0gB,kBAEhCrf,OAAkCiD,KAAKsW,WAC7ClW,OAAOU,KAAK5F,GAAQ6F,QAAQ,SAAAlG,GAC1BkC,EAAWlC,IAASK,EAAOL,MAEvB4gB,KACAF,EAAgBvb,KAAKwb,mBAAmBze,GACxCsf,6BACCrT,EAAM7K,OAAS,GACdme,EAAWtc,KAAKuc,aAClBvB,EAAYhS,EAAOtN,EAASqB,EAAYsf,EAAOd,EAC/CK,EAAaH,EAAiChE,MAC5CrB,QAAQoG,IAAIF,yBAAlBtJ,sBAaF,GAXmB,MAAf4E,GACFtK,QAAQC,KACJ,oIAGAkP,EACFvC,EACK9B,OACG,SAAA5c,GAAQ,OAACyc,GAAczc,KAClBW,EAAUX,EAAKX,KAAMkC,EAAYrB,KACzCY,IAAI,SAAAd,GAAQ,OAAAA,EAAKX,QACPsD,OAAS,EAO1B,MANIue,EAAiB,GACF,MAAf9E,IACF8E,EACI,wFAC2B7E,OAE3B,IAAI1V,MACN,+BAA+Bsa,iCACpB1F,kDACPY,QAAmB+E,GAE7B,SAAO3f,SAGD6b,yBAAR,SACIoC,EAAoBhS,EAA2BtN,EAC/CD,EAA4B4gB,EAC5Bd,EAA4BK,EAC5BH,EACAhE,GAEF,IAPF,WAMQ6E,kBAEJ,IAAMK,EAAO3T,EAAMgP,MACnBtc,EAAQ0gB,eAAiBO,EAAK9F,SAC9B,IAAI5Z,EAAW,GAUf,GANqB,UAAjB0f,EAAKnhB,KAAKsE,IACVxE,EAAc,aAAcqhB,EAAKnhB,KAAMC,EAAWC,KACnDuB,wBAIoC,IAAnC+d,EAAWvC,QAAQkE,EAAKnhB,MAAc,CACxC,IAAM6M,EAAU9D,GAAUoY,EAAKnhB,KAAMC,EAAWC,GAC3CuB,IACFA,uBAEH,IAAM2f,EAAiBlhB,EAAQ0gB,eAC3B/T,aAAmB+N,QACrBkG,EAASle,KAAKiK,EAAQgO,KAAK,SAAA1N,GAQzB,OAPAlN,EAAUwB,GAAY0L,EACtBjN,EAAQ0gB,eAAiBQ,EACzBlc,EAAKgb,uBACDze,EAAU0f,EAAKnhB,KAAMC,EAAWC,EAAS6f,EACzCK,EAAaH,GACjB/a,EAAKmc,kBACDF,EAAKnhB,KAAMwN,EAAOtN,EAASD,EAAW4gB,EAAO5E,GAC1C9O,MAGTlN,EAAUwB,GAAYoL,EACtByU,EAAKpB,uBACDze,EAAU0f,EAAKnhB,KAAMC,EAAWC,EAAS6f,EACzCK,EAAaH,GACjBqB,EAAKD,kBACDF,EAAKnhB,KAAMwN,EAAOtN,EAASD,EAAW4gB,EAAO5E,SAGnDqF,EAAKD,kBACDF,EAAKnhB,KAAMwN,EAAOtN,EAASD,EAAW4gB,EAAO5E,WAxC9CzO,EAAM7K,OAAS,OA2CtB,OAAOme,GAGD1D,8BAAR,SACIpd,EAAYwN,EAA2BtN,EACvCD,EAA4B4gB,EAC5B5E,GACFjc,EAAKyF,SAASF,QAAQ,SAACgc,GACd,IAAA9f,kBACHof,EAAMpf,IAAcwa,EAAUY,IAAI0E,EAAUliB,QAI3B,UAAjBkiB,EAAUjd,GACRid,EAAU3gB,WAAW4gB,KAAK,SAAAniB,GACxB,QAASsB,EAAUtB,EAAMY,EAAWC,OAExC2gB,EAAMpf,IAAY,EAClB+L,EAAM5K,MAAMyY,SAAUnb,EAAQ0gB,eAAgB5gB,KAAMuhB,KAGhDA,EAAU3gB,WAAWqd,MAAM,SAAA5e,GACzB,QAASsB,EAAUtB,EAAMY,EAAWC,OAE5C2gB,EAAMpf,IAAY,EAClB+L,EAAM5K,MAAMyY,SAAUnb,EAAQ0gB,eAAgB5gB,KAAMuhB,SAQ1DnE,oBAAA,WAAA,WACExY,OAAOU,KAAKd,KAAKsW,WACZvV,QACG,SAAAC,GAAO,OAAAN,EAAK4V,UAAUtV,GAAKD,QAAQ,SAAAuD,GAAU,OAAAA,EAAOgE,eAGtDsQ,mCAAR,SAA+B1d,GAA/B,WACEkF,OAAOU,KAAK5F,GAAQ6F,QAAQ,SAAAlG,GAC1B,IAAMuG,EAAQlG,EAAOL,GACfW,EAAOkF,EAAKtB,MAAMqB,MAAM5F,GAC9B,GAAIW,EAAKqB,WAAkB,OAAKrB,EAAKqB,WAAkB,MAAEC,MAAO,CAC9D,IAAMmgB,EAAQzhB,EAAKqB,WAAkB,MAAEC,MACjCogB,EAAQD,EAAM9e,SAAWiD,EAAM2C,MAAM5F,QACvCiD,EAAM2C,MAAM0V,MACR,SAACxV,EAAK/G,GAAU,OAAkB,IAAlB+f,EAAM/f,IAAiB+f,EAAM/f,KAAW+G,IAChEgG,OAAKC,OACDgT,EACA,WAAM,MAAA,sBAAsB1hB,EAAKX,oDACGoiB,iBAC5B7b,EAAM2C,YAEhBvI,EAAKqB,WAAkB,OAAKrB,EAAKqB,WAAkB,MAAEC,OACvDmN,OAAKC,OACD9I,EAAMuG,QAAUnM,EAAKqB,WAAkB,MAAEC,MACzC,WAAM,MAAA,sBAAsBtB,EAAKX,mDAE1BW,EAAKqB,WAAkB,MAAEC,mBAAkBsE,EAAMuG,WAK1DiR,wBAAR,SAAoB1d,GAApB,WACQiiB,EACF/c,OAAOU,KAAK5F,GAAQkd,OAAO,SAAAvd,GAAQ,OAAC6F,EAAKtB,MAAMqB,MAAM5F,KACzD,GAAIsiB,EAAWhf,OAAS,EACtB,MAAM,IAAIgE,MACN,uDACUgb,mCAIVvE,yBAAR,SAAqBhY,GAArB,WACEA,EAAQG,QAAQ,SAAAlG,GACP,IAAAuiB,UACP,IAAK1c,EAAKtB,MAAMqB,MAAM2c,GACpB,MAAM,IAAIjb,MAAM,eAAetH,yCE9a1BwiB,GAAqB,oBACrBC,GAAqB,2BAgDhC,WACYC,EACAC,gBAAAA,MADAxd,cAAAud,EACAvd,iBAAAwd,EAtCJxd,aAAU,MAuCG,MAAfwd,IACFxd,KAAKwd,gBAmMX,OAxOEpd,sBAAIqd,gCAAJ,WACE,OAAOzd,KAAK0d,yCAGdtd,sBAAIqd,8BAAJ,WACE,OAAOzd,KAAK2d,SAAS3C,4CAGvB5a,sBAAIqd,+BAAJ,WACE,OAAOzd,KAAK2d,SAASzD,6CAGvB9Z,sBAAIqd,0BAAJ,WACE,OAAOzd,KAAK2d,SAASziB,wCAGvBkF,sBAAIqd,2BAAJ,WACE,OAAOzd,KAAK2d,SAAS/c,yCAGvBR,sBAAIqd,2BAAJ,WACE,OAAOzd,KAAK2d,SAASrH,2CA4BhBmH,sBAAP,WACEzd,KAAK2d,SAASC,YACkB,MAA5BviB,EAAgB,UAClBT,EAAW,QAAS,SAACY,GACnB,IAAMkR,EAAIlR,EAAKN,OAAO,GAChBqf,EAAQ/e,EAAKN,OAAO,GAC1B,OAAO2iB,QAASnR,EAAG6N,MAKjBkD,0BAAR,WACE,IAAMK,EAAO9d,KAAKud,SAClB,GAAmC,MAA9BO,EAAsBC,KAEzB/d,KAAKge,QAAUF,OACV,GAAoC,MAAhC9d,KAAKwd,YAAYS,YAC1Bje,KAAKge,QAAUE,KAAGC,mBAAmBL,EAAgB9d,KAAKwd,iBACrD,CACL,IAAMY,EACFF,KAAGG,gBAAgBP,EAAgB9d,KAAKwd,YAAYc,YACxD,GAAwB,IAApBF,EAASjgB,OAGXigB,EAAShgB,KAAK8f,KAAGC,mBAAmBL,EAAgB9d,KAAKwd,mBACpD,GAAIY,EAASjgB,OAAS,EAC3B,MAAM,IAAIgE,MACN,wBAAwBic,EAASjgB,oCACxB2f,QAEf9d,KAAKge,QAAUI,EAAS,KAQtBX,iBAAN,6GAEE,GADAzd,KAAKue,gBACoB,MAArBve,KAAKge,QAAQD,KACf,MAAM,IAAI5b,MACN,iHAGY,SAAMnC,KAAKge,QAAQD,eASrC,OATMS,EAAYxhB,SACZoC,EAAQof,EAAUC,cAExBze,KAAK0d,QAAate,EAAMsf,SAASC,aAAYvf,EAAMsf,SAASE,YACtDtI,EACF4H,KAAGW,cAAcL,EAAUM,WAAYN,EAAUO,aACrD/e,KAAK2d,SACD,IAAI/E,GAAcvY,EAAgB2e,SAASC,eAAe7f,IAC9DY,KAAK2d,SAASrH,UAAYtW,KAAKkf,6BAA6B5I,OACrD,SAwCTmH,oBAAA,SAAQviB,EAAwCikB,GAE9C,OAAOnf,KAAKof,QAAQlkB,EAAQ8E,KAAKka,cAG3BuD,4BAAR,SAAwBviB,GAEtB,KAAMA,aAAkBmkB,UAAY7iB,MAAM+F,QAAQrH,IAEhD,OAAOA,EAGT,IADAA,EAASsB,MAAM+F,QAAQrH,GAAUA,GAAUA,IAChCiD,SAAW6B,KAAKgb,WAAW7c,OACpC,MAAM,IAAIgE,MACN,mDACuBnC,KAAKgb,WAAW7c,yCACpBjD,EAAOiD,0BAEhC,OAAO6B,KAAKgb,WAAW9a,OAAO,SAAC5D,EAAKkB,EAAWU,GAE7C,OADA5B,EAAIkB,GAActC,EAAoBgD,GAC/B5B,QAIHmhB,6BAAR,SAAyB7c,GAEvB,OADAA,EAAUA,GAAWZ,KAAKka,YAClB1d,MAAM+F,QAAQ3B,GAAuBA,GAAXA,IAkBpC6c,oBAAA,SAAQviB,EAAwC0F,GAE9C1F,EAAS8E,KAAKsf,gBAAgBpkB,GAC9B0F,EAAUZ,KAAKuf,iBAAiB3e,GAChC,IAAMiM,EAAS7M,KAAK2d,SAASyB,QAAQlkB,EAAQ0F,GAC7C,OAAOiM,EAAO1O,OAAS,EAAI0O,EAASA,EAAO,IAiBvC4Q,yBAAN,SACIviB,EACA0F,iGAGa,OAFf1F,EAAS8E,KAAKsf,gBAAgBpkB,GAC9B0F,EAAUZ,KAAKuf,iBAAiB3e,MACXZ,KAAK2d,SAAS6B,aAAatkB,EAAQ0F,WACxD,UADMiM,EAAS7P,UACDmB,OAAS,EAAI0O,EAASA,EAAO,UAGrC4Q,yCAAR,SAAqCnhB,GACnC,OAAO8D,OAAOU,KAAKxE,GAAK4D,OAAO,SAACuf,EAAyBze,GAEvD,OADAye,EAAOze,IAAQ1E,EAAI0E,IACZye,QAQXhC,oBAAA,WACEzd,KAAK2d,SAASrV,0DAkCdiV,EACAmC,uBAAAA,6FACF,GAAgB,MAAZnC,EACF,MAAM,IAAIpb,MACN,0GAgBN,OAbe,MAAXud,IACFA,MAGEA,EAAQC,WAC6B,MAAlCpC,EAA0BQ,OACvBR,EAAoBqC,SAAS,OACjCrC,GAAkC,KAEpCA,EAAW,GAAGA,EAAWD,GAAqBD,QAG5CwC,EAAQ,IAAIpC,GAAWF,EAAUmC,IAC3B3B,eACZ,OADA/gB,YACO6iB,iC3C7PoBhlB,UACpBF,EAAWE,uC4CzEJ"}